<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Formal Epistemology on Jonathan Weisberg</title>
    <link>http://jonathanweisberg.org/tags/formal-epistemology/index.xml</link>
    <description>Recent content in Formal Epistemology on Jonathan Weisberg</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://jonathanweisberg.org/tags/formal-epistemology/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Crash Course in Inductive Logic</title>
      <link>http://jonathanweisberg.org/post/inductive-logic/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/inductive-logic/</guid>
      <description>

&lt;p&gt;There are four ways things can turn out with two flips of a coin:
$$ HH, \quad HT, \quad TH, \quad TT.$$
If we know nothing about the coin&amp;rsquo;s tendencies, we might assign equal probability to each of
these four possible outcomes:
$$ Pr(HH) = Pr(HT) = Pr(TH) = Pr(TT) = 1/ 4. $$
But from another point of view, there are primarily three possibilities. If we ignore order,
the possible outcomes are $0$ heads, $1$ head, or $2$ heads. So we might
instead assign equal probability to these three outcomes, then divide
the middle $1/ 3$ evenly between $HT$ and $TH$: $$
  Pr(HH) = 1/3  \qquad  Pr(HT) = Pr(TH) = 1/6  \qquad  Pr(TT) = 1/ 3.
$$&lt;/p&gt;

&lt;p&gt;This two-stage approach may seem odd. But it&amp;rsquo;s actually friendlier
from the point of view of inductive reasoning. On the first
scheme, a heads on the first toss doesn&amp;rsquo;t increase the probability of
another heads. It stays fixed at $1/ 2$:
$$
  \newcommand{\p}{Pr}
  \newcommand{\given}{\mid}
  \renewcommand{\neg}{\mathbin{\sim}}
  \renewcommand{\wedge}{\mathbin{\text{&amp;amp;}}}
  \p(HH \given H) = \frac{1/ 4}{1/ 4 + 1/ 4} = \frac{1}{2}.
$$
Whereas it does increase on the second strategy, from $1/ 2$ to $2/ 3$:
$$ \p(HH \given H) = \frac{1/ 3}{1/ 3 + 1/ 6} = \frac{2}{3}. $$
The two-stage approach thus learns from experience, where the
single-step division is skeptical about induction.&lt;/p&gt;

&lt;p&gt;This holds true as we increase the number of flips. If we do three tosses
for example, we&amp;rsquo;ll find that $\p(HHH \given HH) = 3/ 4$ on the
two-stage analysis. Whereas this probability stays stubbornly fixed at
$1/ 2$ on the first approach. It won&amp;rsquo;t budge no matter how many heads
we observe, so we can&amp;rsquo;t learn anything about the coin&amp;rsquo;s bias this way.&lt;/p&gt;

&lt;p&gt;This is the difference between Carnap&amp;rsquo;s famous account of induction, from
his 1950 book &lt;em&gt;Logical Foundations of Probability&lt;/em&gt;, and the account
he finds &lt;a href=&#34;http://www.kfs.org/jonathan/witt/t515en.html&#34; target=&#34;_blank&#34;&gt;in Wittgenstein&amp;rsquo;s
&lt;em&gt;Tractatus&lt;/em&gt;&lt;/a&gt;. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:peirce&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:peirce&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; Although
Carnap had actually been scooped by W. E. Johnson, who worked out a similar
analysis about $25$ years earlier.&lt;/p&gt;

&lt;p&gt;This is a short explainer on some key elements of inductive logic that
Johnson and Carnap worked out, and the place of those ideas in the story of
inductive logic.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://jonathanweisberg.org/pdf/inductive-logic.pdf&#34;&gt;PDF version here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;states-structures&#34;&gt;States &amp;amp; Structures&lt;/h1&gt;

&lt;p&gt;Carnap calls fine-grained specifications like $TH$, &lt;em&gt;state-descriptions&lt;/em&gt;.
The coarser grained &amp;ldquo;$1$ head&amp;rdquo; is a &lt;em&gt;structure-description&lt;/em&gt;. A
state-description specifies which flips land heads, and which tails.
While a structure-description specifies &lt;em&gt;how many&lt;/em&gt; land heads and tails,
without necessarily saying which.&lt;/p&gt;

&lt;p&gt;It needn&amp;rsquo;t be coin flips landing heads or tails, of course. The same
ideas apply to any set of objects or events, and any feature they might
have or lack.&lt;/p&gt;

&lt;p&gt;Suppose we have two objects $a$ and $b$, each of which might have some
property $F$. Working for a moment as Carnap did, in
first-order logic, here is an example of a structure-description:
$$ (Fa \wedge \neg Fb) \vee (\neg Fa \wedge Fb). $$ But this isn&amp;rsquo;t a
state-description, since it doesn&amp;rsquo;t specify which object has $F$. It
only says how many objects have $F$, namely $1$. One of the disjuncts alone would be a
state-description though:
$$ Fa \wedge \neg Fb. $$&lt;/p&gt;

&lt;p&gt;Carnap&amp;rsquo;s idea was that all structure-descriptions start out with the
same probability. And these probabilities are then divided equally among
the state-descriptions that make up a structure-description.&lt;/p&gt;

&lt;p&gt;For example, if we do three flips, there are four
structure-descriptions: $0$ heads, $1$ head, $2$ heads, and $3$ heads.
Some of these have only one state-description. For example, there&amp;rsquo;s only
one way to get $0$ heads, namely $TTT$. So $$ \p(TTT) = 1/ 4. $$ But
others have multiple state-descriptions. There are three ways to get $1$
head for example, so we divide $1/ 4$ between them:
$$ \p(HTT) = \p(THT) = \p(TTH) = 1/ 12. $$&lt;/p&gt;

&lt;p&gt;The effect is that more homogeneous sequences start out more probable.
There&amp;rsquo;s only one way to get all heads, so the $HH$ state-description
inherits the full probability of the corresponding &amp;ldquo;$2$ heads&amp;rdquo;
structure-description. But a $50$-$50$ split has multiple permutations,
each of which inherits only a portion of the same quantum of
probability. A heterogeneous sequence of heads and tails thus starts out
less probable than a homogeneous one.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s why the two-stage analysis is induction-friendly. It effectively
builds Hume&amp;rsquo;s &amp;ldquo;uniformity of nature&amp;rdquo; assumption into the prior
probabilities.&lt;/p&gt;

&lt;h1 id=&#34;the-rule-of-succession&#34;&gt;The Rule of Succession&lt;/h1&gt;

&lt;p&gt;The two-stage assignment also yields a very simple formula for induction:
Laplace&amp;rsquo;s famous Rule of Succession. (Derivation in the Appendix.)&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;The Rule of Succession&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;Given $k$ heads out of $n$ observed flips, the probability of heads
on a subsequent toss is $$\frac{k+1}{n+2}.$$&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Laplace arrived at this rule about $150$ years earlier by somewhat
different means. But there is a strong similarity.&lt;/p&gt;

&lt;p&gt;Laplace supposed that our coin has some fixed, but unknown, chance $p$
of landing heads on each toss. Suppose we regard all possible values
$0 \leq p \leq 1$ as equally likely.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; If we then update our beliefs
about the true value of $p$ using Bayes&amp;rsquo; theorem, we arrive at the Rule
of Succession. (Proving this is a bit involved. Maybe I&amp;rsquo;ll go over it in
another time.)&lt;/p&gt;

&lt;p&gt;Carnap&amp;rsquo;s way of assigning prior probabilities is essentially the same
idea, just applied in a discrete setting. By treating all
structure-descriptions as equiprobable, we make all possible frequencies
of heads equiprobable. This is a discrete analogue of treating all
possible values of $p$ as equiprobable.&lt;/p&gt;

&lt;p&gt;William Ernest Johnson actually carried out the same analysis about $25$
years before Carnap. He even did so with greater generality. But
Carnap&amp;rsquo;s next step here was novel, so far as I know.&lt;/p&gt;

&lt;h1 id=&#34;the-continuum-of-inductive-methods&#34;&gt;The Continuum of Inductive Methods&lt;/h1&gt;

&lt;p&gt;Both Johnson and Carnap eventually realized that the two methods of assigning priors we&amp;rsquo;ve
considered so far are just two points on a larger continuum.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;The $\lambda$ Continuum&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;Given $k$ heads out of $n$ observed flips, the probability of heads
on a subsequent toss is $$\frac{k + \lambda/2}{n + \lambda},$$ for
some $\lambda$ in the range $0 \leq \lambda \leq \infty$.&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;What value should $\lambda$ take here? Notice we get the Rule of
Succession if $\lambda = 2$. And we get inductive skepticism if we let
$\lambda$ approach $\infty$. For then $k$ and $n$ fall away and the
ratio converges to $1/ 2$, no matter what $k$ and $n$ are.&lt;/p&gt;

&lt;p&gt;If we set $\lambda = 0$, we get a formula we haven&amp;rsquo;t discussed yet:
$k/n$. Reichenbach called this the Straight Rule. (In modern statistical
parlance it&amp;rsquo;s the &amp;ldquo;maximum likelihood estimate.&amp;rdquo;)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;The overall pattern is: the higher $\lambda$, the more &amp;ldquo;cautious&amp;rdquo; our
inductive inferences will be. A larger $\lambda$ means less influence
from $k$ and $n$: the probability of another heads stays closer to the
initial value of $1/ 2$. In the extreme case where $\lambda = \infty$,
it stays stuck at exactly $1/ 2$ forever.&lt;/p&gt;

&lt;p&gt;A low value of $\lambda$, on the other hand, will make our inferences
more ambitious. In the extreme case $\lambda = 0$, we jump immediately
to the observed frequency. Our expectation about the next toss is just
$k/n$, the frequency we&amp;rsquo;ve observed so far. If we&amp;rsquo;ve observed only one
flip and it was heads ($k = n = 1$), we&amp;rsquo;ll be certain of heads on
the second toss! &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;We can illustrate this pattern in a plot. First let&amp;rsquo;s consider what
happens if the coin keeps coming up heads, i.e. $k = n$. As $n$
increases, various settings of $\lambda$ behave as follows.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/inductive-logic/lambda-continuum-k1-n1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now suppose the coin only lands heads every third time, so that
$k \approx n/3$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/inductive-logic/lambda-continuum-k1-n3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice how lower settings of $\lambda$ bounce around more here before
settling into roughly $1/ 3$. Higher settings approach $1/ 3$ more
steadily, but they take longer to get there.&lt;/p&gt;

&lt;h1 id=&#34;carnap-s-program&#34;&gt;Carnap&amp;rsquo;s Program&lt;/h1&gt;

&lt;p&gt;Johnson and Carnap went much further, and others since have gone further still. For
example, we can include more than one predicate, we can use relational
predicates, and much more.&lt;/p&gt;

&lt;p&gt;But philosophers aren&amp;rsquo;t too big on this research program nowadays. Why not?&lt;/p&gt;

&lt;p&gt;Choosing $\lambda$ is one issue. Once we see that it&amp;rsquo;s more than a
binary choice, between inductive optimism and skepticism, it&amp;rsquo;s hard to
see why we should plump for any particular value of $\lambda$. We could
set $\lambda = 2$, or $\pi$, or $42$. By what criterion could we make
this choice? No clear answer emerged from Carnap&amp;rsquo;s program.&lt;/p&gt;

&lt;p&gt;Another issue is Goodman&amp;rsquo;s famous &lt;a href=&#34;http://www.wi-phi.com/video/puzzle-grue&#34; target=&#34;_blank&#34;&gt;grue
puzzle&lt;/a&gt;. Suppose we trade our
coin flips for emeralds. We might replace the heads/tails dichotomy with
green/not-green then. But we could instead replace it with
grue/not-grue. The prescriptions of Carnap&amp;rsquo;s inductive logic depend on
our choice of predicate&amp;mdash;on the underlying language to which we apply
our chosen value of $\lambda$.&lt;/p&gt;

&lt;p&gt;So the Johnson/Carnap system doesn&amp;rsquo;t provide us with rules for inductive
reasoning, more a framework for formulating such rules. We have to
decide which predicates should be projectible by choosing the underlying
language. And then we have to decide how projectible they should be by
choosing $\lambda$. Only then does the framework tell us what
conclusions to draw from a given set of observations.&lt;/p&gt;

&lt;p&gt;Personally, I still find Carnap&amp;rsquo;s framework useful. It provides a
lovely way to express informal ideas more rigorously. In it we can frame
questions about induction, skepticism, and prior probabilities with
lucidity.&lt;/p&gt;

&lt;p&gt;I also like it as a source of toy models. For example, I might test when
a given claim about induction holds and when it doesn&amp;rsquo;t, by playing with
different incarnations of $\lambda$.&lt;/p&gt;

&lt;p&gt;The utility of Carnap&amp;rsquo;s framework is thus a lot like that of its
deductive cousins. Compare Timothy Williamson&amp;rsquo;s use of modal logic to
create &lt;a href=&#34;https://philpapers.org/rec/WILANO-22&#34; target=&#34;_blank&#34;&gt;models of Gettier cases&lt;/a&gt;,
for example, or his model of &lt;a href=&#34;https://philpapers.org/rec/WILIKN&#34; target=&#34;_blank&#34;&gt;improbable
knowledge&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Even in deductive logic, we only get as much out as we put in. We have
to choose our connectives in propositional logic, our accessibility
relation in modal logic, etc. But a flexible system like possible-world
frames still has its uses, because we can use it to explore
philosophical options and their interconnections.&lt;/p&gt;

&lt;h1 id=&#34;further-readings&#34;&gt;Further Readings&lt;/h1&gt;

&lt;p&gt;For more on this topic, here are some suggested readings.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://fitelson.org/il.pdf&#34; target=&#34;_blank&#34;&gt;Inductive Logic&lt;/a&gt;, by Branden Fitelson&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cambridge.org/core/books/cambridge-companion-to-carnap/carnap-on-probability-and-induction/8AEBCBACE4A89B567B7508A1E065EB51&#34; target=&#34;_blank&#34;&gt;Carnap on Probability and Induction&lt;/a&gt;,
by Sandy Zabell&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.iep.utm.edu/conf-ind/&#34; target=&#34;_blank&#34;&gt;The IEP entry on Confirmation and
Induction&lt;/a&gt;, by Franz Huber&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://plato.stanford.edu/entries/logic-inductive/&#34; target=&#34;_blank&#34;&gt;The SEP entry on Inductive
Logic&lt;/a&gt;, by
James Hawthorne&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cambridge.org/core/books/pure-inductive-logic/2ED3E3EE53CC51A99C1DD94341CB7FA2&#34; target=&#34;_blank&#34;&gt;Pure Inductive
Logic&lt;/a&gt;,
by Jeffrey Paris and Alena Vencovská&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And if you want to see how Johnson and Carnap&amp;rsquo;s two-stage assignment of priors yields the
Rule of Succession, check out the Appendix.&lt;/p&gt;

&lt;h1 id=&#34;appendix-deriving-the-rule-of-succession&#34;&gt;Appendix: Deriving the Rule of Succession&lt;/h1&gt;

&lt;p&gt;To derive the Rule of Succession from the two-stage assignment of
priors, we need two key formulas.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The prior probability of a particular sequence with $k$ heads out of
$n$ flips.&lt;/li&gt;
&lt;li&gt;The prior probability of the same initial sequence, followed by one
more heads.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first quantity is the probability of getting $k$ heads out of $n$
flips, regardless of order, divided by the number of ways to get $k$
heads out of $n$ flips. The number of ways to get $k$ heads out of $n$
flips is called the &lt;a href=&#34;https://en.wikipedia.org/wiki/Binomial_coefficient&#34; target=&#34;_blank&#34;&gt;binomial
coefficient&lt;/a&gt;. It&amp;rsquo;s
written $\binom{n}{k}$, and there&amp;rsquo;s a nice formula for calculating it:
$$ \binom{n}{k} = \frac{n!}{(n-k)!k!}. $$ Since a sequence of $n$ flips
can feature anywhere from $0$ to $n$ heads, there are $n+1$ structure
descriptions, each with probability $1/(n+1)$. Thus the probability of a
specific state-description with $k$ heads out of $n$ flips is
\begin{align}
  \frac{1}{(n+1)\binom{n}{k}}
    &amp;amp;= \frac{1}{(n+1) \frac{n!}{(n-k)!k!}}\\&lt;br /&gt;
    &amp;amp;= \frac{(n-k)!k!}{(n+1)!}.\tag{1}
\end{align}&lt;/p&gt;

&lt;p&gt;The second probability we need is for the same initial sequence, but
with an additional heads on the next toss. That&amp;rsquo;s a sequence with $k+1$
heads out of $n+1$ tosses. There are $n+2$ structure descriptions now,
each with probability $1/(n+2)$. So the probability in question is
\begin{align}
  \frac{1}{(n+2)\binom{n+1}{k+1}}
    &amp;amp;= \frac{1}{(n+2) \frac{(n+1)!}{(n-k)!(k+1)!}}\\&lt;br /&gt;
    &amp;amp;= \frac{(n-k)!(k+1)!}{(n+2)!}.\tag{2}
\end{align}&lt;/p&gt;

&lt;p&gt;Now, to get the conditional probability we&amp;rsquo;re after, we take the ratio
of the second probability $(2)$ over the first probability $(1)$: $$
\begin{aligned}
  \frac{ \frac{(n-k)!(k+1)!}{(n+2)!} }{ \frac{(n-k)!k!}{(n+1)!} }
    &amp;amp;= \frac{(n-k)!(k+1)!}{(n+2)!}  \frac{(n+1)!}{(n-k)!k!} \\&lt;br /&gt;
    &amp;amp;= \frac{k+1}{n+2}.
\end{aligned}
$$ This agrees with the rule of succession, as desired.&lt;/p&gt;

&lt;p&gt;So far though, we&amp;rsquo;ve only shown the rule of succession for a specific,
observed sequence. We&amp;rsquo;ve shown that $\p(HTHH \given HTH) = 3/ 4$, for example.
But what if we don&amp;rsquo;t know the particular sequence so far? Maybe we only
know there were $2$ heads out of $3$ tosses. Shouldn&amp;rsquo;t we still be able to
derive the same result?&lt;/p&gt;

&lt;p&gt;We can, with the help of a relevant theorem of probability: if
$\p(A \given B) = \p(A \given C)$, and $B$ and $C$ are mutually
exclusive, then
$$ \p(A \given B \vee C) = \p(A \given B) = \p(A \given C). $$ In our
case $A$ specifies heads on flip $n+1$, while $B$ and $C$ each specify
some sequence for flips $1$ through $n$. Although these sequences
feature the same number of heads and tails, $B$ and $C$ specify
different orderings. So they&amp;rsquo;re mutually exclusive.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve already shown that
$$ \p(A \given B) = \frac{k+1}{n+1} = \p(A \given C). $$ So we just have
to verify the theorem:
$$
\begin{aligned}
  \p(A \given B \vee C)
    &amp;amp;= \frac{\p(A \wedge (B \vee C))}{\p(B \vee C)}\\&lt;br /&gt;
    &amp;amp;= \frac{\p(A \wedge B) + \p(A \wedge C)}{\p(B \vee C)}\\&lt;br /&gt;
    &amp;amp;= \frac{\p(A \given B)\p(B) + \p(A \given C)\p( C)}{\p(B \vee C)}\\&lt;br /&gt;
    &amp;amp;= \frac{\p(A \given B) \left( \p(B) + \p( C) \right)}{\p(B \vee C)}\\&lt;br /&gt;
    &amp;amp;= \p(A \given B).
\end{aligned}
$$
By applying this formula repeatedly to a disjunction of state-descriptions, we get the conditional probability on the structure description of interest.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:peirce&#34;&gt;Carnap also cites Keynes and Peirce as endorsing the Wittgensteinian approach. But thanks to Jonathan Livengood I learned this is actually a misattribution: Keynes mistakenly attributes the view to Peirce, and Carnap seems to have followed Keynes&amp;rsquo; error.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:peirce&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:1&#34;&gt;&lt;p&gt;More precisely: we regard them as having the same probability
&lt;em&gt;density&lt;/em&gt;, namely $1$.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:2&#34;&gt;&lt;p&gt;For the $\lambda = 0$ case, we need probability axioms that permit
conditioning on zero-probability events. For example,
$\p(HH \given H) = 1$ so $\p(HT \given H) = 0$. Thus
$\p(HT) = 0$, and $\p(HTH \given HT)$ is undefined on the usual,
Kolmogorov axioms.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:3&#34;&gt;&lt;p&gt;When $n = 0$ we have to stipulate that the probability is $1/ 2$,
the limit as $\lambda \rightarrow 0$.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Super-Humean Theory of Belief</title>
      <link>http://jonathanweisberg.org/post/super-humean-belief/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/super-humean-belief/</guid>
      <description>&lt;p&gt;The classic &lt;a href=&#34;https://plato.stanford.edu/entries/formal-belief/#QuaBel&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Lockean&amp;rdquo; thesis&lt;/a&gt; about full and partial belief says full belief is rational iff strong partial belief is rational. &lt;a href=&#34;https://philpapers.org/rec/LEIIHT&#34; target=&#34;_blank&#34;&gt;Hannes Leitgeb&amp;rsquo;s &amp;ldquo;Humean&amp;rdquo; thesis&lt;/a&gt; proposes a subtler connection.
$
\newcommand\p{Pr}
\newcommand{\B}{\mathbf{B}}
\newcommand{\given}{\mid}
$&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;The Humean Thesis&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;For a rational agent whose full beliefs are given by the set $\mathbf{B}$, and whose credences by the probability function $\p$: $B \in \mathbf{B}$ iff $\p(B \given A) &amp;gt; t$ for all $A$ consistent with $\mathbf{B}$.&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Notice that we can think of this as, instead, a coherentist theory of justification. Suppose we replace credence with &amp;ldquo;evidential&amp;rdquo; probability (think: Carnap, Williamson). Then we get a theory of justification where beliefs aren&amp;rsquo;t justified in isolation. It&amp;rsquo;s not enough for a belief to be highly probable in its own right, it has to be part of a larger body that underwrites that high probability.&lt;/p&gt;

&lt;p&gt;Flipping things around, the coherentist theory of justification from &lt;a href=&#34;http://jonathanweisberg.org/post/coherentism-1&#34;&gt;my last wacky post&lt;/a&gt; doubles as an even wackier theory of full belief. The Humean view is roughly that a belief is justified iff its fellows secure its high probability. Now the &amp;ldquo;Super-Humean&amp;rdquo; view says a belief is justified to the extent its fellows secure its high centrality.&lt;/p&gt;

&lt;p&gt;(Last time we explored one fun way of measuring centrality, drawing on coherentism for inspiration, and network theory for the math. But network theory offers &lt;a href=&#34;https://en.wikipedia.org/wiki/Centrality&#34; target=&#34;_blank&#34;&gt;many others ways of measuring centrality&lt;/a&gt;, which could be slotted in here to provide alternative theories of full and partial belief.)&lt;/p&gt;

&lt;p&gt;Like Leitgeb&amp;rsquo;s Humean view, the Super-Humean view has a holistic character. Instead of evaluating full beliefs just by looking at your credences, we also have to look at what else you believe.&lt;/p&gt;

&lt;p&gt;Another parallel: both theories have a permissive quality. Leitgeb presents examples where more than one set $\B$ fits with a given credence function $\p$, on the Humean view. And the same will be true on the Super-Humean view.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:coins&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:coins&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;But there are interesting differences. We can evaluate beliefs individually on the Super-Humean account, even though our method of evaluation is holistic. True, a belief&amp;rsquo;s justification depends on what else you believe. But your beliefs don&amp;rsquo;t all stand or fall together; some can come out justified even though others come out unjustified.&lt;/p&gt;

&lt;p&gt;Strictly speaking, some beliefs come out highly justified even though others come out hardly justified. Because, differing again from the Humean view, evaluations are graded on the Super-Humean view. Each belief is assigned a degree of justification.&lt;/p&gt;

&lt;p&gt;One nice thing about the Super-Humean view, then, is that it allows for &amp;ldquo;non-ideal&amp;rdquo; theorizing. We can study non-ideal agents, and discern more justified beliefs from lesser ones.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;But does it handle the lottery and preface paradoxes?&amp;rdquo;, is the question we always ask about a theory of full belief. As is so often the case, the answer is &amp;ldquo;yes, but&amp;hellip;&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Consider a lottery of $100$ tickets with one to be selected at random as the winner. If you believe of each ticket that it will lose, we have a network of $101$ nodes: $L_1$ through $L_{100}$, plus the tautology node $\top$. How strong are the connections between these nodes? Assuming we take $L_3&amp;ndash;L_{100}$ as givens in determining the weight of the $L_2 \rightarrow L_1$ arrow, it gets weight $0$ since
$$\p(L_1 \given L_2 \wedge L_3 \wedge \ldots \wedge L_{100}) = 0.$$
And likewise for all the other arrows,&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:epsilon&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:epsilon&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; except those pointing to the $\top$ node (they always get weight $1$). All the $L_i$ beliefs thus come out with rock-bottom justification compared to $\top$, i.e. you aren&amp;rsquo;t justified in believing these lottery propositions.&lt;/p&gt;

&lt;p&gt;Contrast that with a preface case, where you believe each of $100$ claims you&amp;rsquo;ve researched, $C_1$ through $C_{100}$. These claims are positively correlated though, or at least independent.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:pollock&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:pollock&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; So
$$\p(C_1 \given C_2 \wedge C_3 \wedge \ldots \wedge C_{100}) \approx 1,$$
and likewise for the other $C_i$. The belief-graph here is thus tightly connected, and the $C_i$ nodes will score high on centrality compared to $\top$. So you&amp;rsquo;re highly justified in your beliefs in the preface case.&lt;/p&gt;

&lt;p&gt;So far so good, at least if you think&amp;mdash;as I tend to&amp;mdash;that lottery beliefs should come out unjustified, while preface beliefs should come out justified. What&amp;rsquo;s the &amp;ldquo;but&amp;hellip;&amp;rdquo; then? I see two issues (at least).&lt;/p&gt;

&lt;p&gt;First, we had to assume that all your remaining beliefs are taken as given in assessing the weight of a connection like $L_2 \rightarrow L_1$. That worked out well here. But as a general rule, it doesn&amp;rsquo;t always have great results, as &lt;a href=&#34;https://twitter.com/Juan/status/1161735087093776384?s=20&#34; target=&#34;_blank&#34;&gt;Juan Comesaña noted&lt;/a&gt; about our treatment of the Tweety case last time.&lt;/p&gt;

&lt;p&gt;We could go all the way to the other extreme of course, and just evaluate the $L_2 \rightarrow L_1$ connection in isolation by looking at $\p(L_1 \given L_2)$. But that seems too extreme, since it means ignoring the agent&amp;rsquo;s other beliefs altogether.&lt;/p&gt;

&lt;p&gt;What we want is something in between, it seems. We want the agent&amp;rsquo;s other beliefs to &amp;ldquo;get in the way&amp;rdquo; enough that they substantially weaken the connections in the lottery graph. But we don&amp;rsquo;t want them to be taken entirely for granted. Exactly how to achieve the right balance here is something I&amp;rsquo;m not sure about.&lt;/p&gt;

&lt;p&gt;Second issue: what if you only adopt a few lottery beliefs, just $L_1$ and $L_2$ for example? Then we can&amp;rsquo;t exploit the &amp;ldquo;collective defeat&amp;rdquo; that drove our treatment of the lottery.&lt;/p&gt;

&lt;p&gt;You might respond that this is a fine result, since isolated lottery beliefs are actually justified. It&amp;rsquo;s only when you apply the same logic to all the tickets that your justification is undercut. But I find this unsatisfying.&lt;/p&gt;

&lt;p&gt;Maybe a student encountering the paradox for the first time is justified in believing their ticket will lose. But it should be enough to defeat that justification that they merely realize they could believe the same thing about all the other tickets, for identical reasons. Even if they don&amp;rsquo;t go ahead to form those beliefs, they should drop the one belief they had about their own ticket.&lt;/p&gt;

&lt;p&gt;This is one way in which Leitgeb&amp;rsquo;s Humean theory seems superior to me. On the Humean view, which beliefs are rational depends on how the space of possibilities is partitioned (see &lt;a href=&#34;https://philpapers.org/rec/LEITST-2&#34; target=&#34;_blank&#34;&gt;Leitgeb 2014&lt;/a&gt;). And the partition is determined by the context&amp;mdash;how the subject frames the situation in their mind. (At least, that&amp;rsquo;s how I understand Leitgeb here.) So just realizing the symmetry of the lottery paradox is enough to defeat justification, on the Humean view.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:coins&#34;&gt;&lt;p&gt;Example: imagine we&amp;rsquo;ll flip a coin of unknown bias $10$ times. And suppose the probabilities obey Laplace&amp;rsquo;s &lt;a href=&#34;https://en.wikipedia.org/wiki/Rule_of_succession&#34; target=&#34;_blank&#34;&gt;Rule of Succession&lt;/a&gt; (a.k.a. Carnap&amp;rsquo;s  $\mathfrak{m}^*$ confirmation function). Then, if you believe each flip will land heads, your beliefs will all come out highly justified, i.e. highly central in your web of $10$ beliefs. But they&amp;rsquo;d have the same justification if you instead believed each flip will land tails.&lt;/p&gt;

&lt;p&gt;Permissivism aside, this might seem a pretty bad result on its own. Even if our theory fixed which way you should go, say heads instead of tails, that would be pretty weird. Shouldn&amp;rsquo;t you wait for at least a few flips before forming any such beliefs?&lt;/p&gt;

&lt;p&gt;The problem is that we haven&amp;rsquo;t required your beliefs to be inherently probable, only that they render one another probable. The Lockean and Humean theories have such a threshold requirement built-in, but we can build it into our theory too. We can just stipulate that a full belief should be highly probable, as well as being highly central in the network of all your beliefs.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:coins&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:epsilon&#34;&gt;More carefully, each arrow gets the minimum possible weight. If we use the &amp;ldquo;Google hack&amp;rdquo; from last time, this is some small positive number $\epsilon$ instead of $0$.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:epsilon&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:pollock&#34;&gt;Notice we&amp;rsquo;re borrowing the crux of &lt;a href=&#34;https://pdfs.semanticscholar.org/b22f/a2029aad762cbeec8d03659b0f8b71dd6d91.pdf&#34; target=&#34;_blank&#34;&gt;Pollock&amp;rsquo;s (1994)&lt;/a&gt; classic treatment of the lottery and preface paradoxes. We&amp;rsquo;re just plugging his observation into a different formal framework.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:pollock&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Coherentism Without Coherence</title>
      <link>http://jonathanweisberg.org/post/coherentism-1/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/coherentism-1/</guid>
      <description>

&lt;p&gt;If you look at the little network diagram below, you&amp;rsquo;ll probably
agree that $P$ is the most &amp;ldquo;central&amp;rdquo; node in some intuitive sense.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/coherentism-1/fig3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This post is about using a belief&amp;rsquo;s centrality in the web of belief to
give a coherentist account of its justification. The more central a
belief is, the more justified it is.&lt;/p&gt;

&lt;p&gt;But how do we quantify &amp;ldquo;centrality&amp;rdquo;? The rough idea: the more ways there
are to arrive at a proposition by following inferential pathways in the
web of belief, the more central it is.&lt;/p&gt;

&lt;p&gt;Since we&amp;rsquo;re coherentists today (for the next 10 minutes, anyway), cyclic
pathways are allowed here. If we travel
$P \rightarrow Q \rightarrow R \rightarrow P$, that counts as an
inferential path leading to $P$. And if we go around that cycle twice,
that counts as another such pathway.&lt;/p&gt;

&lt;p&gt;You might think this just wrecks the whole idea. Every node has
infinitely many such pathways leading to it, after all. By cycling
around and around we can come up with literally any number of pathways
ending at a given node.&lt;/p&gt;

&lt;p&gt;But, by examining how these pathways differ in the limit, we can
differentiate between more and less central nodes/beliefs. We can thus
clarify a sense in which $P$ is most central, and quantify that
centrality. We can even use that quantity to answer a classic objection
to coherentism leveled by &lt;a href=&#34;https://philpapers.org/rec/KLEWPC&#34; target=&#34;_blank&#34;&gt;Klein &amp;amp; Warfield
(1994)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a bonus, we can do all this without ever giving an account of what
makes a corpus of beliefs &amp;ldquo;coherent.&amp;rdquo; This flips the script on a lot of
contemporary formal work on coherentism.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; Because coherentism is
holistic, you might think it has to evaluate the coherence of a whole
corpus first, before it can assess the individual members.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; But we&amp;rsquo;ll
see this isn&amp;rsquo;t so.
$$
\newcommand\T{\intercal}
\newcommand{\A}{\mathbf{A}}
\renewcommand{\v}{\mathbf{v}}
$$&lt;/p&gt;

&lt;h1 id=&#34;counting-pathways&#34;&gt;Counting Pathways&lt;/h1&gt;

&lt;p&gt;Our idea is to count how many paths there are leading to $P$ vs. other
nodes. We start with paths of length $1$, then count paths of length
$2$, then length $3$, and so on. As we count longer and longer paths,
each node&amp;rsquo;s count approaches infinity.&lt;/p&gt;

&lt;p&gt;But not their relative ratios! If, at each step, we divide the number of
paths ending at $P$ by the number of all paths, this ratio converges.&lt;/p&gt;

&lt;p&gt;To find its limit, we represent our graph numerically. A graph can be
represented in a table, where each node corresponds to a row and column.
The columns represent &amp;ldquo;sources&amp;rdquo; and the rows represent &amp;ldquo;targets.&amp;rdquo; We put
a $1$ where the column node points to the row node, otherwise we put a
$0$.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;$P$&lt;/th&gt;
&lt;th&gt;$Q$&lt;/th&gt;
&lt;th&gt;$R$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$P$&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$Q$&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$R$&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Hiding the row and column names gives us a matrix we&amp;rsquo;ll call $\A$: $$
\A =
\left[
  \begin{matrix}
    0 &amp;amp; 1 &amp;amp; 1 \\&lt;br /&gt;
    1 &amp;amp; 0 &amp;amp; 0 \\&lt;br /&gt;
    0 &amp;amp; 1 &amp;amp; 0
  \end{matrix}
\right].
$$ Notice how each row records the length-$1$ paths leading to the
corresponding node. There are two such paths to $P$, and one each to $Q$
and $R$.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;The key to counting longer paths is to take powers of $\A$. If we
multiply $\A$ by itself to get $\A^2$, we get a record of the length-$2$
paths: $$
\A^2 = \A \times \A = \left[
  \begin{matrix}
    0 &amp;amp; 1 &amp;amp; 1 \\&lt;br /&gt;
    1 &amp;amp; 0 &amp;amp; 0 \\&lt;br /&gt;
    0 &amp;amp; 1 &amp;amp; 0
  \end{matrix}
\right] \left[
  \begin{matrix}
    0 &amp;amp; 1 &amp;amp; 1 \\&lt;br /&gt;
    1 &amp;amp; 0 &amp;amp; 0 \\&lt;br /&gt;
    0 &amp;amp; 1 &amp;amp; 0
  \end{matrix}
\right] =
\left[
  \begin{matrix}
    1 &amp;amp; 1 &amp;amp; 0 \\&lt;br /&gt;
    0 &amp;amp; 1 &amp;amp; 1 \\&lt;br /&gt;
    1 &amp;amp; 0 &amp;amp; 0
  \end{matrix}
\right].
$$ There are two such paths to $P$: $$
\begin{aligned}
  Q \rightarrow R \rightarrow P,\\&lt;br /&gt;
  P \rightarrow Q \rightarrow P.
\end{aligned}
$$ Similarly for $Q$: $$
\begin{aligned}
  Q \rightarrow P \rightarrow Q,\\&lt;br /&gt;
  R \rightarrow P \rightarrow Q.
\end{aligned}
$$ While $R$ has just one length-$2$ path:
$$ P \rightarrow Q \rightarrow R. $$ If we go on to examine $\A^3$, its
rows will tally the length-$3$ paths; in general, $\A^n$ tallies the
paths of length-$n$.&lt;/p&gt;

&lt;p&gt;But we want relative ratios, not raw counts. The trick to getting these
is to divide $\A$ at each step by a special number $\lambda$, known as
the &amp;ldquo;leading eigenvalue&amp;rdquo; of $\A$ (details &lt;a href=&#34;#tech&#34;&gt;below&lt;/a&gt;). If we take
the limit
$$ \lim_{n \rightarrow \infty} \left(\frac{\A}{\lambda}\right)^n $$ we
get a matrix whose columns all have a special property: $$
\left[
  \begin{matrix}
    0.41 &amp;amp; 0.55 &amp;amp; 0.31 \\&lt;br /&gt;
    0.31 &amp;amp; 0.41 &amp;amp; 0.23 \\&lt;br /&gt;
    0.23 &amp;amp; 0.31 &amp;amp; 0.18
  \end{matrix}
\right].
$$ They all have the same relative proportions. They&amp;rsquo;re multiples of the
same &amp;ldquo;frequency vector,&amp;rdquo; a vector of positive values that sum to $1$: $$
\left[
  \begin{matrix}
    0.43 \\&lt;br /&gt;
    0.32 \\&lt;br /&gt;
    0.25 \\&lt;br /&gt;
  \end{matrix}
\right].
$$ So as we tally longer and longer paths, we find that $43\%$ of those
paths lead to $P$, compared with $32\%$ for $Q$ and $25\%$ for $R$. Thus
$P$ is about $1.3$ times as justified as $Q$ ($.43/.32$), and about
$1.7$ times as justified as $R$ ($.43/.25$).&lt;/p&gt;

&lt;p&gt;We want absolute degrees of justification though, not just comparative
ones. So we borrow a trick from probability theory and use a tautology
for scale.&lt;/p&gt;

&lt;p&gt;We add a special node $\top$ to our graph, which every other node points
to, though $\top$ doesn&amp;rsquo;t point back.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/coherentism-1/fig4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Updating our matrix $\A$ accordingly, we insert $\top$ in the first
row/column: $$
\A =
\left[
  \begin{matrix}
    0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 \\&lt;br /&gt;
    0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 \\&lt;br /&gt;
    0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\&lt;br /&gt;
    0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0
  \end{matrix}
\right].
$$ Redoing our limit anlaysis gives us the vector
$(1.00, 0.57, 0.43, 0.33)$. But this isn&amp;rsquo;t our final answer, because
it&amp;rsquo;s actually not possible for the non-$\top$ nodes to get a value
higher than $2/3$ in a graph with just $3$ non-$\top$ nodes.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; So we
divide elementwise by $(1, 2/3, 2/3, 2/3)$ to scale things, giving us
our final result: $$
\left[
  \begin{matrix}
    1.00 \\&lt;br /&gt;
    0.85 \\&lt;br /&gt;
    0.65 \\&lt;br /&gt;
    0.49
  \end{matrix}
\right].
$$ The relative justifications are the same as before, e.g. $P$ is still
$1.3$ times as justified as $Q$. But now we can make absolute
assessments too. $R$ comes out looking pretty bad ($0.49$), as seems
right, while $Q$ looks a bit better ($0.65$). Of course $P$ looks best
($0.85$), though maybe not quite good enough to be justified &lt;em&gt;tout
court&lt;/em&gt;.&lt;/p&gt;

&lt;h1 id=&#34;the-klein-warfield-problem&#34;&gt;The Klein&amp;ndash;Warfield Problem&lt;/h1&gt;

&lt;p&gt;Ok that&amp;rsquo;s theoretically nifty and all, but does it work on actual cases?
Let&amp;rsquo;s try it out by looking at a notorious objection to coherentism.
&lt;a href=&#34;https://philpapers.org/rec/KLEWPC&#34; target=&#34;_blank&#34;&gt;Klein &amp;amp; Warfield (1994)&lt;/a&gt; argue that
coherentism flouts the laws of probability. How so?&lt;/p&gt;

&lt;p&gt;Making sense of things often means believing more: taking on new beliefs
to resolve the tensions in our existing ones. For example, if we think
Tweety is a bird who can&amp;rsquo;t fly, the tension is resolved if we also
believe they&amp;rsquo;re a penguin.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;But believing more means believing less probably. Increases in logical
strength bring decreases in probability (unless the stronger content was
already guaranteed with probability $1$). So increasing the coherence in
one&amp;rsquo;s web of belief will generally mean decreasing its probability. How
could increasing coherence increase justification, then?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://philpapers.org/rec/MEROBO&#34; target=&#34;_blank&#34;&gt;Merricks (1995)&lt;/a&gt; points out that,
even though the probability of the whole corpus goes down, the
probabilities of individual beliefs go up in a way. After all, it&amp;rsquo;s more
likely Tweety can&amp;rsquo;t fly if they&amp;rsquo;re a penguin, than if they&amp;rsquo;re just a
bird of some unknown species.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s only the beginning of a satisfactory answer though. After all, we
might not be justified in believing Tweety&amp;rsquo;s a penguin in the first
place! Adding a new belief to support an existing belief doesn&amp;rsquo;t help if
the new belief has no support itself. We need a more global assessment,
which is where the present account shines.&lt;/p&gt;

&lt;p&gt;Suppose we add $P$ = &lt;em&gt;Tweety is a penguin&lt;/em&gt; to the network containing $B$
= &lt;em&gt;Tweety is a bird&lt;/em&gt; and $\neg F$ = &lt;em&gt;Tweety can&amp;rsquo;t fly&lt;/em&gt;. Will this
increase the centrality/justification of $B$ and of $\neg F$? Yes, but
we need to sort out the support relations to verify this.&lt;/p&gt;

&lt;p&gt;Presumably $P$ supports $B$, and $\neg F$ too. But what about the other
way around? If Tweety is a flightless bird, there&amp;rsquo;s a decent chance
they&amp;rsquo;re a penguin. But it&amp;rsquo;s hardly certain; they might be an emu or kiwi
instead. Come to think of it, isn&amp;rsquo;t support a matter of degree, so don&amp;rsquo;t
we need finer tools than just on/off arrows?&lt;/p&gt;

&lt;p&gt;Yes, and the refinement is easy. We accommodate degrees of support by
attaching weights to our arrows. Instead of just placing a $1$ in our
matrix $\A$ wherever the column-node points to the row-node, we put a
number from the $[0,1]$ interval that reflects the strength of support.
The same limit analysis as before still works, as it turns out.
We just think of our inferential links as &amp;ldquo;leaky pipes&amp;rdquo; now, where
weaker links make for leakier pipelines.&lt;/p&gt;

&lt;p&gt;We still need concrete numbers to analyze the Tweety example. But it&amp;rsquo;s a
toy example, so let&amp;rsquo;s just make up some plausible-ish numbers to get us
going. Let&amp;rsquo;s suppose $1\%$ of birds are flightless, and birds are an
even smaller percentage of the flightless things, say $0.1\%$. Let&amp;rsquo;s
also pretend that $20\%$ of flightless birds are penguins.&lt;/p&gt;

&lt;p&gt;Before believing Tweety is a penguin then, our web of belief looks like
this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/coherentism-1/fig5a.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Calculating the degrees of justification for $B$ and $\neg F$, both come
out very close to $0$ as you&amp;rsquo;d expect (with $B$ closer to $0$ than
$\neg F$). Now we add $P$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/coherentism-1/fig5b.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Recalculating degrees of justification, we find that they increase
drastically. $B$ and $F$ are now justified to degree $0.85$, while $P$
is justified to degree $0.26$. (All numbers approximate.)&lt;/p&gt;

&lt;p&gt;So our account vindicates Merricks. Not only does adding $P$ to the
corpus add &amp;ldquo;local&amp;rdquo; justification for $B$ and for $\neg F$. It also
improves their standing on a more global assessment.&lt;/p&gt;

&lt;p&gt;You might be worried though: did $P$ come out too weakly justified, at
just $0.26$? No: that&amp;rsquo;s either an artifact of oversimplification, or
else it&amp;rsquo;s actually the appropriate outcome. Notice that $B$ and $\neg F$
don&amp;rsquo;t really support Tweety being a penguin. They&amp;rsquo;re a flightless bird,
sure, but maybe they&amp;rsquo;re an emu, kiwi, or moa. We chose to believe
penguin, and maybe we have our reasons. If we do, then the graph is
missing background beliefs which would improve $P$&amp;rsquo;s standing once
added. But otherwise, we just fell prey to stereotyping or
comes-to-mind-bias, in which case it&amp;rsquo;s right that $P$ stand poorly.&lt;/p&gt;

&lt;h1 id=&#34;tech&#34;&gt;Technical Background&lt;/h1&gt;

&lt;p&gt;The notion of centrality used here is a common tool in network analysis,
where it&amp;rsquo;s known as &lt;a href=&#34;https://en.wikipedia.org/wiki/Eigenvector_centrality&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;eigenvector
centrality.&amp;rdquo;&lt;/a&gt;
Because the frequency vector we arrive at in the limit is an
&lt;a href=&#34;https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors&#34; target=&#34;_blank&#34;&gt;eigenvector&lt;/a&gt;
of the matrix $\A$. In fact it&amp;rsquo;s a special eigenvector, the only one
with all-positive values.&lt;/p&gt;

&lt;p&gt;Since we&amp;rsquo;re measuring justification on a $0$-to-$1$ scale, our account
depends on there always being such an eigenvector for $\A$. In fact we
need it to be unique, up to scaling (i.e. up to multiplication by a
constant).&lt;/p&gt;

&lt;p&gt;The theorem that guarantees this is actually quite old, going back to
work by Oskar Perron and Georg Frobenius published around 1910. Here&amp;rsquo;s one version of it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Perron&amp;ndash;Frobenius Theorem.&lt;/strong&gt; Let $\A$ be a square matrix whose entries
are all positive. Then all of the following hold.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$\A$ has an eigenvalue $\lambda$ that is larger (in absolute value)
than $\A$&amp;rsquo;s other eigenvalues. We call $\lambda$ the &lt;em&gt;leading
eigenvalue&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;$\A$&amp;rsquo;s leading eigenvalue has an eigenvector $\v$ whose entries are
all positive. We call $\v$ the &lt;em&gt;leading eigenvector&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;$\A$ has no other positive eigenvectors, save multiples of $\v$.&lt;/li&gt;
&lt;li&gt;The powers $(\A/\lambda)^n$ as $n \rightarrow \infty$ approach a
matrix whose columns are all multiples of $\v$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now, our matrices had some zeros, so they weren&amp;rsquo;t positive in all their
entries. But it doesn&amp;rsquo;t really matter, as it turns out.&lt;/p&gt;

&lt;p&gt;Frobenius&amp;rsquo; contribution was to generalize this result to many cases that
feature zeros. But even in cases where Frobenius&amp;rsquo; weaker conditions
aren&amp;rsquo;t satisfied, we can just borrow a trick from Google.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; Instead of
using a $0$-to-$1$ scale, we use $\epsilon$-to-$1$ for some very small
positive number $\epsilon$. Then all entries in $\A$ are guaranteed to
be positive, and we just rescale our results accordingly. (Choose
$\epsilon$ small enough and the difference is negligible in practice.)&lt;/p&gt;

&lt;h1 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h1&gt;

&lt;p&gt;This post owes a lot to prior work by Elena Derksen and Selim Berker.
I&amp;rsquo;d never really thought much about how coherence and justification
relate prior to reading &lt;a href=&#34;http://www.philpeople.com/elenarabinoffderksen/research.html&#34; target=&#34;_blank&#34;&gt;Derksen&amp;rsquo;s
work&lt;/a&gt;. And
&lt;a href=&#34;https://philpapers.org/rec/BERCVG&#34; target=&#34;_blank&#34;&gt;Berker&amp;rsquo;s&lt;/a&gt; prompted me to take graphs
more seriously as a way of formalizing coherentism. I&amp;rsquo;m also grateful to
David Wallace for &lt;a href=&#34;http://jonathanweisberg.org/post/page-rank-1/&#34;&gt;introducing me to the Perron&amp;ndash;Frobenius theorem&amp;rsquo;s use
as a tool in network
analysis&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;&lt;p&gt;See &lt;a href=&#34;https://philpapers.org/rec/SHOICT-2&#34; target=&#34;_blank&#34;&gt;Shogenji (1999)&lt;/a&gt; and
&lt;a href=&#34;https://philpapers.org/rec/FITAPT&#34; target=&#34;_blank&#34;&gt;Fitelson (2003)&lt;/a&gt; for some early
accounts. See Section 6 of &lt;a href=&#34;https://plato.stanford.edu/entries/justep-coherence/#ProMeaCoh&#34; target=&#34;_blank&#34;&gt;Olsson&amp;rsquo;s SEP
entry&lt;/a&gt;
for a survey and more recent references.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:2&#34;&gt;&lt;p&gt;In his seminal book on coherentism, &lt;a href=&#34;https://philpapers.org/rec/BONTSO-4&#34; target=&#34;_blank&#34;&gt;Bonjour
(1985)&lt;/a&gt; writes: &amp;ldquo;the
justification of a particular empirical belief finally depends, not
on other particular beliefs as the linear conception of
justification would have it, but instead on the overall system and
its coherence.&amp;rdquo; This doesn&amp;rsquo;t commit us to
assessing overall coherence before individual
justification. But that&amp;rsquo;s a natural conclusion you might come away with.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:3&#34;&gt;&lt;p&gt;We could count every proposition as pointing to itself. This would
mean putting $1$&amp;rsquo;s down the diagonal, i.e. adding the identity
matrix $\mathbf{I}$ to $\A$. This can be useful as a way to ensure
the limits we&amp;rsquo;ll require exist. But we&amp;rsquo;ll solve that problem
differently in the &amp;ldquo;Technical Background&amp;rdquo; section. And otherwise it
doesn&amp;rsquo;t really affect our results. It increases the leading
eigenvalue by $1$, but doesn&amp;rsquo;t affect the leading eigenvector.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:4&#34;&gt;&lt;p&gt;In general, the maximum possible centrality is $(k-1)/k$ in a
graph with $k$ non-$\top$ nodes.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:5&#34;&gt;&lt;p&gt;Hat tip to Erik J. Olsson&amp;rsquo;s &lt;a href=&#34;https://plato.stanford.edu/entries/justep-coherence/&#34; target=&#34;_blank&#34;&gt;entry on
coherentism&lt;/a&gt;
in the SEP, which uses this example in place of Klein &amp;amp; Warfield&amp;rsquo;s
slightly more involved one.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:6&#34;&gt;&lt;p&gt;Google&amp;rsquo;s founders used a variant of eigenvector centrality called
&amp;ldquo;PageRank&amp;rdquo; in their original search engine.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Open Handbook of Formal Epistemology</title>
      <link>http://jonathanweisberg.org/post/open-handbook/</link>
      <pubDate>Wed, 26 Jun 2019 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/open-handbook/</guid>
      <description>&lt;p&gt;Today &lt;em&gt;The Open Handbook of Formal Epistemology&lt;/em&gt; is &lt;a href=&#34;http://jonathanweisberg.org/pdf/open-handbook-of-formal-epistemology.pdf&#34;&gt;available for download&lt;/a&gt;. It&amp;rsquo;s an open access book, the first published by PhilPapers itself. (The editors are &lt;a href=&#34;https://richardpettigrew.com/&#34; target=&#34;_blank&#34;&gt;Richard Pettigrew&lt;/a&gt; and me.)&lt;/p&gt;

&lt;p&gt;The book features 11 outstanding entries by 11 wonderful philosophers.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Precise Credences&amp;rdquo;, by &lt;a href=&#34;https://sites.google.com/site/michaeltitelbaum/&#34; target=&#34;_blank&#34;&gt;Michael G. Titelbaum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Decision Theory&amp;rdquo;, by &lt;a href=&#34;https://johannathoma.com/&#34; target=&#34;_blank&#34;&gt;Johanna Thoma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Imprecise Probabilities&amp;rdquo;, by &lt;a href=&#34;http://www.lse.ac.uk/cpnss/people/anna-mahtani?from_serp=1&#34; target=&#34;_blank&#34;&gt;Anna Mahtani&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Primitive Conditional Probabilities&amp;rdquo;, by &lt;a href=&#34;http://www.kennyeaswaran.org/&#34; target=&#34;_blank&#34;&gt;Kenny Easwaran&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Infinitesimal Probabilities&amp;rdquo;, by &lt;a href=&#34;http://www.sylviawenmackers.be/&#34; target=&#34;_blank&#34;&gt;Sylvia Wenmackers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Comparative Probabilities&amp;rdquo;, by &lt;a href=&#34;https://jason-konek.squarespace.com/&#34; target=&#34;_blank&#34;&gt;Jason Konek&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Belief Revision Theory&amp;rdquo;, by &lt;a href=&#34;https://sites.google.com/site/hantilinphil/&#34; target=&#34;_blank&#34;&gt;Hanti Lin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Ranking Theory&amp;rdquo;, by &lt;a href=&#34;https://huber.blogs.chass.utoronto.ca/&#34; target=&#34;_blank&#34;&gt;Franz Huber&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Full &amp;amp; Partial Belief&amp;rdquo;, by &lt;a href=&#34;https://kgenin.github.io/&#34; target=&#34;_blank&#34;&gt;Konstantin Genin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Doxastic Logic&amp;rdquo;, by &lt;a href=&#34;https://sites.google.com/site/caiemike/&#34; target=&#34;_blank&#34;&gt;Michael Caie&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Conditionals&amp;rdquo;, by &lt;a href=&#34;https://philosophy.stanford.edu/people/ray-briggs&#34; target=&#34;_blank&#34;&gt;R. A. Briggs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We wanted to include lots more, but didn&amp;rsquo;t want to hold up publication any longer. Hopefully a second edition will cover more.&lt;/p&gt;

&lt;p&gt;For me personally, a central aim of this project was to demonstrate a point about open access publishing and shared standards. The budget for this book was exactly $0.00, and this was only possible because we didn&amp;rsquo;t need a human typesetter.&lt;/p&gt;

&lt;p&gt;Pretty much everyone in formal epistemology uses the same, standardized format to do their writing. And that format plugs in to a high-quality, freely available &lt;a href=&#34;https://en.wikipedia.org/wiki/TeX&#34; target=&#34;_blank&#34;&gt;typesetting program&lt;/a&gt;. So all you have to do to turn a dozen contributions from different authors into a unified book is paste them into a template and click &amp;ldquo;typeset&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Ok, it did actually take some noodling to iron out the kinks. But mainly just because of my poor planning. Having done it once now and learned the gotchas, a second go would come pretty close to the copy→paste→typeset dream.&lt;/p&gt;

&lt;p&gt;So for me, the moral is that philosophers in general should settle on a similar standard  (all academics, really). If we did, we&amp;rsquo;d have a lot more freedom from commercial publishers. We could publish open access books like this on the regular. The books would be freely and easily available to all, and authors would retain copyright.&lt;/p&gt;

&lt;p&gt;Collective action problems plague academia, and philosophical publishing in particular. But this one&amp;rsquo;s about as close to an opportunity for a major Pareto improvement as we&amp;rsquo;re likely to get.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nobody Expects the Chance Function!</title>
      <link>http://jonathanweisberg.org/post/samet-theorem/</link>
      <pubDate>Fri, 15 Feb 2019 11:52:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/samet-theorem/</guid>
      <description>

&lt;p&gt;Here&amp;rsquo;s a striking result that caught me off guard the other day. It came up in a facebook thread, and judging by the discussion there it caught a few other people in this neighbourhood off guard too.&lt;/p&gt;

&lt;p&gt;The short version: chances are &amp;ldquo;self-expecting&amp;rdquo; pretty much if and only if they&amp;rsquo;re &amp;ldquo;self-certain&amp;rdquo;. Less cryptically: the chance of a proposition equals its expected chance just in case the chance function assigns probability 1 to itself being the true chance function, modulo an exception to be discussed below.&lt;/p&gt;

&lt;p&gt;The same result applies to any probabilities of course, whether they represent physical chances or evidential probabilities or whatever. In fact, thanks to friends on facebook, I learned that it drives &lt;a href=&#34;https://philpapers.org/archive/DOREAG.pdf&#34; target=&#34;_blank&#34;&gt;this lovely paper by Kevin Dorst&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I just happened to stumble across it while thinking about chances, because Richard Pettigrew uses the assumption that chances are self-expecting in &lt;a href=&#34;http://fitelson.org/coherence/pettigrew_chance.pdf&#34; target=&#34;_blank&#34;&gt;his &lt;em&gt;Phil Review&lt;/em&gt; paper on accuracy and the Principal Principle&lt;/a&gt;. But later, in &lt;a href=&#34;https://philpapers.org/rec/PETAAT-7&#34; target=&#34;_blank&#34;&gt;his landmark book on accuracy&lt;/a&gt;, he switches to the requirement that they be self-certain. It turns out this isn&amp;rsquo;t a coincidence. The result we&amp;rsquo;re about to look at illuminates this shift.&lt;/p&gt;

&lt;p&gt;The result goes back to 1997 at least, in &lt;a href=&#34;https://homepages.cwi.nl/~jve/books/oldgass/high-order-beliefs.pdf&#34; target=&#34;_blank&#34;&gt;a paper by Dov Samet&lt;/a&gt;. Proving the full result is a bit more involved than what I&amp;rsquo;ll present here. For simplicity, I&amp;rsquo;ll only prove a special case at the end. But along the way we&amp;rsquo;ll look at some suggestive examples that illustrate the full version.&lt;/p&gt;

&lt;h1 id=&#34;the-chance-matrix&#34;&gt;The Chance Matrix&lt;/h1&gt;

&lt;p&gt;Imagine we have just four possible worlds, resulting from two tosses of a coin. What are the physical chances at each of the four possible worlds $HH$, $HT$, $TH$, and $TT$? $\newcommand{\mstar}{\mathfrak{m}^*} \newcommand{\C}{\mathbf{C}}$&lt;/p&gt;

&lt;p&gt;One natural thought is to apply Laplace&amp;rsquo;s classic rule of succession: given $s$ heads out of $n$ tosses, conclude that the probability of heads on each toss is $(s+1)/(n+2)$. So at $HH$-world for example, the chance of heads was $3/ 4$ on each toss.&lt;/p&gt;

&lt;p&gt;If we assume the tosses are independent, then $HH$-world had chance $(3/ 4)(3/ 4) = 9/16$ of being actual, according to the chance function at $HH$-world. Whereas $HT$-world had chance $(3/ 4)(1/ 4) = 3/16$ of being actual at $HH$-world. The full chance function at $HH$-world can be displayed as a column vector:
$$
\left(
    \begin{matrix}
        9/16\\&lt;br /&gt;
        3/16\\&lt;br /&gt;
        3/16\\&lt;br /&gt;
        1/16
    \end{matrix}
\right).
$$
Applying the same recipe at $HT$-world would give us a different column vector. And sticking the columns for all four worlds together, we get a $4 \times 4$ &lt;em&gt;chance matrix&lt;/em&gt; for our space of possible worlds:
$$
\mathbf{C} =
    \left(
        \begin{matrix}
            9/16 &amp;amp; 1/ 4 &amp;amp; 1/ 4 &amp;amp; 1/16\\&lt;br /&gt;
            3/16 &amp;amp; 1/ 4 &amp;amp; 1/ 4 &amp;amp; 3/16\\&lt;br /&gt;
            3/16 &amp;amp; 1/ 4 &amp;amp; 1/ 4 &amp;amp; 3/16\\&lt;br /&gt;
            1/16 &amp;amp; 1/ 4 &amp;amp; 1/ 4 &amp;amp; 9/16
        \end{matrix}
    \right).
$$
Each column gives the chances &lt;em&gt;at&lt;/em&gt; a world, while a row gives the chances &lt;em&gt;of&lt;/em&gt; a world. For example, entry $c_{14}$ gives the chance &lt;em&gt;at&lt;/em&gt; world $4$ &lt;em&gt;of&lt;/em&gt; world $1$ being actual. It says how likely the sequence $HH$ was if the actual unfolding of events is instead $TT$, namely $1/16$.&lt;/p&gt;

&lt;p&gt;A different thought would be to appeal to Carnap&amp;rsquo;s notorious &amp;ldquo;logical&amp;rdquo; prior $\mstar$:
$$
\mstar =
    \left(
        \begin{matrix}
            1/3\\&lt;br /&gt;
            1/6\\&lt;br /&gt;
            1/6\\&lt;br /&gt;
            1/3
        \end{matrix}
    \right).
$$
This assignment of probabilities ignores the actual unfolding of events in each world. It falls out of a bit of a priori reasoning instead. There are three possible outcomes: $2$ heads, $1$ head, or $0$ heads. Each is equally likely, $1/ 3$. But there are two ways to get $1$ head, so the $1/ 3$ there gets subdivided equally between $HT$ and $TH$, leaving $1/6$ for each.&lt;/p&gt;

&lt;p&gt;Since these chances ignore the actual unfolding of events in each world, the chance matrix we get here is extremely anti-Humean. It&amp;rsquo;s just four repetitions of $\mstar$:
$$
\mathbf{C} =
    \left(
        \begin{matrix}
            1/3 &amp;amp; 1/3 &amp;amp; 1/3 &amp;amp; 1/3\\&lt;br /&gt;
            1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6\\&lt;br /&gt;
            1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6\\&lt;br /&gt;
            1/3 &amp;amp; 1/3 &amp;amp; 1/3 &amp;amp; 1/3
        \end{matrix}
    \right).
$$
You might think that&amp;rsquo;s a pretty terrible theory of chance, and I sympathize. But what we&amp;rsquo;re about to see is that, of our two chance matrices, only the second is &amp;ldquo;self-expecting&amp;rdquo;. And its terribleness is part of the reason why.&lt;/p&gt;

&lt;h1 id=&#34;self-expectation&#34;&gt;Self Expectation&lt;/h1&gt;

&lt;p&gt;Pettigrew&amp;rsquo;s &lt;em&gt;Phil Review&lt;/em&gt; paper assumes that chance functions are &amp;ldquo;self-expecting&amp;rdquo;. The chance of a proposition at a given world must equal its expected value, where the expectation is taken according to the chances at that world.&lt;/p&gt;

&lt;p&gt;In terms of a chance matrix $\C$, this amounts to the requirement that $\C \C = \C$. When we multiply $\C$ by $\C$, we take dot-products of rows and columns. For example, if we were doing the calculation by hand, we&amp;rsquo;d start by multiplying the first row of $\C$ by the first column of $\C$. And this is just the weighted average of the various possible chances &lt;em&gt;of&lt;/em&gt; the first world, where the weights are the chances &lt;em&gt;at&lt;/em&gt; that world. In other words, it&amp;rsquo;s the expected chance &lt;em&gt;of&lt;/em&gt; $HH$-world &lt;em&gt;at&lt;/em&gt; $HH$-world.&lt;/p&gt;

&lt;p&gt;In general, the dot product of row $i$ with column $j$ is the expected chance &lt;em&gt;of&lt;/em&gt; world $i$ &lt;em&gt;at&lt;/em&gt; world $j$. For this expected chance to equal the chance of world $i$ at world $j$, it must be that $\C \C = \C$. More succinctly, $\C^2 = \C$.&lt;/p&gt;

&lt;p&gt;Matrices that have this property&amp;mdash;squaring them leaves them unchanged&amp;mdash;are called &lt;em&gt;idempotent&lt;/em&gt;. And when our matrices are column stochastic (all values are nonnegative and each column sums to $1$), idempotence is a very&amp;hellip; well, potent requirement.&lt;/p&gt;

&lt;p&gt;For example, our first chance matrix based on Laplace&amp;rsquo;s rule of succession is not idempotent. Its square is not itself, but something quite different. Our second, Carnapian matrix is idempotent though. Its square is just itself. And that&amp;rsquo;s not a coincidence.&lt;/p&gt;

&lt;h1 id=&#34;self-certainty&#34;&gt;Self Certainty&lt;/h1&gt;

&lt;p&gt;Any chance matrix whose columns are redundant will be idempotent. After all, if the chances are the same &lt;em&gt;at&lt;/em&gt; every world, the expected value &lt;em&gt;of&lt;/em&gt; any world is always the same. So its expected value just is the value it has at every world.&lt;/p&gt;

&lt;p&gt;But redundant columns also mean that the chances are &lt;em&gt;self certain&lt;/em&gt;. Each world&amp;rsquo;s chance assignment gives zero probability to the chances being anything other than what they are at that world. Because there &lt;em&gt;are&lt;/em&gt; no worlds where the chances are different.&lt;/p&gt;

&lt;p&gt;The chances can vary from world to world and still be self-expecting though. There are idempotent chance matrices where the columns are not simply redundant. For example, here&amp;rsquo;s another idempotent chance matrix:
$$
\left(
    \begin{matrix}
        1/3 &amp;amp; 1/3 &amp;amp; 0      &amp;amp;    0\\&lt;br /&gt;
        2/3 &amp;amp; 2/3 &amp;amp; 0      &amp;amp;    0\\&lt;br /&gt;
            0 &amp;amp;   0 &amp;amp; 1/ 4 &amp;amp; 1/ 4\\&lt;br /&gt;
            0 &amp;amp;   0 &amp;amp; 3/ 4 &amp;amp; 3/ 4
    \end{matrix}
\right).
$$
But notice how it&amp;rsquo;s still kind of a degenerate case. There are two, disjoint regions of modal space here that regard one another as zero-chance. And within each region the chances are the same at each world. Worlds $1$ and $2$ have the same chances, and they give zero chance to worlds $3$ and $4$. And vice versa from the point of view of worlds $3$ and $4$.&lt;/p&gt;

&lt;p&gt;In other words, self-expectation and self-certainty go hand in hand here once again.&lt;/p&gt;

&lt;h1 id=&#34;a-sliver-of-daylight&#34;&gt;A Sliver of Daylight&lt;/h1&gt;

&lt;p&gt;Is there any daylight at all then between self-expectation and self-certainty?&lt;/p&gt;

&lt;p&gt;Self-certainty entails self-expectation, and the argument is pretty short. If the only worlds with positive chance according to world $j$ assign the same chances as world $j$ does, then any average of those chances will just be those same chances.&lt;/p&gt;

&lt;p&gt;But self-expectation doesn&amp;rsquo;t &lt;em&gt;quite&lt;/em&gt; entail self-certainty. For example, here&amp;rsquo;s an idempotent chance matrix that&amp;rsquo;s not self-certain:
$$
\left(
    \begin{matrix}
        1/3 &amp;amp; 1/3 &amp;amp; 0      &amp;amp;    0 &amp;amp; 25/94\\&lt;br /&gt;
        2/3 &amp;amp; 2/3 &amp;amp; 0      &amp;amp;    0 &amp;amp; 25/47\\&lt;br /&gt;
            0 &amp;amp;   0 &amp;amp; 1/ 4 &amp;amp; 1/ 4 &amp;amp; 19/376\\&lt;br /&gt;
            0 &amp;amp;   0 &amp;amp; 3/ 4 &amp;amp; 3/ 4 &amp;amp; 57/376\\&lt;br /&gt;
            0 &amp;amp;   0 &amp;amp;    0 &amp;amp;    0 &amp;amp; 0
    \end{matrix}
\right).
$$
It&amp;rsquo;s kind of a lame counterexample though, because the new, fifth world we&amp;rsquo;ve introduced (the coin explodes or something idk) has zero chance at every world, even itself.&lt;/p&gt;

&lt;p&gt;In fact this is what Samet proves: this is the only kind of counterexample possible! If probabilities are self-expecting, then they must be either self-certain or self-effacing. They must assign zero chance to the chances being otherwise, or they must assign chance one to them being otherwise.&lt;/p&gt;

&lt;p&gt;In terms of matrices, there are only three kinds of idempotent chance matrix:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;All columns are identical.&lt;/li&gt;
&lt;li&gt;The matrix is &lt;a href=&#34;https://en.wikipedia.org/wiki/Block_matrix#Block_diagonal_matrices&#34; target=&#34;_blank&#34;&gt;block diagonal&lt;/a&gt;, with identical columns inside each block.&lt;/li&gt;
&lt;li&gt;The matrix is as in (2), except for some columns $j_1, \ldots, j_n$. But the corresponding rows $j_1, \ldots, j_n$ contain only zeros.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Strictly speaking (1) is actually a special case of (2). But (1) deserves direct attention because it arises in a way that&amp;rsquo;s interesting both philosophically and mathematically.&lt;/p&gt;

&lt;h1 id=&#34;the-connected-case&#34;&gt;The Connected Case&lt;/h1&gt;

&lt;p&gt;Here&amp;rsquo;s a natural thought, one that&amp;rsquo;s driven a lot of the literature on chance and Lewis&amp;rsquo; Principal Principle. The thought: however events unfold at one world, there&amp;rsquo;s a chance they could have evolved differently. There&amp;rsquo;s even some small, non-zero chance they could have evolved quite differently.&lt;/p&gt;

&lt;p&gt;Taking this thought a bit further, you might think there&amp;rsquo;s a region of modal space where, even though worlds $w_1$ and $w_n$ have different chances, $w_n$ is always reachable from world $w_1$. More exactly, there&amp;rsquo;s always a connecting sequence of worlds $w_1, w_2, \ldots, w_n$ where $w_i$ gives non-zero chance to $w_{i+1}$.&lt;/p&gt;

&lt;p&gt;In terms of coin tosses, maybe it&amp;rsquo;s a law of nature that all coins land heads when all hundred out of one hundred flips land heads. But when there&amp;rsquo;s a mix of heads and tails, there&amp;rsquo;s at least some chance the mix could have had a few more heads, or a few more tails. So every world where the sequence isn&amp;rsquo;t perfectly uniform can be reached from every other. If not in a single, positive-chance hop, then at least by a series of hops, perhaps by switching the outcomes of the flips one at a time for example.&lt;/p&gt;

&lt;p&gt;In terms of graphs, such a region of modal space is said to be &lt;em&gt;connected&lt;/em&gt;. In terms of matrices, it amounts to the chance matrix for this region being &lt;em&gt;regular&lt;/em&gt;: there must be some power $n$ such that $\C^n$ contains all positive entries.&lt;/p&gt;

&lt;p&gt;Now, regular matrices have the remarkable property that, as we multiply them against themselves more and more times, the result converges to a matrix $\mathbf{P}$ whose columns are all identical:
$$ \lim_{n \rightarrow \infty} \C^n = \mathbf{P} =
\left(
    \begin{matrix}
        p_1    &amp;amp; \ldots &amp;amp; p_1    \\&lt;br /&gt;
        \vdots &amp;amp; \ldots &amp;amp; \vdots \\&lt;br /&gt;
        p_k    &amp;amp; \ldots &amp;amp; p_k    \\&lt;br /&gt;
    \end{matrix}
\right).
$$
Now recall that for $\C$ to be self-expecting, it must be idempotent, meaning $\C^2 = \C$. But that means $\C^n = \C$ for any power $n$. But then $\C = \mathbf{P}$, so $\C$ must already have redundant columns.&lt;/p&gt;

&lt;p&gt;What does this mean for us? One way to think about it: there isn&amp;rsquo;t as much room for chances to vary from world to world as one might have thought. If the chances are going to be self-expecting, they must be the same at every world across a whole region of modal space despite the facts turning out quite differently at various worlds across that region.&lt;/p&gt;

&lt;p&gt;This point is strongly reminiscent of David Lewis&amp;rsquo; famous &amp;ldquo;Big Bad Bug&amp;rdquo; of course. And there&amp;rsquo;s tons of relevant literature, most of which I confess I never really absorbed. So I&amp;rsquo;ll close by linking to just one paper I&amp;rsquo;m finding especially helpful on this right now, Richard Pettigrew&amp;rsquo;s &lt;a href=&#34;https://drive.google.com/file/d/0B-Gzj6gcSXKrcW5MeUhIN2Jsd1k/view&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;What Chance-Credence Norms Should Not Be&amp;rdquo;&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Call for Papers: Formal Epistemology Workshop (FEW) 2018</title>
      <link>http://jonathanweisberg.org/post/CFP%20FEW%202018/</link>
      <pubDate>Thu, 21 Dec 2017 10:36:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/CFP%20FEW%202018/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Location:&lt;/strong&gt; University of Toronto&lt;br /&gt;
&lt;strong&gt;Dates:&lt;/strong&gt; June 12–14, 2018&lt;br /&gt;
&lt;strong&gt;Keynote Speakers:&lt;/strong&gt; &lt;a href=&#34;http://www.larabuchak.net/&#34; target=&#34;_blank&#34;&gt;Lara Buchak&lt;/a&gt; and &lt;a href=&#34;https://sites.google.com/site/michaeltitelbaum/&#34; target=&#34;_blank&#34;&gt;Mike Titelbaum&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Submission Deadline:&lt;/strong&gt; February 12, 2018&lt;br /&gt;
&lt;strong&gt;Authors Notified:&lt;/strong&gt; March 31, 2018&lt;/p&gt;

&lt;p&gt;We are pleased to invite papers in formal epistemology, broadly construed to include related areas of philosophy as well as cognate disciplines like statistics, psychology, economics, computer science, and mathematics.&lt;/p&gt;

&lt;p&gt;Submissions should be:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;prepared for anonymous review,&lt;/li&gt;
&lt;li&gt;no more than 6,000 words,&lt;/li&gt;
&lt;li&gt;accompanied by an abstract of up to 300 words, and&lt;/li&gt;
&lt;li&gt;in PDF format.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Submission is via the &lt;a href=&#34;https://easychair.org/conferences/?conf=few2018&#34; target=&#34;_blank&#34;&gt;EasyChair website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The final selection of the program will be made with an eye to diversity. We especially encourage submissions from PhD candidates, early career researchers, and members of groups underrepresented in academic philosophy.&lt;/p&gt;

&lt;p&gt;Some funds are available to reimburse speakers&amp;rsquo; travel expenses. The available amounts are still being determined, but we hope to cover most/all expenses for student and early career speakers. Childcare can also be arranged.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;http://jonathanweisberg.org/few2018&#34; target=&#34;_blank&#34;&gt;conference website is here&lt;/a&gt;. The contact address is &lt;a href=&#34;mailto:few2018toronto@gmail.com&#34; target=&#34;_blank&#34;&gt;few2018toronto@gmail.com&lt;/a&gt;. The local organizers are &lt;a href=&#34;http://www.davidjamesbar.net/&#34; target=&#34;_blank&#34;&gt;David James Barnett&lt;/a&gt;, &lt;a href=&#34;http://individual.utoronto.ca/jnagel/Home_Page.html&#34; target=&#34;_blank&#34;&gt;Jennifer Nagel&lt;/a&gt;, and &lt;a href=&#34;http://jonathanweisberg.org/&#34; target=&#34;_blank&#34;&gt;Jonathan Weisberg&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>REU Redux: Allais All Over Again</title>
      <link>http://jonathanweisberg.org/post/REU%20Redeux/</link>
      <pubDate>Tue, 26 Sep 2017 20:24:04 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/REU%20Redeux/</guid>
      <description>

&lt;p&gt;&lt;em&gt;This post is coauthored with &lt;a href=&#34;http://johannathoma.com/&#34; target=&#34;_blank&#34;&gt;Johanna Thoma&lt;/a&gt; and cross-posted at &lt;a href=&#34;https://choiceinference.wordpress.com/&#34; target=&#34;_blank&#34;&gt;Choice &amp;amp; Inference&lt;/a&gt;. Accompanying Mathematica code is available on &lt;a href=&#34;https://github.com/jweisber/reu&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Lara Buchak&amp;rsquo;s &lt;a href=&#34;http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199672165.001.0001/acprof-9780199672165&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt;&lt;/a&gt; advertises REU theory as able to recover the modal preferences in the Allais paradox. In &lt;a href=&#34;https://link.springer.com/content/pdf/10.1007%2Fs11098-017-0916-3.pdf&#34; target=&#34;_blank&#34;&gt;our commentary&lt;/a&gt; we challenged this claim. We pointed out that REU theory is strictly &lt;a href=&#34;https://johannathoma.files.wordpress.com/2015/08/decision-theory-open-handbook-edit.pdf#page=11&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;grand-world&amp;rdquo;&lt;/a&gt;, and in the grand-world setting it actually struggles with the Allais preferences.&lt;/p&gt;

&lt;p&gt;To demonstrate, we constructed a grand-world model of the Allais problem. We replaced each small-world outcome with a normal distribution whose mean matches its utility, and whose height corresponds to its probability.&lt;/p&gt;

&lt;p&gt;Take for example the Allais gamble:
$$(\$0, .01; \$1M, .89; \$5M, .1).$$
If we adopt &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt;&amp;rsquo;s utility assignments:
$$u(\$0) = 0, u(\$1M) = 1, u(\$5M) = 2,$$
we can depict the small-world version of this gamble:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reu_redeux/fig1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;On our grand-world model this becomes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reu_redeux/fig2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And REU theory fails to predict the usual Allais preferences on this model, provided the normal distributions used are minimally spread out.&lt;/p&gt;

&lt;p&gt;If we squeeze the normal distributions tight enough, the grand-world problem collapses into the small-world problem, and REU theory can recover the Allais preferences. But, we showed, they&amp;rsquo;d have to be squeezed absurdly tight. A small standard deviation like $\sigma = .1$ lets REU theory recover the Allais preferences.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; But it also requires outlandish certainty that a windfall of $\$$1M will lead to a better life than the one you&amp;rsquo;d expect to lead without it. The probability of a life of utility at most 0, despite winning $\$$1M, would have to be smaller than $1 \times 10^{-23}$.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; Yet the chances are massively greater than that of suffering life-ruining tragedy (illness, financial ruin&amp;hellip; &lt;em&gt;Game of Thrones&lt;/em&gt; ending happily ever after, etc.).&lt;/p&gt;

&lt;p&gt;In response Buchak offers &lt;a href=&#34;https://link.springer.com/content/pdf/10.1007%2Fs11098-017-0907-4.pdf&#34; target=&#34;_blank&#34;&gt;two replies&lt;/a&gt;. The first is a technical maneuver, adjusting the model parameters. The second is more philosophical, adjusting the target interpretation of the Allais paradox instead.&lt;/p&gt;

&lt;h1 id=&#34;first-reply&#34;&gt;First Reply&lt;/h1&gt;

&lt;p&gt;Buchak&amp;rsquo;s first reply tweaks our model in two ways. First, the mean utility of winning $\$$5M is shifted from 2 down to 1.3. Second, all normal distributions are skewed by a factor of 5 (positive 5 for utility 0, negative otherwise). So, for example, the Allais gamble pictured above becomes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reu_redeux/fig3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll focus on the second tweak here, the introduction of skew. It rests on a technical error, as we&amp;rsquo;ll show momentarily. But it also wants for motivation.&lt;/p&gt;

&lt;h2 id=&#34;motivational-problems&#34;&gt;Motivational Problems&lt;/h2&gt;

&lt;p&gt;Why should the grand-world model be skewed? And why in this particular way? Buchak writes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&amp;hellip;] receiving $\$$1M makes the worst possibilities much less likely. Receiving $\$$1M provides security in the sense of making the probability associated with lower utility values smaller and smaller. The utility of $\$$1M is concentrated around a high mean with a long tail to the left: things likely will be great, though there is some small and diminishing chance they will be fine but not great. Similarly, the utility of $\$$0 is concentrated around a low mean with a long tail to the right: things likely will be fine but not great, though there is some small and diminishing chance they will be great. In other words, $\$$1M (and $\$$5M) is a gamble with negative skew, and $\$$0 is a gamble with positive skew &lt;a href=&#34;p. 2401&#34; target=&#34;_blank&#34;&gt;&amp;hellip;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But this passage never actually identifies any asymmetry in the phenomena we&amp;rsquo;re modeling. True, &amp;ldquo;receiving $\$$1M makes the worst possibilities much less likely&amp;rdquo;, but it also makes the best possibilities much more likely. Likewise,  &amp;ldquo;[r]eceiving $\$$1M provides security in the sense of making the probability associated with lower utility values smaller and smaller.&amp;rdquo; But $\$$1M also makes the probability associated with higher utility values larger. And so on.&lt;/p&gt;

&lt;p&gt;The tendencies of large winnings to control bad outcomes and promote good outcomes was already captured in the original model. A normal distribution centered on utility 1 already admits &amp;ldquo;some small and diminishing chance that [things] will be fine but not great.&amp;rdquo; It just also admits some small chance that things will be much better than great, since it&amp;rsquo;s symmetric around utility 1. To motivate the skewed model, we&amp;rsquo;d need some reason to think this symmetry should not hold. But none has been given.&lt;/p&gt;

&lt;h2 id=&#34;technical-difficulties&#34;&gt;Technical Difficulties&lt;/h2&gt;

&lt;p&gt;Motivation aside, there is a technical fault in the skewed model.&lt;/p&gt;

&lt;p&gt;Introducing skew is supposed to make room for a reasonably large standard deviation while still recovering the Allais preferences. Buchak advertises a standard deviation&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; of $\sigma = .17$ for the skewed model, but the true value is actually $.106$&amp;mdash;essentially the same as the $.1$ value Buchak concedes is implausibly small, and seeks to avoid by introducing skew.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Where does the $.17$ figure come from then? It&amp;rsquo;s the &lt;a href=&#34;https://en.wikipedia.org/wiki/Scale_parameter&#34; target=&#34;_blank&#34;&gt;scale parameter&lt;/a&gt; of the skew normal distribution, often denoted $\omega$. For an ordinary normal distribution, the scale $\omega$ famously coincides with the standard deviation $\sigma$, and so we write $\sigma$ for both. But when we skew a normal distribution, we tighten it, shrinking the standard deviation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reu_redeux/fig4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The distributions in this figure share the same scale parameter ($.17$) but the skewed one (yellow) is much narrower.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, &lt;em&gt;Mathematica&lt;/em&gt; uses $\sigma$ for the scale parameter even in skewed normal distributions, giving the misleading impression that it&amp;rsquo;s still the standard deviation.&lt;/p&gt;

&lt;p&gt;What really matters, of course, isn&amp;rsquo;t the value of the standard deviation itself, but the probabilities that result from whatever parameters we choose. And Buchak argues that her model avoids the implausible probabilities we cited in the introduction. How can this be?&lt;/p&gt;

&lt;p&gt;Buchak says that the skewed model has &amp;ldquo;more overlap in the utility that $\$$0 and $\$$1M might deliver&amp;rdquo;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&amp;hellip;] there is a 0.003 probability that the $\$$0 gamble will deliver more than 0.5 utils, and a 0.003 probability that the $\$$1M gamble will deliver less than 0.5 utils. (p. 2402)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But this &amp;ldquo;overlap&amp;rdquo; was never the problematic quantity. The problem was, rather, that a small standard deviation like $.1$ requires you to think it less than $1 \times 10^{-23}$ likely you will end up with a life no better than $0$ utils, despite a $\$$1M windfall.&lt;/p&gt;

&lt;p&gt;On Buchak&amp;rsquo;s model this probability is still absurdly small: $4 \times 10^{-9}$.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; This is a considerable improvement over $1 \times 10^{-23}$, but it&amp;rsquo;s still not plausible. For example, it&amp;rsquo;s almost $300,000$ times more likely that one author of this post (Jonathan Weisberg) will &lt;a href=&#34;http://www.statcan.gc.ca/pub/84-537-x/2013005/tbl/tbl7a-eng.htm&#34; target=&#34;_blank&#34;&gt;die in the coming year at the ripe old age of 39&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But worst of all, any improvement here comes at an impossible price: ludicrously low probabilities on the other side. For example, the probability that the life you&amp;rsquo;ll lead with $\$$1M will end up as good as the one you&amp;rsquo;d expect with $\$$5M is so small that &lt;em&gt;Mathematica&lt;/em&gt; can&amp;rsquo;t distinguish it from zero.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:7&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:7&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; So the problem is actually worse than before, not better.&lt;/p&gt;

&lt;h1 id=&#34;second-reply&#34;&gt;Second Reply&lt;/h1&gt;

&lt;p&gt;Buchak&amp;rsquo;s second reply is that it wouldn&amp;rsquo;t in fact be a problem if REU theory could only recover the Allais preferences in a small-world setting. We should think of the Allais problem as a thought experiment: it asks us to abstract away from anything but the immediate rewards mentioned in the problem, and to think of the monetary rewards as stand-ins for things that are valuable for their own sakes.&lt;/p&gt;

&lt;p&gt;What &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; showed, according to Buchak, is that REU theory can accommodate people&amp;rsquo;s intuitions regarding such a small-world thought experiment. And this is a success, because this establishes that the theory can accommodate a certain kind of reasoning that we all engage in. Buchak moreover concedes that it may well be a mistake for agents to think of the choices they actually face in small-world terms. But she claims this is no problem for her theory:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[I]f people &amp;lsquo;really&amp;rsquo; face the simple choices, then their reasoning is correct and REU captures it. If people &amp;lsquo;really&amp;rsquo; face the complex choices, then the reasoning in favor of their preferences is misapplied, and REU does not capture their preferences. Either way, the point still stands: REU-maximization rationalizes and formally reconstructs a certain kind of intuitive reasoning, as seen through REU theory&amp;rsquo;s ability to capture preferences over highly idealized gambles to which this reasoning is relevant. (p. 2403)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But there isn&amp;rsquo;t actually an &amp;lsquo;if&amp;rsquo; here. People do really face &amp;lsquo;complex&amp;rsquo; choices as we tried to model them. Any reward from an isolated gamble an agent faces in her life really should itself be thought of as a gamble. This is not only true when the potential reward is something like money, which is only a means to something else. Even if the good in question is &amp;lsquo;ultimate&amp;rsquo;, it just adds to the larger gamble of the agent&amp;rsquo;s life she is yet to face. She might win a beautiful holiday, but she will still face 20 micromorts per day for the rest of her life (&lt;a href=&#34;https://en.wikipedia.org/wiki/Micromort#Baseline&#34; target=&#34;_blank&#34;&gt;24 if she moves from Canada to England&lt;/a&gt;). Even on our deathbeds, we are unsure about how a lot of things we care about will play out. REU theory makes this background risk relevant to the evaluation of any individual gamble.&lt;/p&gt;

&lt;p&gt;So Buchak&amp;rsquo;s response really comes to this: REU theory captures a kind of intuitive reasoning that we employ in highly idealized decision contexts, but which would be misapplied in any actual decisions agents face in their lives. This raises two questions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Why should we care about accommodating reasoning in highly idealized decision contexts?&lt;/p&gt;

&lt;p&gt;The original project of &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; was to rationally accommodate the ordinary decision-maker. But now what we are rationally accommodating are at best her responses to thought experiments that are very far removed from her real life, namely thought experiments that ask her to imagine that she faces no other risk in her life. If our model is right, then REU theory still has to declare her irrational if she acts in real life as she would in the thought experiment&amp;mdash;as presumably ordinary decision-makers do. And then we haven&amp;rsquo;t done very much to rationally accommodate her. At best, we have provided an error theory to explain her ordinary behaviour: her mistake is to treat grand-world problems like small-world problems. This is, of course, a different project than the one &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; originally embarked on. As an error theory, REU theory will have to compete with other theories of choice under uncertainty that were never meant to be theories of rationality, such as prospect theory. Moreover, there is still another open question.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Why should agents have developed a knack for the reasoning displayed in the Allais problem if it is never actually rational to use it?&lt;/p&gt;

&lt;p&gt;As a heuristic to try and approximate the behaviour of a perfectly rational system, at least in the Allais example, agents would do better to maximize expected utility&amp;mdash;which is also easier to compute. Moreover, the burden of proof is on proponents of REU theory to show that there are any grand-world decisions commonly faced by real agents where REU theory comes to a significantly different assessment than expected utility theory. Unless they can show this, expected utility theory comes out as the better heuristic more generally. It is then quite mysterious what explains our supposed employment of REU-style reasoning. Why should irrational agents, who employ it more generally, have developed a bad heuristic? And why should rational agents, who never use it in real life, develop a tendency to employ it exclusively in highly idealized thought experiments?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Ultimately, if Buchak&amp;rsquo;s first reply fails, and all we can rely on is her second reply, &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; provides us with no reason to abandon expected utility theory as our best theory of rational choice under uncertainty in actual choice scenarios. Even if we grant that REU theory is a better theory of rational choice in hypothetical scenarios we never face, this is a much less exciting result than the one &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; advertised.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Though we need a slightly more severe risk function than that used in &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt;: $r(p) = p^{2.05}$ instead of $r(p) = p^2$. See our original commentary for details.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:2&#34;&gt;&lt;p&gt;To get this figure we calculate the cumulative density, at zero, of the normal distribution $𝒩(1,.1)$. Using &lt;em&gt;Mathematica&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;CDF[NormalDistribution[1, .1], 0]
7.61985 × 10^-24
&lt;/code&gt;&lt;/pre&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;This is the &amp;ldquo;variance&amp;rdquo; in Buchak&amp;rsquo;s terminology, but we&amp;rsquo;ll continue to use &amp;ldquo;standard deviation&amp;rdquo; here for consistency with our previous discussion and the preferred nomenclature.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:4&#34;&gt;&lt;p&gt;In &lt;em&gt;Mathematica&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;StandardDeviation[SkewNormalDistribution[1, .17, -5]]
0.105874
&lt;/code&gt;&lt;/pre&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;Skewing also shifts the mean, we should note.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:6&#34;&gt;&lt;p&gt;In &lt;em&gt;Mathematica&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;CDF[SkewNormalDistribution[1, .17, -5], 0]
4.04475 × 10^-9
&lt;/code&gt;&lt;/pre&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:7&#34;&gt;&lt;p&gt;Here we calculate the complement of the cumulative density, at $1.3$, of the skew normal distribution with location $1$, scale $.17$, and skew $-5$. In &lt;em&gt;Mathematica&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;1 - CDF[SkewNormalDistribution[1, .17, -5], 1.3]
0.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that &lt;em&gt;Mathematica&lt;/em&gt; can estimate this value at the nearby point $1.25$, which gives us an upper bound of about $7 \times 10^{-16}$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;1 - CDF[SkewNormalDistribution[1, .17, -5], 1.25]
6.66134 × 10^-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For comparison, this probability was about $.0013$ with no skew and $\sigma = .1$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;1 - CDF[NormalDistribution[1, .1], 1.3]
0.0013499
&lt;/code&gt;&lt;/pre&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:7&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Mosteller Hall Puzzle</title>
      <link>http://jonathanweisberg.org/post/Teaching%20Monty%20Hall/</link>
      <pubDate>Wed, 14 Jun 2017 15:21:42 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Teaching%20Monty%20Hall/</guid>
      <description>&lt;p&gt;One of my favourite probability puzzles to teach is a close cousin of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Monty_Hall_problem&#34; target=&#34;_blank&#34;&gt;Monty Hall problem&lt;/a&gt;. Originally from a 1965 &lt;a href=&#34;https://books.google.ca/books/about/Fifty_Challenging_Problems_in_Probabilit.html?id=QiuqPejnweEC&#34; target=&#34;_blank&#34;&gt;book by Frederick Mosteller&lt;/a&gt;,&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; here&amp;rsquo;s my formulation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Three prisoners, A, B, and C, are condemned to die in the morning. But the king decides in the night to pardon one of them. He makes his choice at random and communicates it to the guard, who is sworn to secrecy. She can only tell the prisoners that one of them will be released at dawn.&lt;/p&gt;

&lt;p&gt;Prisoner A welcomes the news, as he now has a 1/3 chance of survival. Hoping to go even further, he says to the guard, &amp;ldquo;I know you can&amp;rsquo;t tell me whether I am condemned or pardoned. But at least one other prisoner must still be condemned, so can you just name one who is?&amp;rdquo;. The guard replies (truthfully) that B is still condemned. &amp;ldquo;Ok&amp;rdquo;, says A, &amp;ldquo;then it&amp;rsquo;s either me or C who was pardoned. So my chance of survival has gone up to &amp;frac12;&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Unfortunately for A, he is mistaken. But how?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: turns out the puzzle isn&amp;rsquo;t originally due to Mosteller after all! It appears in &lt;a href=&#34;https://www.nature.com/scientificamerican/journal/v201/n4/pdf/scientificamerican1059-174.pdf&#34; target=&#34;_blank&#34;&gt;a 1959 article&lt;/a&gt; in &lt;em&gt;Scientific American&lt;/em&gt;, by Martin Gardner.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For me it&amp;rsquo;s really intuitive that A is mistaken. The way he figures things, his chance of survival will go up to &amp;frac12; whoever the guard names in her response. But then A doesn&amp;rsquo;t even have to bother the guard. He can just skip ahead to the conclusion that his chance of survival is &amp;frac12;. And that&amp;rsquo;s absurd.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s a bit harder to say exactly &lt;em&gt;where&lt;/em&gt; A goes wrong. But I&amp;rsquo;ve always taken this puzzle to be, like Monty Hall, a lesson in Carnap&amp;rsquo;s TER: the Total Evidence Requirement.&lt;/p&gt;

&lt;p&gt;What A learns isn&amp;rsquo;t only that B is condemned, but also that the guard reports as much. And this report is more likely if C was pardoned than if A was. If C was pardoned, the guard had to name B, the only other prisoner still condemned. Whereas if A was pardoned, the guard could just as easily have named C instead.&lt;/p&gt;

&lt;p&gt;So when the guard names B, her report fits twice as well with the hypothesis that C was pardoned, not A:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/misc/mosteller_tree_diagram.png&#34; alt=&#34;Tree diagram&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Thus A&amp;rsquo;s chance of being condemned remains twice that of being pardoned.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re like me, this reasoning will actually be less intuitive than the initial, gut feeling that A must be mistaken (because her logic would make it unnecessary to consult the guard). The argument is still instructive though, for several reasons:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;It shows how the initial, gut feeling is consistent with the probability axioms. We&amp;rsquo;ve constructed a plausible probability model that vindicates it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Total Evidence Requirement makes the difference in this model. Learning merely that B is condemned would have a different effect in this model. A&amp;rsquo;s chance of survival really would go up to &amp;frac12; then.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;These lessons can be carried over to Monty Hall. The same model yields the correct solution there, with the TER playing out in a parallel way.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And that last point is the real point of this post. As my colleague &lt;a href=&#34;http://www.sergiotenenbaum.org/&#34; target=&#34;_blank&#34;&gt;Sergio Tenenbaum&lt;/a&gt; pointed out in conversation, it means you can use Mosteller&amp;rsquo;s puzzle to teach Monty Hall. Because, unlike in Monty Hall, &lt;em&gt;the intuitive judgment is the correct one in Mosteller&amp;rsquo;s puzzle&lt;/em&gt;. So you can use it to get students on board with the less intuitive (but entirely correct) argument we used to resolve Mosteller&amp;rsquo;s puzzle.&lt;/p&gt;

&lt;p&gt;Once students have seen how important it is to set up the probability model correctly, so that the Total Evidence Requirement can do its work, they may be more comfortable using the same technique on Monty Hall.&lt;/p&gt;

&lt;p&gt;There are other ways of bringing students around to the correct solution to Monty Hall, of course. You can run them through a variant with a hundred doors instead of three; you can invite them to consider what would happen in the long run in repeated games; you can ask them how things would have been different had Monty opened the other door instead.&lt;/p&gt;

&lt;p&gt;These are all worthy heuristics. And I expect different ones will click for different students.&lt;/p&gt;

&lt;p&gt;But for my money, there&amp;rsquo;s nothing like a simple and concrete model to help me get oriented and shake off that befuddled feeling. And, in this case, Mosteller&amp;rsquo;s puzzle helps make the model more intuitive, hence more memorable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://68.media.tumblr.com/776dfc1f8b3baa0309b41c6a90ea1a13/tumblr_nd53ozBNz81qj0u7fo1_r1_400.gif&#34; alt=&#34;Fainting Goat&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;So I think it actually predates Monty Hall, though I gather this general family of puzzles goes back at least to 1889 and &lt;a href=&#34;https://en.wikipedia.org/wiki/Bertrand%27s_box_paradox&#34; target=&#34;_blank&#34;&gt;Bertrand&amp;rsquo;s box paradox&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 7: Dominance</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%207%20-%20Brier%20Dominance/</link>
      <pubDate>Wed, 07 Jun 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%207%20-%20Brier%20Dominance/</guid>
      <description>

&lt;p&gt;In our &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 5 - Convexity/&#34;&gt;last&lt;/a&gt; &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 6 - Obtusity/&#34;&gt;two&lt;/a&gt; posts we established two key facts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The set of possible probability assignments is convex.&lt;/li&gt;
&lt;li&gt;Convex sets are &amp;ldquo;obtuse&amp;rdquo;. Given a point outside a convex set, there&amp;rsquo;s a point inside that forms a right-or-obtuse angle with any third point in the set.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Today we&amp;rsquo;re putting them together to get the central result of the accuracy framework, the Brier dominance theorem. We&amp;rsquo;ll show that a non-probabilistic credence assignment is always &amp;ldquo;Brier dominated&amp;rdquo; by some probabilistic one. That is, there is always a probabilistic assignment that is closer, in terms of Brier distance, to every possible truth-value assignment.&lt;/p&gt;

&lt;p&gt;In fact we&amp;rsquo;ll show something a bit more general. We&amp;rsquo;ll show that there&amp;rsquo;s a probability assignment that&amp;rsquo;s closer to all the possible &lt;em&gt;probability&lt;/em&gt; assignments. But truth-value assignments are probability assignments, just extreme ones. So the result we really want follows straight away as a special case.$
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\x}{\vec{x}}
\newcommand{\y}{\vec{y}}
\newcommand{\z}{\vec{z}}
\newcommand{\v}{\vec{v}}
\newcommand{\p}{\vec{p}}
\newcommand{\q}{\vec{q}}
\newcommand{\B}{B}
\newcommand{\R}{\mathbb{R}}
\newcommand{\EIpq}{EI_{\p}(\q)}\newcommand{\EIpp}{EI_{\p}(\p)}
$&lt;/p&gt;

&lt;h1 id=&#34;recap&#34;&gt;Recap&lt;/h1&gt;

&lt;p&gt;For reference, let&amp;rsquo;s collect our notation, terminology, and previous results, so that we have everything in one place.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re using $n$ for the number of possibilities under consideration. And we use bold letters like $\x$ and $\p$ to represent $n$-tuples of real numbers. So $\p = (p_1, \ldots, p_n)$ is a point in $n$-dimensional space: a member of $\R^n$.&lt;/p&gt;

&lt;p&gt;We call $\p$ a &lt;em&gt;probability assignment&lt;/em&gt; if its coordinates are (a) all nonnegative, and (b) they sum to $1$. And we write $P$ for the set of all probability assignments.&lt;/p&gt;

&lt;p&gt;We call $\v$ a &lt;em&gt;truth-value assignment&lt;/em&gt; if its coordinates are all zeros except for a single $1$. And we write $V$ for the set of all truth-value assignments.&lt;/p&gt;

&lt;p&gt;A point $\y$ is a &lt;em&gt;mixture&lt;/em&gt; of the points $\x_1, \ldots, \x_n$ if there are real numbers $\lambda_1, \ldots, \lambda_n$ such that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\lambda_i \geq 0$ for all $i$,&lt;/li&gt;
&lt;li&gt;$\lambda_1 + \ldots + \lambda_n = 1$, and&lt;/li&gt;
&lt;li&gt;$\y = \lambda_1 \x_1 + \ldots + \lambda_n \x_n$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We say that a set is &lt;em&gt;convex&lt;/em&gt; if it is closed under mixing, i.e. any mixture of elements in the set is also in the set.&lt;/p&gt;

&lt;p&gt;The difference between two points, $\x - \y$, is defined coordinate-wise:
  $$ \x - \y = (x_1 - y_1, \ldots, x_n - y_n). $$
The &lt;em&gt;dot product&lt;/em&gt; of two points $\x$ and $\y$ is written $\x \cdot \y$, and is defined:
  $$ \x \cdot \y = x_1 y_1 + \ldots + x_n y_n. $$
As a reminder, the dot product returns a single, real number (not another $n$-dimensional point as one might expect). And the sign of the dot product reflects the angle between $\x$ and $\y$ when viewed as vectors/arrows. In particular, $\x \cdot \y \leq 0$ corresponds to a right-or-obtuse angle.&lt;/p&gt;

&lt;p&gt;Finally, $\B(\x,\y)$ is the Brier distance between $\x$ and $\y$, which can be defined:
  $$
  \begin{align}
    \B(\x,\y) &amp;amp;= (\x - \y)^2\\&lt;br /&gt;
              &amp;amp;= (\x - \y) \cdot (\x - \y).
  \end{align}
  $$&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s restate the two key theorems we&amp;rsquo;ll be relying on.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem (Convexity).&lt;/strong&gt;&amp;nbsp;
The set of probability functions $P$ is convex.&lt;/p&gt;

&lt;p&gt;We established this in &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 5 - Convexity/&#34;&gt;Part 5&lt;/a&gt; of this series. In particular, we showed that $P$ is the &amp;ldquo;convex hull&amp;rdquo; of $V$: the set of all mixtures of points in $V$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lemma (Obtusity).&lt;/strong&gt;&amp;nbsp;
If $S$ is convex, $\x \not \in S$, and $\y \in S$ minimizes $\B(\y,\x)$ as a function of $\y$ on the domain $S$, then for any $\z \in S$, $(\x - \y) \cdot (\z - \y) \leq 0$.&lt;/p&gt;

&lt;p&gt;The intuitive idea behind this lemma, which we proved last time in &lt;a href=&#34;(/post/Accuracy for Dummies - Part 6 - Obtusity/)&#34; target=&#34;_blank&#34;&gt;Part 6&lt;/a&gt;, can be illustrated with a diagram:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/ObtusityLemma3.png&#34; alt=&#34;&#34; /&gt;
Given a point outside a convex set, we can find a point inside (the closest point) that forms a right-or-obtuse angle with all other points in the set.&lt;/p&gt;

&lt;p&gt;What we&amp;rsquo;ll show next is the natural and intuitive consequence: that point $\y$ is thus closer to any point $\z$ of $S$ than $\x$ is.&lt;/p&gt;

&lt;h1 id=&#34;the-brier-dominance-theorem&#34;&gt;The Brier Dominance Theorem&lt;/h1&gt;

&lt;p&gt;Intuitively, we want to show that if the angle formed at point $\y$ with the points $\x$ and $\z$ is right-or-obtuse, then $\y$ must be closer to $\z$ than $\x$ is (in Brier distance).&lt;/p&gt;

&lt;p&gt;Formally, a right-or-obtuse angle corresponds to a dot product less than or equal to zero: $(\x - \y) \cdot (\z - \y) \leq 0$. But if $\x = \y$, then the dot product will be zero trivially. So the precise statement of our theorem is:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
If $(\x - \y) \cdot (\z - \y) \leq 0$ and $\x \neq \y$, then $\B(\x,\z) &amp;gt; \B(\y,\z)$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;  To start, we establish a general identity via algebra:
  $$
  \begin{align}
  \B(\x, \z) - \B(\x, \y) - \B(\y,\z)
    &amp;amp;= (\x - \z)^2 - (\x - \y)^2 - (\y - \z)^2\\&lt;br /&gt;
    &amp;amp;= -2\y^2 - 2 \x \cdot \z + 2 \x \cdot \y + 2 \y \cdot \z\\&lt;br /&gt;
    &amp;amp;= -2 (\x - \y) \cdot (\z - \y).
  \end{align}
  $$
Now suppose $ (\x - \y) \cdot (\z - \y) \leq 0$. Then, given the negative sign on the $-2$ in the established identity,
  $$ \B(\x, \z) - \B(\x, \y) - \B(\y,\z) \geq 0, $$
from which we derive
  $$ \B(\x, \z)  \geq \B(\x, \y) + \B(\y,\z). $$
Now, since $\x \neq \y$ by hypothesis, $\B(\x,\y) &amp;gt; 0$. Thus $\B(\x,\z) &amp;gt; \B(\y,\z)$, as desired.
&lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;It follows now that if $\x$ isn&amp;rsquo;t a probability assignment, there&amp;rsquo;s a probability assignment that&amp;rsquo;s closer to every truth-value assignment than $\x$ is.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Corollary (Brier Dominance).&lt;/strong&gt; If $\x \not \in P$ then there is a $\p \in P$ such that $\B(\p,\v) &amp;lt; \B(\x, \v)$ for all $\v \in V$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;  Fix $\x \not \in P$, and let $\p$ be the member of $P$ that minimizes $B(\y,\x)$ as a function of $\y$. The Convexity theorem tells us that $P$ is convex, so the Obtusity lemma implies $(\x - \p) \cdot (\v - \p) \leq 0$ for every $\v \in V$. And since $\x \neq \p$ (because $\x \not \in P$), the last theorem entails $\B(\p,\v) &amp;lt; \B(\x, \v)$, as desired.
&lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;This is the core of the main result we&amp;rsquo;ve been working towards. Hooray! But, we still have one piece of unfinished business. For what if $\p$ is itself dominated??&lt;/p&gt;

&lt;h1 id=&#34;undominated-dominance&#34;&gt;Undominated Dominance&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;ve shown that credences which violate the probability axioms are always &amp;ldquo;accuracy dominated&amp;rdquo; by some assignment of credences that obeys those axioms. But what if those dominating, probabilistic credences are themselves dominated? &lt;em&gt;What if they&amp;rsquo;re dominated by non-probabilistic credences??&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For all we&amp;rsquo;ve said, that&amp;rsquo;s a real possibility. And if it actually obtains, then there&amp;rsquo;s nothing especially accuracy-conducive about the laws of probability. So we had better rule this possibility out. Luckily, that&amp;rsquo;s pretty easy to do.&lt;/p&gt;

&lt;p&gt;In fact, the reals work here was already done back in &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 3/&#34;&gt;Part 3&lt;/a&gt; of the series. There we showed that Brier distance is a &amp;ldquo;proper&amp;rdquo; measure of inaccuracy: each probability assignment expects itself to do best with respect to accuracy, if inaccuracy is measured by Brier distance.&lt;/p&gt;

&lt;p&gt;As a reminder, we wrote $\EIpq$ for the expected inaccuracy of probability assignment $\q$ according to assignment $\p$. When inaccuracy is measured in terms of Brier distance:
$$ \EIpq = p_1 \B(\q,\v_1) + p_2 \B(\q,\v_2) + \ldots + p_n \B(\q,\v_n). $$
Here $\v_i$ is the truth-value assignment with a $1$ in the $i$-th coordinate, and $0$ everywhere else. What we showed in Part 3 was:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
$\EIpq$ is uniquely minimized when $\q = \p$.&lt;/p&gt;

&lt;p&gt;And notice, this would be impossible if there were some $\q$ such that $\B(\q,\v_i) \leq \B(\p,\v_i)$ for all $i$. For then the weighted average $\EIpq$ would have to be no larger than $\EIpp$. And this contradicts the theorem, which says that $\EIpq &amp;gt; \EIpp$ for all $\q \neq \p$.&lt;/p&gt;

&lt;p&gt;So, at long last, we have the full result we want:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Corollary (Undominated Brier Dominance).&lt;/strong&gt; If $\x \not \in P$ then there is a $\p \in P$ such that $\B(\p,\v) &amp;lt; \B(\x, \v)$ for all $\v \in V$. Moreover, there is no $\q \in P$ such that $\B(\q,\v) \leq \B(\p, \v)$ for all $\v \in V$.&lt;/p&gt;

&lt;p&gt;So the laws of probability really are specially conducive to accuracy, as measured using Brier distance. Only probabilistic credence assignments are undominated.&lt;/p&gt;

&lt;h1 id=&#34;where-to-next&#34;&gt;Where to Next?&lt;/h1&gt;

&lt;p&gt;That&amp;rsquo;s a pretty sweet result. And it raises plenty of fun and interesting questions we could look at next. Here are three:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;What about other ways of measuring inaccuracy besides Brier? Are there reasonable alternatives, and if so, do similar results apply to them?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What about other probabilistic principles, like Conditionalization, the Principal Principle, or the Principle of Indifference? Can we take this approach beyond the probability axioms?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Speaking of the probability axioms, we&amp;rsquo;ve been working with a pretty paired down conception of a &amp;ldquo;probability assignment&amp;rdquo;. Usually we assign probabilities not just to atomic possibilities, but to disjunctions/sets of possibilities: e.g. &amp;ldquo;the prize is behind either door #1 or door #2&amp;rdquo;. Can we extend this result to such &amp;ldquo;super-atomic&amp;rdquo; probability assignments?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We&amp;rsquo;ll tackle some or all of these questions in future posts. But I haven&amp;rsquo;t yet decided which ones or in what order.&lt;/p&gt;

&lt;p&gt;So for now let&amp;rsquo;s just stop and appreciate the work we&amp;rsquo;ve already done. Because not only have we proved one of the most central and interesting results of the accuracy framework. But also, in a lot of ways the hardest work is already behind us. If you&amp;rsquo;ve come this far, I think you deserve a nice pat on the back.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i1145.photobucket.com/albums/o503/KimmieRocks/tumblr_liqmv89ru51qb2dn6.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 6: Obtusity</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%206%20-%20Obtusity/</link>
      <pubDate>Wed, 24 May 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%206%20-%20Obtusity/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 5 - Convexity/&#34;&gt;Last time&lt;/a&gt; we saw that the set of probability assignments is &lt;em&gt;convex&lt;/em&gt;. Today we&amp;rsquo;re going to show that convex sets have a special sort of &amp;ldquo;obtuse&amp;rdquo; relationship with outsiders. Given a point &lt;em&gt;outside&lt;/em&gt; a convex set, there is always a point &lt;em&gt;in&lt;/em&gt; the set that forms a right-or-obtuse angle with it.&lt;/p&gt;

&lt;p&gt;Recall our 2D diagram from the first post. The convex set of interest here is the diagonal line segment from $(0,1)$ to $(1,0)$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For any point outside the diagonal, like $c^* $, there is a point like $c&amp;rsquo;$ on it that forms a right angle with all other points on the diagonal. As a result, $c&amp;rsquo;$ is closer to all other points on the diagonal than $c^* $ is. In particular, $c&amp;rsquo;$ is closer to both vertices, so it&amp;rsquo;s always more accurate than $c^*$. It&amp;rsquo;s &amp;ldquo;closer to the truth&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;The insider point $c&amp;rsquo;$ that we used in this case is the closest point on the diagonal to $c^*$. That&amp;rsquo;s what licenses the right-triangle reasoning here. Today we&amp;rsquo;re generalizing this strategy to $n$ dimensions.&lt;/p&gt;

&lt;p&gt;To do that, we need some tools for reasoning about $n$-dimensional geometry.$
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\x}{\vec{x}}
\newcommand{\y}{\vec{y}}
\newcommand{\z}{\vec{z}}
\newcommand{\B}{B}
$&lt;/p&gt;

&lt;h1 id=&#34;arithmetic-with-arrows&#34;&gt;Arithmetic with Arrows&lt;/h1&gt;

&lt;p&gt;You&amp;rsquo;re familiar with arithmetic in one dimension: adding, subtracting, and multiplying single numbers. What about points in $n$ dimensions?&lt;/p&gt;

&lt;p&gt;We introduced two ideas for arithmetic with points last time. We&amp;rsquo;ll add a few more today, and also talk about what they mean geometrically.&lt;/p&gt;

&lt;p&gt;Suppose you have two points $\x$ and $\y$ in $n$ dimensions:
  $$
  \begin{align}
    \x &amp;amp;= (x_1, \ldots, x_n),\\&lt;br /&gt;
    \y &amp;amp;= (y_1, \ldots, y_n).
  \end{align}
  $$
Their sum $\x + \y$, as we saw last time, is defined as follows:
  $$ \x + \y = (x_1 + y_1, \ldots, x_n + y_n). $$
In other words, points are added coordinate-wise.&lt;/p&gt;

&lt;p&gt;This definition has a natural, geometric meaning we didn&amp;rsquo;t mention last time. Start by thinking of $\x$ and $\y$ as &lt;em&gt;vectors&lt;/em&gt;&amp;mdash;as arrows pointing from the origin to the points $\x$ and $\y$. Then $\x + \y$ just amounts to putting the two arrows end-to-point and taking the point at the end:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorAddition.png&#34; alt=&#34;&#34; /&gt;
(Notice that we&amp;rsquo;re continuing our usual practice of bold letters for points/vectors like $\x$ and $\y$, and italics for single numbers like $x_1$ and $y_3$.)&lt;/p&gt;

&lt;p&gt;You can also multiply a vector $\x$ by a single number, $a$. The definition is once again coordinate-wise:
  $$ a \x = (a x_1, \ldots, a x_n). $$
And again there&amp;rsquo;s a natural, geometric meaning. We&amp;rsquo;ve lengthened the vector $\x$ by a factor of $a$.
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorMultiplication.png&#34; alt=&#34;&#34; /&gt;
Notice that if $a$ is between $0$ and $1$, then &amp;ldquo;lengthening&amp;rdquo; is actually shortening. For example, multiplying a vector by $a = 1/ 2$ makes it half as long.&lt;/p&gt;

&lt;p&gt;If $a$ is negative, then multiplying by $a$ reverses the direction of the arrow. For example, multiplying the northeasterly arrow $(1,1)$ by $-1$ yields the southwesterly arrow pointing to $(-1,-1)$.&lt;/p&gt;

&lt;p&gt;That means we can define subtraction in terms of addition and multiplication by negative one (just as with single numbers):
  $$
  \begin{align}
    \x - \y &amp;amp;= \x + (-1 \times \y)\\&lt;br /&gt;
            &amp;amp;= (x_1 - y_1, \ldots, x_n - y_n).
  \end{align}
  $$
So vector subtraction amounts to coordinate-wise subtraction.&lt;/p&gt;

&lt;p&gt;But what about multiplying two vectors? That&amp;rsquo;s actually different from what you might expect! We don&amp;rsquo;t just multiply coordinate-wise. We do that &lt;strong&gt;and then add up the results&lt;/strong&gt;:
  $$ \x \cdot \y = x_1 y_1 + \ldots + x_n y_n. $$
So the product of two vectors is &lt;strong&gt;not a vector&lt;/strong&gt;, but a number. That number is called the &lt;em&gt;dot product&lt;/em&gt;, $\x \cdot \y$.&lt;/p&gt;

&lt;p&gt;Why are dot products defined this way? Why do we add up the results of coordinate-wise multiplication to get a single number? Because it yields a more useful extension of the concept of multiplication from single numbers to vectors. We&amp;rsquo;ll see part of that in a moment, in the geometric meaning of the dot product.&lt;/p&gt;

&lt;p&gt;(There&amp;rsquo;s an algebraic side to the story too, having to do with the axioms that characterize the real numbers&amp;mdash;&lt;a href=&#34;https://en.wikipedia.org/wiki/Field_(mathematics)&#34; target=&#34;_blank&#34;&gt;the field axioms&lt;/a&gt;. We won&amp;rsquo;t go into that, but it comes out in &lt;a href=&#34;http://www.youtube.com/watch?v=63HpaUFEtXY&amp;amp;t=8m28s&#34; target=&#34;_blank&#34;&gt;this bit&lt;/a&gt; of a beautiful lecture by Francis Su, especially around &lt;a href=&#34;http://www.youtube.com/watch?v=63HpaUFEtXY&amp;amp;t=11m45s&#34; target=&#34;_blank&#34;&gt;the 11:45 mark&lt;/a&gt;.)&lt;/p&gt;

&lt;h1 id=&#34;signs-and-their-significance&#34;&gt;Signs and Their Significance&lt;/h1&gt;

&lt;p&gt;In two dimensions, a right angle has a special algebraic property: the dot-product of two arrows making the angle is always zero.&lt;/p&gt;

&lt;p&gt;Imagine a right triangle at the origin, with one leg going up to the point $(0,1)$ and the other leg going out to $(1,0)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorRightAngle.png&#34; alt=&#34;&#34; /&gt;
The dot product of those two vectors is $(1,0) \cdot (0,1) = 1 \times 0 + 0 \times 1 = 0$. One more example: consider the right angle formed by the vectors $(-3,3)$ and $(1,1)$.
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorRightAngle2.png&#34; alt=&#34;&#34; /&gt;
Again, the dot product is $(-3,3) \cdot (1,1) = -3 \times 1 + 3 \times 1 = 0.$&lt;/p&gt;

&lt;p&gt;Going a bit further: the dot product is always positive for acute angles, and negative for obtuse angles. Take the vectors $(5,0)$ and $(-1,1)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorObtuseAngle.png&#34; alt=&#34;&#34; /&gt;
Then we have $(5,0) \cdot (-1,1) = -5$. Whereas for $(5,0)$ and $(1,1)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorAcuteAngle.png&#34; alt=&#34;&#34; /&gt;
we find $(5,0) \cdot (1,1) = 5$.&lt;/p&gt;

&lt;p&gt;So the sign of the dot-product reflects the angle formed by the vectors $\x$ and $\y$:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;acute angle: $\x \cdot \y &amp;gt; 0$,&lt;/li&gt;
&lt;li&gt;right angle: $\x \cdot \y = 0$,&lt;/li&gt;
&lt;li&gt;obtuse angle: $\x \cdot \y &amp;lt; 0$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That&amp;rsquo;s going to be key in generalizing to $n$ dimensions, where reasoning with diagrams breaks down. But first, one last bit of groundwork.&lt;/p&gt;

&lt;h1 id=&#34;algebra-with-arrows&#34;&gt;Algebra with Arrows&lt;/h1&gt;

&lt;p&gt;You can check pretty easily that vector addition and multiplication behave a lot like ordinary addition and multiplication. The usual laws of commutativity, associativity, and distribution hold:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\x + \y = \y + \x$.&lt;/li&gt;
&lt;li&gt;$\x + (\y + \z) = (\x + \y) + \z$.&lt;/li&gt;
&lt;li&gt;$a ( \x + \y) = a\x + a\y$.&lt;/li&gt;
&lt;li&gt;$\x \cdot \y = \y \cdot \x$.&lt;/li&gt;
&lt;li&gt;$\x \cdot (\y + \z) = \x\y + \x\z$.&lt;/li&gt;
&lt;li&gt;$a (\x \cdot \y) = a \x \cdot \y = \x \cdot a \y$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One notable consequence, which we&amp;rsquo;ll use below, is the analogue of the familiar &lt;a href=&#34;https://en.wikipedia.org/wiki/FOIL_method&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;FOIL method&amp;rdquo;&lt;/a&gt; from high school algebra:
  $$
  \begin{align}
    (\x - \y)^2 &amp;amp;= (\x - \y) \cdot (\x - \y)\\&lt;br /&gt;
                &amp;amp;= \x^2 - 2 \x \cdot \y + \y^2.
  \end{align}
  $$
We&amp;rsquo;ll also make use of the fact that the Brier distance between $\x$ and $\y$ can be written $(\x - \y)^2$. Why?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s write $\B(\x,\y)$ for the Brier distance between points $\x$ and $\y$. Recall the definition of Brier distance, which is just the square of Euclidean distance:
  $$ \B(\x,\y) = (x_1 - y_1)^2 + (x_2 - y_2)^2 + \ldots + (x_n - y_n)^2. $$
Now consider that, thanks to our definition of vector subtraction:
  $$ \x - \y = (x_1 - y_1, x_2 - y_2, \ldots, x_n - y_n). $$
And thanks to the definition of the dot product:
  $$ (\x - \y) \cdot (\x - \y) = (x_1 - y_1)^2 + (x_2 - y_2)^2 + \ldots (x_n - y_n)^2. $$
So $\B(\x, \y) = (\x - \y) \cdot (\x - \y)$, in other words:
  $$ \B(\x, \y) = (\x - y)^2. $$&lt;/p&gt;

&lt;h1 id=&#34;a-cute-lemma&#34;&gt;A Cute Lemma&lt;/h1&gt;

&lt;p&gt;Now we can prove the lemma that&amp;rsquo;s the aim of this post. For the intuitive idea, picture a convex set $S$ in the plane, like a pentagon. Then choose an arbitrary point $\x$ outside that set:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/ObtusityLemma.png&#34; alt=&#34;&#34; /&gt;
Now trace a straight line from $\x$ to the closest point of the convex region, $\y$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/ObtusityLemma2.png&#34; alt=&#34;&#34; /&gt;
Finally, trace another straight line to any other point $\z$ of $S$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/ObtusityLemma3.png&#34; alt=&#34;&#34; /&gt;
No matter what point we choose for $\z$, the angle formed will either be right or obtuse. It cannot be acute.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lemma.&lt;/strong&gt; Let $S$ be a convex set of points in $\mathbb{R}^n$. Let $\x \not \in S$, and let $\y \in S$ minimize $\B(\y, \x)$ as a function of $\y$ on the domain $S$. Then for any $\z \in S$,
  $$ (\x - \y) \cdot (\z - \y) \leq 0. $$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s pause to understand what the Lemma is saying before we dive into the proof.&lt;/p&gt;

&lt;p&gt;Focus on the centered inequality. It&amp;rsquo;s about the vectors $\x - \y$ and $\z - \y$. These are the arrows pointing from $\y$ to $\x$, and from $\y$ to $\z$. So in terms of our original two dimensional diagram with the triangle:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34; alt=&#34;&#34; /&gt;
we&amp;rsquo;re looking at the angle between  $c^*$, $c&amp;rsquo;$, and any point on the diagonal you like&amp;hellip; which includes the ones we&amp;rsquo;re especially interested in, the vertices. What the lemma tells us is that this angle is always at least a right angle.&lt;/p&gt;

&lt;p&gt;Of course, it&amp;rsquo;s exactly a right angle in this case, not an obtuse one. That&amp;rsquo;s because our convex region is just the diagonal line. But the Lemma could also be applied to the whole triangular region in the diagram. That&amp;rsquo;s a convex set too. And if we took a point inside the triangle as our third point, the angle formed would be obtuse. (This is actually important if you want to generalize the dominance theorem beyond what we&amp;rsquo;ll prove next time. But for us it&amp;rsquo;s just a mathematical extra.)&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s prove the Lemma.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt; Because $S$ is convex and $\y$ and $\z$ are in $S$, any mixture of $\y$ and $\z$ must also be in $S$. That is, every point $\lambda \z + (1-\lambda) \y$ is in $S$, given $0 \leq \lambda \leq 1$.&lt;/p&gt;

&lt;p&gt;Notice that we can rewrite $\lambda \z + (1-\lambda) \y$ as follows:
  $$ \lambda \z + (1-\lambda) \y = \y + \lambda(\z - \y). $$
We&amp;rsquo;ll use this fact momentarily.&lt;/p&gt;

&lt;p&gt;Now, by hypothesis $\y$ is at least as close to $\x$ as any other point of $S$ is. So, in particular, $\y$ is at least as close to $\x$ as the mixtures of $\y$ and $\z$ are. Thus, for any given $\lambda \in [0,1]$:
  $$ \B(\y,\x) \leq \B(\lambda \z + (1-\lambda) \y, \x). $$
Using algebra, we can transform the right-hand side as follows:
  $$
  \begin{align}
    \B(\lambda \z + (1-\lambda) \y, \x) &amp;amp;= \B(\x, \lambda \z + (1-\lambda) \y)\\&lt;br /&gt;
      &amp;amp;= \B(\x, \y + \lambda(\z - \y))\\&lt;br /&gt;
      &amp;amp;= (\x - (\y + \lambda(\z - \y)))^2\\&lt;br /&gt;
      &amp;amp;= ((\x - \y) - \lambda(\z - \y))^2\\&lt;br /&gt;
      &amp;amp;= (\x - \y)^2 + \lambda^2(\z - \y)^2 - 2\lambda(\x - \y) \cdot (\z - \y)\\&lt;br /&gt;
      &amp;amp;= \B(\x,\y) + \lambda^2\B(\z,\y) - 2\lambda(\x - \y) \cdot (\z - \y).
  \end{align}
  $$
Combining this equation with the previous inequality, we have:
  $$ \B(\y,\x) \leq \B(\x,\y) + \lambda^2\B(\z,\y) - 2\lambda(\x - \y) \cdot (\z - \y). $$
And because $\B(\y, \x) = \B(\x, \y)$, this becomes:&lt;br /&gt;
  $$ 0 \leq \lambda^2\B(\z,\y) - 2\lambda(\x - \y) \cdot (\z - \y). $$
If we then restrict our attention to $\lambda &amp;gt; 0$, we can divide and rearrange terms to get:
  $$ (\x - \y) \cdot (\z - \y) \leq \frac{\lambda\B(\z,\y)}{2}. $$
And since this inequality holds no matter how small $\lambda$ is, it follows that
  $$ (\x - \y) \cdot (\z - \y) \leq 0, $$
as desired.
&lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;taking-stock&#34;&gt;Taking Stock&lt;/h1&gt;

&lt;p&gt;Here&amp;rsquo;s what we&amp;rsquo;ve got from this post and the last one:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Last time: the set of probability functions $P$ is convex.&lt;/li&gt;
&lt;li&gt;This time: given a point $\x$ outside $P$, there&amp;rsquo;s a point $\y$ inside $P$ that forms a right-or-obtuse angle with every other point $\z$ in $P$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Intuitively, it should follow that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\y$ is closer to every $\z$ in $P$ than $\x$ is.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And indeed, that&amp;rsquo;s what we&amp;rsquo;ll show in the next post!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 5: Convexity</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%205%20-%20Convexity/</link>
      <pubDate>Thu, 18 May 2017 10:35:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%205%20-%20Convexity/</guid>
      <description>

&lt;p&gt;In this and the next two posts we&amp;rsquo;ll establish the central theorem of the accuracy framework. We&amp;rsquo;ll show that the laws of probability are specially suited to the pursuit of accuracy, measured in Brier distance.&lt;/p&gt;

&lt;p&gt;We showed this for cases with two possible outcomes, like a coin toss,  way back in &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;the first post of this series&lt;/a&gt;. A simple, &lt;a href=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34;&gt;two-dimensional diagram&lt;/a&gt; was all we really needed for that argument. To see how the same idea extends to any number of dimensions, we need to generalize the key ingredients of that reasoning to $n$ dimensions.&lt;/p&gt;

&lt;p&gt;This post supplies the first ingredient: the convexity theorem.&lt;/p&gt;

&lt;h1 id=&#34;convex-shapes&#34;&gt;Convex Shapes&lt;/h1&gt;

&lt;p&gt;Convex shapes are central to the accuracy framework because, in a way, the laws of probability have a convex shape. Hopefully that mystical pronouncement will make sense by the end of this post.&lt;/p&gt;

&lt;p&gt;You probably know a convex shape when you see one. Circles, triangles, and octagons are convex; pentagrams and the state of Texas are not.&lt;/p&gt;

&lt;p&gt;But what makes a convex shape convex? Roughly: &lt;em&gt;it contains all its connecting lines&lt;/em&gt;. If you take any two points in a convex region and draw a line connecting them, the line will lie entirely inside that region.&lt;/p&gt;

&lt;p&gt;But on a non-convex figure, you can find points whose connecting line leaves the figure&amp;rsquo;s boundary:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/TexasLine.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We want to take this idea beyond two dimensions, though. And for that, we need  to generalize the idea of connecting lines. We need the concept of a &amp;ldquo;mixture&amp;rdquo;.&lt;/p&gt;

&lt;h2 id=&#34;pointy-arithmetic&#34;&gt;Pointy Arithmetic&lt;/h2&gt;

&lt;p&gt;In two dimensions it&amp;rsquo;s pretty easy to see that if you take some percentage of one point, and a complementary percentage of another point, you get a third point on the line between them.$
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\p}{\vec{p}}
\newcommand{\q}{\vec{q}}
\newcommand{\r}{\vec{r}}
\newcommand{\v}{\vec{v}}
\newcommand{\R}{\mathbb{R}}
$&lt;/p&gt;

&lt;p&gt;For example, if you take $1/ 2$ of $(0,0)$ and add it to $1/ 2$ of $(1,1)$, you get the point halfway between: $(1/ 2,1/ 2)$. That&amp;rsquo;s pretty intuitive geometrically:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Fig1.png&#34; alt=&#34;&#34; /&gt;
But we can capture the idea algebraically too:
$$
  \begin{align}
    1/ 2 \times (0,0) + 1/ 2 \times (1,1)
      &amp;amp;= (0,0) + (1/ 2, 1/ 2)\\&lt;br /&gt;
      &amp;amp;= (1/ 2, 1/ 2).
  \end{align}
$$&lt;/p&gt;

&lt;p&gt;Likewise, if you add $3/10$ of $(0,0)$ to $7/10$ of $(1, 1)$, you get the point seven-tenths of the way in between, namely $(7/10, 7/10)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Fig2.png&#34; alt=&#34;&#34; /&gt;
In algebraic terms:
$$
  \begin{align}
    3/10 \times (0,0) + 7/10 \times (1,1)
      &amp;amp;= (0,0) + (7/10, 7/10)\\&lt;br /&gt;
      &amp;amp;= (7/10, 7/10).
  \end{align}
$$&lt;/p&gt;

&lt;p&gt;Notice that we just introduced two rules for doing arithmetic with points. When multiplying a point $\p = (p_1, p_2)$ by a number $a$, we get:
$$ a \p = (a p_1, a p_2). $$
And when adding two points $\p = (p_1, p_2)$ and $\q = (q_1, q_2)$ together:
$$ \p + \q = (p_1 + q_1, p_2 + q_2). $$
In other words, multiplying a point by a single number works element-wise, and so does adding two points together.&lt;/p&gt;

&lt;p&gt;We can generalize these ideas straightforwardly to any number of dimensions $n$. Given points $\p = (p_1, p_2, \ldots, p_n)$ and $\q = (q_1, q_2, \ldots, q_n)$, we can define:
$$ a \p = (a p_1, a p_2, \ldots, a p_n), $$
and
$$ \p + \q = (p_1 + q_1, p_2 + q_2, \ldots, p_n + q_n).$$
We&amp;rsquo;ll talk more about arithmetic with points next time. For now, these two definitions will do.&lt;/p&gt;

&lt;h2 id=&#34;mixtures&#34;&gt;Mixtures&lt;/h2&gt;

&lt;p&gt;Now back to connecting lines between points. The idea is that the straight line between $\p$ and $\q$ is the set of points we get by &amp;ldquo;mixing&amp;rdquo; some portion of $\p$ with some portion of $\q$.&lt;/p&gt;

&lt;p&gt;We take some number $\lambda$ between $0$ and $1$, we multiply $\p$ by $\lambda$ and $\q$ by $1 - \lambda$, and we sum the results: $\lambda \p + (1-\lambda) \q$. The set of points you can obtain this way is the straight line between $\p$ and $\q$.&lt;/p&gt;

&lt;p&gt;In fact, you can mix any number of points together. Given $m$ points $\q_1, \ldots, \q_m$, we can define their &lt;em&gt;mixture&lt;/em&gt; as follows. Let $\lambda_1, \ldots \lambda_m$ be positive real numbers that sum to one. That is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\lambda_i \geq 0$ for all $i$, and&lt;/li&gt;
&lt;li&gt;$\lambda_1 + \lambda_2 + \ldots + \lambda_m = 1$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then we multiply each $\q_i$ by the corresponding $\lambda_i$ and sum up:
  $$ \p = \lambda_1 \q_1 + \ldots + \lambda_m \q_m. $$
The resulting point $\p$ is a &lt;em&gt;mixture&lt;/em&gt; of the $\q_i$&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;Now we can define the general notion of a &lt;em&gt;convex set&lt;/em&gt; of points. A convex set is one where the mixture of any points in the set is also contained in the set. (A convex set is &amp;ldquo;closed under mixing&amp;rdquo;, you might say.)&lt;/p&gt;

&lt;h1 id=&#34;convex-hulls&#34;&gt;Convex Hulls&lt;/h1&gt;

&lt;p&gt;It turns out that the set of possible probability assignments is convex.&lt;/p&gt;

&lt;p&gt;More than that, it&amp;rsquo;s the convex set generated by the possible truth-value assignments, in a certain way. It&amp;rsquo;s the &amp;ldquo;convex hull&amp;rdquo; of the possible truth-value assignments.&lt;/p&gt;

&lt;p&gt;What in the world is a &amp;ldquo;convex hull&amp;rdquo;?&lt;/p&gt;

&lt;p&gt;Imagine some points in the plane&amp;mdash;the corners of a square, for example. Now imagine stretching a rubber band around those points and letting it snap tight. The shape you get is the square with those points as corners. And the set of points enclosed by the rubber band is a convex set. Take any two points inside the square, or on its boundary, and draw the straight line between them. The line will not leave the square.&lt;/p&gt;

&lt;p&gt;Intuitively, the convex hull of a set of points in the plane is the set enclosed by the rubber band exercise. Formally, the convex hull of a set of points is the set of points that can be obtained from them as a mixture. (And this definition works in any number of dimensions.)&lt;/p&gt;

&lt;p&gt;For example, any of the points in our square example can be obtained by taking a mixture of the vertices. Take the center of the square: it&amp;rsquo;s halfway between the bottom left and top right corners. To get something to the left of that we can mix in some of the top left corner (and correspondingly less of the top right). And so on.&lt;/p&gt;

&lt;p&gt;Now imagine the rubber band exercise using the possible truth-value assignments, instead of the corners of a square. In two dimensions, those are the points $(0,1)$ and $(1,0)$. And when you let the band snap tight, you get the diagonal line connecting them. As we saw way back in &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;our first post&lt;/a&gt;, the points on that diagonal line are the possible probability assignments.&lt;/p&gt;

&lt;h1 id=&#34;peeking-ahead&#34;&gt;Peeking Ahead&lt;/h1&gt;

&lt;p&gt;We also saw that if you take any point &lt;em&gt;not&lt;/em&gt; on that diagonal, the closest point on the diagonal forms a right angle. That&amp;rsquo;s what lets us do some basic geometric reasoning to see that there&amp;rsquo;s a point on the line that&amp;rsquo;s closer to both vertices than the point off the line:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That fact about closest points and right angles is what&amp;rsquo;s going to enable us to generalize the argument beyond two dimensions. If you take any point not on a convex hull, there&amp;rsquo;s a point on the convex hull (namely the closest point) which forms a right (or obtuse) angle with the other points on the hull.&lt;/p&gt;

&lt;p&gt;Consider the three dimensional case. The possible truth-value assignments are $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Three Vertices.png&#34; alt=&#34;&#34; /&gt;
And when you let a rubber band snap tight around them, it encloses the triangular surface connecting them:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Three Vertices with Hull.png&#34; alt=&#34;&#34; /&gt;
That&amp;rsquo;s the set of probability assignments for three outcomes.&lt;/p&gt;

&lt;p&gt;Now take any point that&amp;rsquo;s not on that triangular surface. Drop a straight line to the closest point on the surface. Then draw another straight line from there to one of the triangle&amp;rsquo;s vertices. These two straight lines will form a right or obtuse angle. So the distance from the first, off-hull point to the vertex is further than the distance from the second, on-hull point to the vertex.&lt;/p&gt;

&lt;p&gt;Essentially the same reasoning works in any number of dimensions. But to make it work, we need to do three things.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Prove that the probability assignments always form a convex hull around the possible truth-value assignments.&lt;/li&gt;
&lt;li&gt;Prove that any point outside a convex hull forms a right angle (or an obtuse angle) with any point on the hull.&lt;/li&gt;
&lt;li&gt;Prove that the point off the hull is further from all the vertices than the closest point on the hull.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This post is dedicated to the first item.&lt;/p&gt;

&lt;h1 id=&#34;the-convexity-theorem&#34;&gt;The Convexity Theorem&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;re going to prove that the set of possible probability assignments is the same as the convex hull of the possible truth-value assignments. First let&amp;rsquo;s get some notation in place.&lt;/p&gt;

&lt;h2 id=&#34;notation&#34;&gt;Notation&lt;/h2&gt;

&lt;p&gt;As usual $n$ is the number of possible outcomes under consideration. So each possible truth-value assignment is a point of $n$ coordinates, with a single $1$ and $0$ everywhere else. For example, if $n = 4$ then $(0, 0, 1, 0)$ represents the case where the third possibility obtains.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll write $V$ for the set of all possible truth value assignments. And we&amp;rsquo;ll write $\v_1, \ldots, \v_n$ for the elements of $V$. The first element $\v_1$ has its $1$ in the first coordinate, $\v_2$ has its $1$ in the second coordinate, etc.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll use a superscript $^+$ for the convex hull of a set. So $V^+$ is the convex hull of $V$. It&amp;rsquo;s the set of all points that can be obtained by mixing members of $V$.&lt;/p&gt;

&lt;p&gt;Recall, a mixture is a point obtained by taking nonnegative real numbers $\lambda_1, \ldots, \lambda_n$ that sum to one, and multiplying each one against the corresponding $\v_i$ and then summing up:
  $$ \lambda_1 \v_1 + \lambda_2 \v_2 + \ldots + \lambda_n \v_n. $$
So $V^+$ is the set of all points that can be obtained by this method. Each choice of values $\lambda_1, \ldots, \lambda_n$ generates a member of $V^+$. (To exclude one of the $\v_i$&amp;rsquo;s from a mixture, just set $\lambda_i = 0$.)&lt;/p&gt;

&lt;p&gt;Finally, we&amp;rsquo;ll use $P$ for the set of all probability assignments. Recall: a probability assignment is a point of $n$ coordinates, where each coordinate is nonnegative, and all the coordinates together add up to one. That is, $\p = (p_1,\ldots,p_n)$ is a probability assignment just in case:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$p_i \geq 0$ for all $i$, and&lt;/li&gt;
&lt;li&gt;$p_1 + p_2 + \ldots + p_n = 1$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The set $P$ contains just those points $\p$ satisfying these two conditions.&lt;/p&gt;

&lt;h2 id=&#34;statement-and-proof&#34;&gt;Statement and Proof&lt;/h2&gt;

&lt;p&gt;In the notation just established, what we&amp;rsquo;re trying to show is that $V^+ = P$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; $V^+ = P$. That is, the convex hull of the possible truth-value assignments just is the set of possible probability assignments.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt; Let&amp;rsquo;s first show that $V^+ \subseteq P$.&lt;/p&gt;

&lt;p&gt;Notice that a truth-value assignment is also probability assignment. Its coordinates are always $1$ or $0$, so all coordinates are nonnegative. And since it has only a single coordinate with value $1$, its coordinates add up to $1$.&lt;/p&gt;

&lt;p&gt;But we have to show that any mixture of truth-value assignments is also a probability assignment. So let $\lambda_1, \ldots, \lambda_n$ be nonnegative numbers that sum to $1$. If we multiply $\lambda_i$ against a truth-value assignment $\v_i$, we get a point with $0$ in every coordinate except the $i$-th coordinate, which has value $\lambda_i$. For example, $\lambda_3 \times (0, 0, 1, 0) = (0, 0, \lambda_3, 0)$. So the mixture that results from $\lambda_1, \ldots, \lambda_n$ is:
  $$
    \lambda_1 \v_1 + \lambda_2 \v_2 + \ldots \lambda_n \v_n = (\lambda_1, \lambda_2, \ldots, \lambda_n).
  $$
And this mixture has coordinates that are all nonnegative and sum to $1$, by hypothesis. In other words, it is a probability assignment.&lt;/p&gt;

&lt;p&gt;So we turn to showing that $P \subseteq V^+$. In other words, we want to show that every probability assignment can be obtained as a mixture of the $\v_i$&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;So take an arbitrary probability assignment $\p \in P$, where $\p = (p_1, \ldots, p_n)$. Let the $\lambda_i$&amp;rsquo;s be the probabilities that $\p$ assigns to each $i$: $\lambda_1 = p_1$, $\lambda_2 = p_2$, and so on. Then, by the same logic as in the first part of the proof:
  $$ \lambda_1 \v_1 + \ldots + \lambda_n \v_n = (p_1, \ldots, p_n). $$
In other words, $\p$ is a mixture of the possible truth-value assignments, where the weights in the mixture are just the probability values assigned by $\p$. &lt;span style=&#34;float: right;&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;up-next&#34;&gt;Up Next&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;ve established the first of the three items listed earlier. Next time we&amp;rsquo;ll establish the second: given a point outside a convex set, there&amp;rsquo;s always a point inside that forms a right or obtuse angle with any other point of the set. Then we&amp;rsquo;ll be just a few lines of algebra from the main result: the Brier dominance theorem!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 4: Euclid in the Round</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%204/</link>
      <pubDate>Thu, 23 Feb 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%204/</guid>
      <description>

&lt;p&gt;Last time we took Brier distance beyond two dimensions. &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 3/&#34;&gt;We showed&lt;/a&gt; that it&amp;rsquo;s &amp;ldquo;proper&amp;rdquo; in any finite number of dimensions. Today we&amp;rsquo;ll show that Euclidean distance is &amp;ldquo;improper&amp;rdquo; in any finite number dimensions.&lt;/p&gt;

&lt;p&gt;When I first sat down to write this post, I had in mind a straightforward generalization of &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;our previous result&lt;/a&gt; for Euclidean distance in two dimensions. And I figured it would be easy to prove.&lt;/p&gt;

&lt;p&gt;Not so.&lt;/p&gt;

&lt;p&gt;My initial conjecture was false, and worse, when I asked my accuracy-guru friends for the truth, nobody seemed to know. (They did offer lots of helpful suggestions, though.)&lt;/p&gt;

&lt;p&gt;So today we&amp;rsquo;re muddling through on our own even more than usual. Here goes.&lt;/p&gt;

&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s recall where we are. We&amp;rsquo;ve been considering different ways of measuring the inaccuracy of a probability assignment given a possibility, or a &amp;ldquo;possible world&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start today by regimenting our terminology. We&amp;rsquo;ve used these terms semi-formally for a while now. But let&amp;rsquo;s gather them here for reference, and to make them a little more precise.$
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\p}{\vec{p}}
\newcommand{\q}{\vec{q}}
\newcommand{\u}{\vec{u}}
\newcommand{\EIpq}{EI_{\p}(\q)}
\newcommand{\EIpp}{EI_{\p}(\p)}
$&lt;/p&gt;

&lt;p&gt;Given a number of dimensions $n$:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A &lt;em&gt;probability assignment&lt;/em&gt; $\p = (p_1, \ldots, p_n)$ is a vector of positive real numbers that sum to $1$.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;possible world&lt;/em&gt; is a vector $\u$ of length $n$ containing all zeros except for a single $1$. (A &lt;a href=&#34;https://en.wikipedia.org/wiki/Unit_vector&#34; target=&#34;_blank&#34;&gt;unit vector&lt;/a&gt; of length $n$, in other words.)&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;measure of inaccuracy&lt;/em&gt; $D(\p, \u)$ is a function that takes a probability assignment and a possible world and returns a real number.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;rsquo;ve been considering two measures of inaccuracy. The first is the familiar Euclidean distance between $\p$ and $\u$. For example, when $\u = (1, 0, \ldots, 0)$ we have:
$$ \sqrt{(p_1 - 1)^2 + (p_2 - 0)^2 + \ldots + (p_n - 0)^2}.$$
The second way of measuring inaccuracy is less familiar, Brier distance, which is just the square of Euclidean distance:
$$ (p_1 - 1)^2 + (p_2 - 0)^2 + \ldots + (p_n - 0)^2.$$&lt;/p&gt;

&lt;p&gt;What we found in $n = 2$ dimensions is that Euclidean distance is &amp;ldquo;unstable&amp;rdquo; in a way that Brier is not. If we measure inaccuracy using Euclidean distance, a probability assignment can expect some &lt;em&gt;other&lt;/em&gt; probability assignment to do better accuracy-wise, i.e. to have lower inaccuracy.&lt;/p&gt;

&lt;p&gt;In fact, given almost any probability assignment, the way to minimize expected inaccuracy is to leap to certainty in the most likely possibility. Given $(2/3, 1/3)$, for example, the way to minimize expected inaccuracy is to move to $(1,0)$.&lt;/p&gt;

&lt;p&gt;Because Euclidean distance is unstable in this way, it&amp;rsquo;s called an &amp;ldquo;improper&amp;rdquo; measure of inaccuracy. So, two more bits of terminology:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Given a probability assignment $\p$ and a measure of inaccuracy $D$, the &lt;em&gt;expected inaccuracy&lt;/em&gt; of probability assignment $\q$, written $\EIpq$, is the weighted sum:
$$
\EIpq = p_1 D(\q,\u_1) + \ldots + p_n D(\q,\u_n),
$$
where $\u_i$ is the possible world with a $1$ at index $i$.&lt;/li&gt;
&lt;li&gt;A measure of inaccuracy $D$ is &lt;em&gt;improper&lt;/em&gt; if there is a probability assignment $\p$ such that for some assignment $\q \neq \p$, $\EIpq &amp;lt; \EIpp$ when inaccuracy is measured according to $D$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Last time we showed that Brier is &lt;em&gt;proper&lt;/em&gt; in any finite number of dimensions $n$. Today our main task is to show that Euclidean distance is &lt;em&gt;&lt;strong&gt;im&lt;/strong&gt;proper&lt;/em&gt; in any finite number of dimensions $n$.&lt;/p&gt;

&lt;p&gt;But first, let&amp;rsquo;s get a tempting mistake out of the way.&lt;/p&gt;

&lt;h1 id=&#34;a-conjecture-and-its-refutation&#34;&gt;A Conjecture and Its Refutation&lt;/h1&gt;

&lt;p&gt;In &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;our first post&lt;/a&gt;, we saw that Euclidean distance isn&amp;rsquo;t just improper in two dimensions. It&amp;rsquo;s also &lt;em&gt;extremizing&lt;/em&gt;: the assignment $(2/3, 1/3)$ doesn&amp;rsquo;t just expect &lt;em&gt;some&lt;/em&gt; other assignment to do better accuracy-wise. It expects the assignment $(1,0)$ to do best!&lt;/p&gt;

&lt;p&gt;At first I thought we&amp;rsquo;d be proving a straightforward generalization of that result today:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conjecture 1 (False).&lt;/strong&gt; Let $(p_1, \ldots, p_n)$ be a probability assignment with a unique largest element $p_i$. If we measure inaccuracy by Euclidean distance, then $\EIpq$ is minimized when $\q = \u_i$.&lt;/p&gt;

&lt;p&gt;Intuitively: expected inaccuracy is minimized by leaping to certainty in the most probable possibility. Turns out this is false in three dimensions. Here&amp;rsquo;s a&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Counterexample.&lt;/strong&gt; Let&amp;rsquo;s define:
$$
\begin{align}
\p &amp;amp;= (5/12, 4/12, 3/12),\\&lt;br /&gt;
\p&amp;rsquo; &amp;amp;= (6/12, 4/12, 2/12),\\&lt;br /&gt;
\u_1 &amp;amp;= (1, 0, 0).
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Then we can calculate (or better, &lt;a href=&#34;https://github.com/jweisber/a4d/blob/master/Euclid%20in%20the%20Round.nb&#34; target=&#34;_blank&#34;&gt;have &lt;em&gt;Mathematica&lt;/em&gt; calculate&lt;/a&gt;):
$$
\begin{align}
\EIpp &amp;amp;\approx .804,\\&lt;br /&gt;
EI_{\p}(\p&amp;rsquo;) &amp;amp;\approx .800,\\&lt;br /&gt;
EI_{\p}(\u_1) &amp;amp;\approx .825.
\end{align}
$$
In this case $\EIpp &amp;lt; EI_{\p}(\u_1)$. So leaping to certainty doesn&amp;rsquo;t minimize expected inaccuracy (as measured by Euclidean distance).&lt;/p&gt;

&lt;p&gt;Of course, staying put doesn&amp;rsquo;t minimize it either, since $EI_{\p}(\p&amp;rsquo;) &amp;lt; \EIpp$.&lt;/p&gt;

&lt;p&gt;So what &lt;em&gt;does&lt;/em&gt; minimize it in this example? I asked &lt;em&gt;Mathematica&lt;/em&gt; to minimize $\EIpq$ and got&amp;hellip; nothing for days. Eventually I gave up waiting and asked instead for &lt;a href=&#34;https://github.com/jweisber/a4d/blob/master/Euclid%20in%20the%20Round.nb&#34; target=&#34;_blank&#34;&gt;a numerical approximation of the minimum&lt;/a&gt;. One second later I got:&lt;/p&gt;

&lt;p&gt;$$EI_{\p}(0.575661, 0.250392, 0.173947) \approx 0.797432.$$&lt;/p&gt;

&lt;p&gt;I have no idea what that is in more meaningful terms, I&amp;rsquo;m sorry to say. But at least we know it&amp;rsquo;s not anywhere near the extreme point $\u_1$ I conjectured at the outset. (See the &lt;strong&gt;Update&lt;/strong&gt; at the end for a little more.)&lt;/p&gt;

&lt;h1 id=&#34;a-shortcut-and-its-shortcomings&#34;&gt;A Shortcut and Its Shortcomings&lt;/h1&gt;

&lt;p&gt;So I asked friends who do this kind of thing for a living how they handle the $n$-dimensional case.  A couple of them suggested taking a shortcut around it!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Look, you&amp;rsquo;ve already handled the two-dimensional case. And that&amp;rsquo;s just an instance of higher dimensional cases.&lt;/p&gt;

&lt;p&gt;Take a probability assignment like (2/3, 1/3). We can also think of it as (2/3, 1/3, 0), or as (2/3, 0, 1/3, 0), etc.&lt;/p&gt;

&lt;p&gt;No matter how many zeros we sprinkle around in there, the same thing is going to happen as in the two-dimensional case. Leaping to certainty in the 2/3 possibility will minimize expected inaccuracy. (Because possibilities with no probability make no difference to expected value calculations.)&lt;/p&gt;

&lt;p&gt;So no matter how many dimensions we&amp;rsquo;re working in, there will always be &lt;em&gt;some&lt;/em&gt; probability assignment where leaping to certainty minimizes expected inaccuracy. It just might have lots of zeros in it.&lt;/p&gt;

&lt;p&gt;So Euclidean distance is, technically, improper in any finite number of dimensions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At first I thought that was good enough for philosophy. Though I still wanted to know how to handle &amp;ldquo;no zeros&amp;rdquo; cases for the mathematical clarity.&lt;/p&gt;

&lt;p&gt;Then I realized there may be a philosophical reason to be dissatisfied with this shortcut. A lot of people endorse the &lt;a href=&#34;http://philosophy.anu.edu.au/sites/default/files/Staying%20Regular.December%2028.2012.pdf&#34; target=&#34;_blank&#34;&gt;Regularity principle&lt;/a&gt;: you should never assign zero probability to any possibility. For these people, the shortcut might be a dead end.&lt;/p&gt;

&lt;p&gt;(Of course, maybe we shouldn&amp;rsquo;t embrace Regularity if we&amp;rsquo;re working in the accuracy framework. I won&amp;rsquo;t stop for that question here.)&lt;/p&gt;

&lt;h1 id=&#34;a-theorem-and-its-corollary&#34;&gt;A Theorem and Its Corollary&lt;/h1&gt;

&lt;p&gt;So let&amp;rsquo;s take the problem head on. We want to show that Euclidean distance is improper in $n &amp;gt; 2$ dimensions, even when there are &amp;ldquo;no zeros&amp;rdquo;. Two last bits of terminology:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A probability assignment $(p_1, \ldots, p_n)$ is &lt;em&gt;regular&lt;/em&gt; if $p_i &amp;gt; 0$ for all $i$.&lt;/li&gt;
&lt;li&gt;A probability assignment $(p_1, \ldots, p_n)$ is &lt;em&gt;uniform&lt;/em&gt; if $p_i = p_j$ for all $i,j$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, for example, the assignment $(1/3, 1/3, 1/3)$ is both regular and uniform. Whereas the assignment $(2/5, 2/5, 1/5)$ is regular, but not uniform.&lt;/p&gt;

&lt;p&gt;What we&amp;rsquo;ll show is that assignments like $(2/5, 2/5, 1/5)$ make Euclidean distance &amp;ldquo;unstable&amp;rdquo;: they expect some other assignment to do better, accuracy-wise. (Exactly which other assignment they&amp;rsquo;ll expect to do best isn&amp;rsquo;t always easy to say.)&lt;/p&gt;

&lt;p&gt;(Though I try to keep the math in these posts as elementary as possible, this proof will use calculus. If you know a bit about derivatives, you should be fine. Technically we&amp;rsquo;ll use multi-variable calculus. But if you&amp;rsquo;ve worked with derivatives in single-variable calculus, that should be enough for the main ideas.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
Let $\p = (p_1, \ldots, p_n)$ be a regular, non-uniform probability assignment. If accuracy is measured by Euclidean distance, then $EI_{\p}(\q)$ is not minimized when $\q = \p$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp;
Let $\p = (p_1, \ldots, p_n)$ be a regular and non-uniform probability assignment, and measure inaccuracy using Euclidean distance. Then:
$$
\begin{align}
EI_{\p}(\q) &amp;amp;= p_1 \sqrt{(q_1 - 1)^2 + \ldots + (q_n - 0)^2} + \ldots + p_n \sqrt{(q_1 - 0)^2 + \ldots + (q_n - 1)^2}\\&lt;br /&gt;
&amp;amp;= p_1 \sqrt{(q_1 - 1)^2 + \ldots + q_n^2} + \ldots + p_n \sqrt{q_1^2 + \ldots + (q_n - 1)^2}
\end{align}
$$&lt;/p&gt;

&lt;p&gt;The crux of our proof will be that the derivatives of this function are non-zero at the point $\q = \p$. Since the minimum of a function is always a &lt;a href=&#34;https://en.wikipedia.org/wiki/Critical_point_(mathematics)&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;critical point&amp;rdquo;&lt;/a&gt;, that suffices to show that $\q = \p$ is not a minimum of $\EIpq$.&lt;/p&gt;

&lt;p&gt;To start, we calculate the partial derivative of $\EIpq$ for an arbitrary $q_i$:
$$
\begin{align}
\frac{\partial}{\partial q_i} \EIpq
&amp;amp;=
\frac{\partial}{\partial q_i} \left( p_1 \sqrt{(q_1 - 1)^2 + \ldots + q_n^2} + \ldots + p_n \sqrt{q_1^2 + \ldots + (q_n - 1)^2} \right)\\&lt;br /&gt;
&amp;amp;=
p_1 \frac{\partial}{\partial q_i} \sqrt{(q_1 - 1)^2 + \ldots + q_n^2} + \ldots + p_n \frac{\partial}{\partial q_i} \sqrt{q_1^2 + \ldots + (q_n - 1)^2}\\&lt;br /&gt;
&amp;amp;= \quad
p_i \frac{q_i - 1}{\sqrt{(q_i - 1)^2 + \sum_{j \neq i} q_j^2}} + \sum_{j \neq i} p_j \frac{q_i}{\sqrt{(q_j - 1)^2 + \sum_{k \neq j} q_k^2}}\\&lt;br /&gt;
&amp;amp;= \quad
\sum_{j \neq i} \frac{p_j q_i}{\sqrt{(q_j - 1)^2 + \sum_{k \neq j} q_k^2}} - \sum_{j \neq i} \frac{p_i q_j}{\sqrt{(q_i - 1)^2 + \sum_{j \neq i} q_j^2}}.
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Then we evaluate at $\q = \p$:
$$
\begin{align}
\frac{\partial}{\partial q_i} \EIpp
&amp;amp;= \sum_{j \neq i} \frac{p_i p_j}{\sqrt{(p_j - 1)^2 + \sum_{k \neq j} p_k^2}} - \sum_{j \neq i} \frac{p_i p_j}{\sqrt{(p_i - 1)^2 + \sum_{j \neq i} p_j^2}}
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Now, because $\p$ is not uniform, some of its elements are larger than others. And because it is finite, there is at least one largest element. When $p_i$ is one of these largest elements, then $\partial / \partial q_i \EIpp$ is negative.&lt;/p&gt;

&lt;p&gt;Why?&lt;/p&gt;

&lt;p&gt;In our equation for $\partial / \partial q_i \EIpp$, each positive term has a corresponding negative term whose numerator is identical. And when $p_i$ is a largest element of $\p$, the denominator of each negative term will never be larger, but will sometimes be smaller, than the denominator of its corresponding positive term. Subtracting $1$ from $p_i$ before squaring does more to reduce the sum of squares $p_i^2 + \sum_{j \neq i} p_j^2$ than subtracting $1$ from any smaller term would. It effectively removes the/a largest square from the sum and substitutes the smallest replacement. So the negative terms are never smaller, but are sometimes larger, than their positive counterparts.&lt;/p&gt;

&lt;p&gt;If, on the other hand, $p_i$ is the one of the smallest elements, then $\partial / \partial q_i \EIpp$ is positive. For then the reverse argument applies: the denominator of each negative term will never be smaller and will sometimes be larger than the denominator of the corresponding positive term. So the negatives terms are never larger, but are sometimes smaller, than their positive counterparts.&lt;/p&gt;

&lt;p&gt;We have shown that the partial derivates of $\EIpq$ are non-zero at the point $\q = \p$. Thus $\p$ is not a critical point of $\EIpq$, and hence cannot be a minimum of $\EIpq$.  &lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Corollary.&lt;/strong&gt; Euclidean distance is improper in any finite number of dimensions.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp; This is just a slight restatement of our theorem. If $\q = \p$ is not a minimum of $\EIpq$, then there is some $\q \neq \p$ such that $\EIpq &amp;lt; \EIpp$.  &lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;conjectures-awaiting-refutations&#34;&gt;Conjectures Awaiting Refutations&lt;/h1&gt;

&lt;p&gt;Notice, we&amp;rsquo;ve also shown something a bit stronger. We showed that the slope of $\EIpq$ at the point $\q = \p$ is always negative in the direction of $\p$&amp;rsquo;s largest element(s), and positive in the direction of its smallest element(s). That means we can always reduce expected inaccuracy by taking some small quantity away from the/a smallest element of $\p$ and adding it to the/a largest element. In other words, we can always reduce expected inaccuracy by moving &lt;em&gt;some&lt;/em&gt; way towards perfect certainty in the/a possibility that $\p$ rates most probable.&lt;/p&gt;

&lt;p&gt;However, we &lt;em&gt;haven&amp;rsquo;t&lt;/em&gt; shown that repeatedly minimizing expected inaccuracy will, eventually, lead to certainty in the/a possibility that was most probable to begin with. For one thing, we haven&amp;rsquo;t shown that moving towards certainty in this direction minimizes expected inaccuracy at each step. We&amp;rsquo;ve only shown that moving in this direction reduces it.&lt;/p&gt;

&lt;p&gt;Still, I&amp;rsquo;m pretty sure a result along these lines holds. Tinkering in &lt;em&gt;Mathematica&lt;/em&gt; strongly suggests that the following Conjectures are true in any finite number of dimensions $n$:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conjecture 2.&lt;/strong&gt; If a probability assignment gives greater than $1/ 2$ probability to some possibility, then expected inaccuracy is minimized by assigning probability 1 to that possibility. (But see the &lt;strong&gt;Update&lt;/strong&gt; below.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conjecture 3.&lt;/strong&gt; Given a non-uniform probability assignment, repeatedly minimizing expected inaccuracy will, within a finite number of steps, increase the probability of the/a possibility that was most probable initially beyond $1/ 2$.&lt;/p&gt;

&lt;p&gt;If these conjectures hold, then there&amp;rsquo;s still a weak-ish sense in which Euclidean distance is &amp;ldquo;extremizing&amp;rdquo; in $n &amp;gt; 2$ dimensions. Given a non-uniform probability assignment, repeatedly minimizing expected inaccuracy will eventually lead to greater than $1/ 2$ probability in the/a possibility that was most probable to begin with. Then, minimizing inaccuracy will lead in a single step to certainty in that possibility.&lt;/p&gt;

&lt;p&gt;Proving these conjectures would close much of the gap between the theorem we proved and the false conjecture I started with. If you&amp;rsquo;re interested, you can use &lt;a href=&#34;https://github.com/jweisber/a4d/blob/master/Euclid%20in%20the%20Round.nb&#34; target=&#34;_blank&#34;&gt;this &lt;em&gt;Mathematica&lt;/em&gt; notebook&lt;/a&gt; to test them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update: Mar. 6, 2017.&lt;/strong&gt; Thanks to some excellent help from &lt;a href=&#34;https://mathematics.stanford.edu/people/department-directory/name/jonathan-love/&#34; target=&#34;_blank&#34;&gt;Jonathan Love&lt;/a&gt;, I&amp;rsquo;ve tweaked this post (and greatly simplified &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%203/&#34;&gt;the previous one&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I changed the counterexample to the false Conjecture 1, which used to be $\p = (3/7, 2/7, 2/7)$ and $\p&amp;rsquo; = (4/7, 2/7, 1/7)$. That works fine, but it&amp;rsquo;s potentially misleading.&lt;/p&gt;

&lt;p&gt;As Jonathan kindly pointed out, the minimum point then is something quite nice. It&amp;rsquo;s obtained by moving in the $x$-dimension from $3/7$ to $\sqrt{3/7}$, and correspondingly reducing the probability in the $y$ and $z$ dimensions in equal parts.&lt;/p&gt;

&lt;p&gt;But, in general, moving to the square root of the largest $p_i$ (when there is one) doesn&amp;rsquo;t minimize $\EIpq$. Even in the special case where all the other elements in the vector are equal, this doesn&amp;rsquo;t generally work.&lt;/p&gt;

&lt;p&gt;Jonathan did solve that special case, though, and he found at least one interesting result connected with Conjecture 2. There appear to be cases where $p_i &amp;lt; 1/ 2$ for all $i$, and yet $\EIpq$ is still minimized by going directly to the extreme. For example, $\p = (.465, .2675, .2675)$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 3: Beyond the Second Dimension</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%203/</link>
      <pubDate>Fri, 27 Jan 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%203/</guid>
      <description>

&lt;p&gt;Last time we saw why accuracy-mavens prefer Brier distance to Euclidean distance. But we did everything in two dimensions. That&amp;rsquo;s fine for a coin toss, with only two possibilities. But what if there are three doors and one of them has a prize behind it??&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t panic! Today we&amp;rsquo;re going to verify that Brier distance is still a proper way of measuring inaccuracy, even when there are more than two possibilities. (Next time we&amp;rsquo;ll talk about Euclidean distance with more than two possibilitie.)&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start small, with just three possibilities. $\renewcommand{\vec}[1]{\mathbf{#1}}\newcommand{\p}{\vec{p}}\newcommand{\q}{\vec{q}}\newcommand{\v}{\vec{v}}\newcommand{\EIpq}{EI_{\p}(\q)}\newcommand{\EIpp}{EI_{\p}(\p)}$&lt;/p&gt;

&lt;h1 id=&#34;three-possibilities&#34;&gt;Three Possibilities&lt;/h1&gt;

&lt;p&gt;You&amp;rsquo;re on a game show; there are three doors; one has a prize behind it. The three possibilities are represented by the vertices $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Three Vertices.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Your credences are given by some probability assignment $(p_1, p_2, p_3)$. It might be $(1/ 3, 1/ 3, 1/ 3)$ but it could be anything&amp;hellip; $(7/ 10, 2/ 10, 1/ 10)$, for example.&lt;/p&gt;

&lt;p&gt;In case you&amp;rsquo;re curious, here&amp;rsquo;s what the range of possible probability assignments looks like in graphical terms:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Three Vertices with Hull.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The triangular surface is the three-dimensional analogue of the diagonal line in &lt;a href=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram.png&#34;&gt;the two-dimensional diagram&lt;/a&gt; from our &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;first post&lt;/a&gt; in this series.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;ll be handy to refer to points on this surface using single letters, like $\p$ for $(p_1, p_2, p_3)$. We&amp;rsquo;ll write these letters in bold, to distinguish a sequence of numbers like $\p$ from a single number like $p_1$. (In math-speak, $\p$ is a &lt;em&gt;vector&lt;/em&gt; and $p_1$ is a &lt;em&gt;scalar&lt;/em&gt;.)&lt;/p&gt;

&lt;p&gt;Our job is to show that Brier distance is &amp;ldquo;proper&amp;rdquo; in three dimensions. Let&amp;rsquo;s recall what that means: given a point $\p$, the expected Brier distance (according to $\p$) of a point $\q = (q_1, q_2, q_3)$ from the three vertices is always smallest when $\q = \p$.&lt;/p&gt;

&lt;p&gt;What does &lt;em&gt;that&lt;/em&gt; mean?&lt;/p&gt;

&lt;p&gt;Recall, the Brier distance from $\q$ to the vertex $(1, 0, 0)$ is:
$$
(q_1 - 1)^2 + (q_2 - 0)^2 + (q_3 - 0)^2
$$
Or, more succinctly:
$$
(q_1 - 1)^2 + q_2^2 + q_3^2
$$
So the &lt;em&gt;expected&lt;/em&gt; Brier distance of $\q$ according to $\p$ weights each such sum by the probability $\p$ assigns to the corresponding vertex.
$$
\begin{align}
&amp;amp;\quad\quad p_1 \left( (q_1 - 1)^2 + q_2^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_2 \left( q_1^2 + (q_2 - 1)^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_3 \left( q_1^2 + q_2^2 + (q_3 - 1)^2 \right)
\end{align}
$$
We need to show that this quantity is smallest when $\q = \p$, i.e. when $q_1 = p_1$, $q_2 = p_2$, and $q_3 = p_3$.&lt;/p&gt;

&lt;h2 id=&#34;visualizing-expected-inaccuracy&#34;&gt;Visualizing Expected Inaccuracy&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s do some visualization. We&amp;rsquo;ll take a few examples of $\p$, and graph the expected inaccuracy of other possible points $\q$, using Brier distance to measure inaccuracy.&lt;/p&gt;

&lt;p&gt;For example, suppose $\p = (1/ 3, 1/ 3, 1/ 3)$. Then the expected inaccuracy of each point $\q$ looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/BrierEI3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The horizontal axes represent $q_1$ and $q_2$. The vertical axis represents expected inaccuracy.&lt;/p&gt;

&lt;p&gt;Where&amp;rsquo;s $q_3$?? Not pictured! If we used all three visible dimensions for the elements of $\q$, we&amp;rsquo;d have nothing left to visualize expected inaccuracy. But $q_3$ is there implicitly. You can always get $q_3$ by calculating $1 - (q_1 + q_2)$, because $\q$ is a probability assignment. So we don&amp;rsquo;t actually need $q_3$ in the graph!&lt;/p&gt;

&lt;p&gt;Now, the red dot is the lowest point on the surface: the smallest possible expected inaccuracy, according to $\p$. But where is that in terms of $q_1$ and $q_2$? Let&amp;rsquo;s look at the same graph from directly above:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/BrierEI3-above.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hey! Looks like the red dot is located at $q_1 = 1/ 3$ and $q_2 = 1/ 3$, i.e. at $\q = (1/ 3, 1/ 3, 1/ 3)$. Also known as $\p$. So that&amp;rsquo;s promising: looks like expected inaccuracy is minimized when $\q = \p$, at least in this example.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s do one more example, $\p = (6/ 10, 3/ 10, 1/ 10)$. Then the expected Brier distance of each point $\q$ looks like this:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/BrierEI3-2.png&#34; alt=&#34;&#34; /&gt;
Or, taking the aerial view again:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/BrierEI3-2above.png&#34; alt=&#34;&#34; /&gt;
Yep, looks like the red dot is located at $q_1 = 6/ 10$ and $q_2 = 3/ 10$, i.e. at $\q = (6/ 10, 3/ 10, 1/ 10)$, also known as $\p$. So, once again, it seems expected inaccuracy is minimized when $\q = \p$.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s prove that that&amp;rsquo;s how it always is.&lt;/p&gt;

&lt;h2 id=&#34;a-proof&#34;&gt;A Proof&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll need a little notation: I&amp;rsquo;m going to write $\EIpq$ for the expected inaccuracy of point $\q$, according to $\p$.&lt;/p&gt;

&lt;p&gt;Now recall our formula for expected inaccuracy:
$$
\begin{align}
\EIpq
&amp;amp;= \quad p_1 \left( (q_1 - 1)^2 + q_2^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_2 \left( q_1^2 + (q_2 - 1)^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_3 \left( q_1^2 + q_2^2 + (q_3 - 1)^2 \right).
\end{align}
$$
How do we find the point $\q$ that minimizes this mess?&lt;/p&gt;

&lt;p&gt;Originally this post used some pretty tedious calculus. But thanks to a hot tip from &lt;a href=&#34;https://mathematics.stanford.edu/people/department-directory/name/jonathan-love/&#34; target=&#34;_blank&#34;&gt;Jonathan Love&lt;/a&gt;, we can get by just with algebra.&lt;/p&gt;

&lt;p&gt;First we need to expand the squares in our big ugly sum:
$$
\begin{align}
\EIpq
&amp;amp;= \quad p_1 \left( q_1^2 - 2q_1 + 1 + q_2^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_2 \left( q_1^2 + q_2^2 - 2q_2 + 1 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_3 \left( q_1^2 + q_2^2 + q_3^2 - 2q_3 + 1 \right).
\end{align}
$$
Then we&amp;rsquo;ll gather some common terms and rearrange things:
$$
\begin{align}
\EIpq &amp;amp;= (p_1 + p_2 + p_3)\left(q_1^2 + q_2^2 + q_3^2 + 1 \right) - 2p_1q_1 - 2p_2q_2 - 2p_3q_3.\\&lt;br /&gt;
\end{align}
$$
Since $p_1 + p_2 + p_3 = 1$, that simplifies to:
$$
\begin{align}
\EIpq &amp;amp;= q_1^2 + q_2^2 + q_3^2 + 1 - 2p_1q_1 - 2p_2q_2 - 2p_3q_3.\\&lt;br /&gt;
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Now we&amp;rsquo;ll use &lt;a href=&#34;https://mathematics.stanford.edu/people/department-directory/name/jonathan-love/&#34; target=&#34;_blank&#34;&gt;Jonathan&lt;/a&gt;&amp;rsquo;s ingenious trick. We&amp;rsquo;re going to add $p_1^2 + p_2^2 + p_3^2 - 1$ to this expression, &lt;em&gt;which doesn&amp;rsquo;t change where the minimum occurs&lt;/em&gt;. If you shift every point on a graph upwards by the same amount, the minimum is still in the same place. (Imagine everybody in the world grows by an inch overnight; the shortest person in the world is still the shortest, despite being an inch taller.)&lt;/p&gt;

&lt;p&gt;Then, magically, we get an expression that factors into something tidy:
$$
\begin{align}
&amp;amp;\phantom{=}\phantom{=} p_1^2 + p_2^2 + p_3^2 + q_1^2 + q_2^2 + q_3^2 - 2p_1q_1 - 2p_2q_2 - 2p_3q_3\\&lt;br /&gt;
  &amp;amp;= (p_1 - q_1)^2 + (p_2 - q_2)^2 + (p_3 - q_3)^2.
\end{align}
$$
And not just tidy, but easy to minimize. It&amp;rsquo;s a sum of squares, and squares are never negative. So the smallest possible value  is $0$, which occurs when all the squares are $0$, i.e. when $q_1 = p_1$, $q_2 = p_2$, and $q_3 = p_3$.&lt;/p&gt;

&lt;p&gt;So, the minimum of $\EIpq$ occurs in the same place, namely when $\q = \p$!&lt;/p&gt;

&lt;h2 id=&#34;the-nth-dimension&#34;&gt;The Nth Dimension&lt;/h2&gt;

&lt;p&gt;Now we can use the same idea to generalize to any number of dimensions. Since the steps are essentially identical, I&amp;rsquo;ll keep it short and (I hope) sweet.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
Given a probability assignment $\p = (p_1, \ldots, p_n)$, if inaccuracy is measured using Brier distance, then $\EIpq$ is uniquely minimized when $\q = \p$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp;
Let $\p = (p_1, \ldots, p_n)$ be a probability assignment, and let $\EIpq$ be the expected inaccuracy according to $\p$ of probability assignment $\q = (q_1, \ldots, q_n)$, measured using Brier distance.&lt;/p&gt;

&lt;p&gt;First we simplify our expression for $\EIpq$ using algebra:
$$
\begin{align}
\EIpq
&amp;amp;= \quad p_1 \left( (q_1 - 1)^2 + q_2^2 + \ldots + q_n^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_2 \left( q_1^2 + (q_2 - 1)^2 + \ldots + q_n^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad\quad \vdots\\&lt;br /&gt;
  &amp;amp;\quad + p_n \left( q_1^2 + q_2^2 + \ldots + q_{n-1}^2 + (q_n - 1)^2 \right)\\&lt;br /&gt;
&amp;amp;= (p_1 + \ldots + p_n)\left( q_1^2 + \ldots + q_n^2 + 1\right) - 2 p_1 q_1 - \ldots - 2 p_n q_n\\&lt;br /&gt;
&amp;amp;= q_1^2 + \ldots + q_n^2 + 1 - 2 p_1 q_1 - \ldots - 2 p_n q_n.
\end{align}
$$
Now, because $p_1^2 + \ldots + p_n^2 - 1$ is a constant, adding it to $\EIpq$ doesn&amp;rsquo;t change where the minimum occurs. So we can minimize instead:
$$
\begin{align}
&amp;amp;\phantom{=}\phantom{=} p_1^2 + \ldots + p_n^2 + q_1^2 + \ldots + q_n^2 - 2 p_1 q_1 - \ldots - 2 p_n q_n\\&lt;br /&gt;
&amp;amp;= (p_1 - q_1)^2 + \ldots + (p_n - q_n)^2.
\end{align}
$$
Being a sum of squares, the minimum value here cannot be less than $0$, which occurs when $\q = \p$. &lt;span style=&#34;float: right;&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;div class=&#34;text-center&#34;&gt;
&lt;object data=&#34;http://www.youtube.com/embed/MkmMxfCgewQ&#34;
   width=&#34;560&#34; height=&#34;315&#34; classboo=&#34;text-center&#34;&gt;&lt;/object&gt;
&lt;/div&gt;

&lt;p&gt;So what did we learn? That Brier distance isn&amp;rsquo;t just &amp;ldquo;stable&amp;rdquo; in toy cases like a coin-toss. It&amp;rsquo;s also stable in toy cases with any finite number of outcomes.&lt;/p&gt;

&lt;p&gt;No matter how many outcomes are under consideration, each probability assignment expects itself to do best at minimizing inaccuracy, if we use Brier distance to measure inaccuracy.&lt;/p&gt;

&lt;p&gt;To go beyond toy cases, we&amp;rsquo;d have to extend this result to cases with infinite numbers of possibilities. And I haven&amp;rsquo;t even begun to think about how to do that.&lt;/p&gt;

&lt;p&gt;Instead, next time we&amp;rsquo;ll look at what happens in $3+$ dimensions when we use Euclidean distance instead of Brier distance. And it&amp;rsquo;s actually kind of interesting! It turns out Euclidean distance is still improper in $3+$ dimensions, but not necessarily in the same way as in $2$ dimensions. More on that next time&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 2: from Euclid to Brier</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%202/</link>
      <pubDate>Wed, 18 Jan 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%202/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%201/&#34;&gt;Last time&lt;/a&gt; we saw that Euclidean distance is an &amp;ldquo;unstable&amp;rdquo; way of measuring inaccuracy. Given one assignment of probabilities, you&amp;rsquo;ll expect some other assignment to be more accurate (unless the first assignment is either perfectly certain or perfectly uncertain).&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s why accuraticians don&amp;rsquo;t use good ol&amp;rsquo; Euclidean distance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://crookedrunbrewing.files.wordpress.com/2014/05/scientician.png?w=240&#34; alt=&#34;Just ask this accuratician&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Instead they use&amp;hellip; well, there are lots of alternatives. But the closest thing to a standard one is &lt;em&gt;Brier distance&lt;/em&gt;: the square of Euclidean distance.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s Euclid&amp;rsquo;s formula for the distance between two points $(a, b)$ and $(c, d)$ in the plane:
$$ \sqrt{ (a - c)^2 + (b - d)^2 }. $$
And here&amp;rsquo;s Brier&amp;rsquo;s:
$$ (a - c)^2 + (b - d)^2. $$
So, to get from Euclid to Brier, you just take away the square root.&lt;/p&gt;

&lt;p&gt;That makes a world of difference, it turns out. Brier distance isn&amp;rsquo;t unstable the way Euclidean distance is. But we&amp;rsquo;ll see that it&amp;rsquo;s enough like Euclidean distance to vindicate the argument for the laws of probability we began with last time.&lt;/p&gt;

&lt;p&gt;But first, a fun fact.&lt;/p&gt;

&lt;h1 id=&#34;fun-fact&#34;&gt;Fun Fact&lt;/h1&gt;

&lt;p&gt;Brier distance comes from the world of weather forecasting. Glenn W. Brier worked for the U. S. Weather Bureau, and in &lt;a href=&#34;http://docs.lib.noaa.gov/rescue/mwr/078/mwr-078-01-0001.pdf&#34; target=&#34;_blank&#34;&gt;a 1950 paper&lt;/a&gt; he proposed his formula as a way of measuring how well a weather forecaster is doing at predicting the weather.&lt;/p&gt;

&lt;p&gt;Suppose you say there&amp;rsquo;s a 70% chance of rain. If it does rain, you&amp;rsquo;re hardly wrong, but you&amp;rsquo;re not exactly right either. Brier suggested assessing a forecaster&amp;rsquo;s probabilities by taking the square of the difference from $1$ when it rains, and from $0$ when it doesn&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;Well, actually, he proposed taking the &lt;em&gt;average&lt;/em&gt; of those squares. But we&amp;rsquo;ll follow the recent philosophical literature and keep it simple: we&amp;rsquo;ll just use the sum of squares rather than its average.&lt;/p&gt;

&lt;p&gt;Now on to the substance. Two facts about Brier distance make it useful as a replacement for Euclidean distance.&lt;/p&gt;

&lt;h1 id=&#34;euclid-and-brier-are-ordinally-equivalent&#34;&gt;Euclid and Brier are Ordinally Equivalent&lt;/h1&gt;

&lt;p&gt;First, Brier distance is &lt;em&gt;ordinally equivalent&lt;/em&gt; to Euclidean distance. Meaning: whenever a distance is larger according to Euclid, it&amp;rsquo;s larger according to Brier too. And vice versa.&lt;/p&gt;

&lt;p&gt;How do we know that? Because Brier is just Euclid squared, and squaring a larger number always results in a larger number (for positive numbers like distances, anyway). If $D$ is the distance from Toronto to the sun, and $d$ is the distance from Toronto to the moon, then $D^2 &amp;gt; d^2$. It&amp;rsquo;s further to the sun than to the moon, both in terms of Brier distance and Euclidean distance.&lt;/p&gt;

&lt;p&gt;So, when we&amp;rsquo;re comparing distances from the truth, Brier distance behaves a lot like Euclidean distance. In particular, what we learned from our opening diagram about Euclidean distance holds for Brier distance, too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D%20Dominance%20Diagram%20-%20400px.png&#34; alt=&#34;Opening diagram&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Not only is $c&amp;rsquo;$ closer to both vertices than $c^*$ in Euclidean terms, it&amp;rsquo;s also closer in terms of Brier distance.&lt;/p&gt;

&lt;h1 id=&#34;brier-is-stable&#34;&gt;Brier is Stable&lt;/h1&gt;

&lt;p&gt;Second, Brier distance doesn&amp;rsquo;t lead to the kind of instability that made Euclidean distance problematic. To see why, let&amp;rsquo;s rerun our expected inaccuracy calculations from last time, but using Brier distance instead of Euclid.&lt;/p&gt;

&lt;p&gt;Suppose your credences in Heads and Tails are $p$ and $1-p$. What&amp;rsquo;s the expected inaccuracy of having some credence $q$ in Heads, and $1-q$ in Tails?&lt;/p&gt;

&lt;p&gt;Well, the Brier distance between $(q, 1-q)$ and $(1,0)$ is:
$$(q - 1)^2 + ((1-q) - 0)^2.$$
And the Brier distance between $(q, 1-q)$ and $(0,1)$ is:
$$(q - 0)^2 + ((1-q) - 1)^2.$$
We don&amp;rsquo;t know which of $(1,0)$ or $(0,1)$ is the &amp;ldquo;true&amp;rdquo; one. But we have assigned them the probabilities $p$ and $1-p$, respectively. So we can calculate the expected inaccuracy of $(q, 1-q)$, written $EI(q, 1-q)$:
$$
\begin{align}
EI(q, 1-q) &amp;amp;= p \left( (q - 1)^2 + ((1-q) - 0)^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + (1-p) \left( (q - 0)^2 + ((1-q) - 1)^2 \right)\\&lt;br /&gt;
  &amp;amp;= 2 p (1 - q)^2 + 2(1-p) q^2\\&lt;br /&gt;
  &amp;amp;= 2 p q^2 - 4pq + 2p + 2q^2 - 2pq^2\\&lt;br /&gt;
  &amp;amp;= 2q^2 - 4pq + 2p
\end{align}
$$
Now that last line might look like a mess. But it&amp;rsquo;s really just a quadratic equation, where the variable is $q$. Remember: we&amp;rsquo;re treating $p$ as a constant since that&amp;rsquo;s the credence you hold. And we&amp;rsquo;re looking at potential values of $q$ to see which ones minimize the quantity $EI(q, 1-q)$, given a fixed credence of $p$ in heads.&lt;/p&gt;

&lt;p&gt;So which value of $q$ minimizes this quadratic formula? You might remember from algebra class that a quadratic equation of the form:
$$
ax^2 + bx + c
$$
is a parabola, with the bottom of the bowl located at $x = -b/2a$. (Or, if you know some calculus, you can take the derivative and set it equal to $0$. Since the derivative here is $2ax + b$, setting it equal to $0$ yields, again, $x = -b/2a$.)&lt;/p&gt;

&lt;p&gt;In the case of our formula, we have $a = 2$ and $b = -4p$. So the minimum happens when $q = 4p/4 = p$. In other words, given credence $p$ in heads, expected inaccuracy is minimized by sticking with that same credence, i.e. assigning $q = p$.&lt;/p&gt;

&lt;p&gt;So, to complement our result about Euclidean distance from last time, we have a&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp; Suppose $p \in [0,1]$. Then, according to the probability assignment $(p, 1-p)$, the expected Brier distance of any alternative assignment $(q, 1-q)$ from the points $(1,0)$ and $(0,1)$ is uniquely minimized when $p = q$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp; Scroll up! &lt;span style=&#34;float: right;&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;proper-scoring-rules&#34;&gt;Proper Scoring Rules&lt;/h1&gt;

&lt;p&gt;When a measure of inaccuracy is stable like this, it&amp;rsquo;s called &lt;em&gt;proper&lt;/em&gt; (or sometimes: &lt;em&gt;immodest&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;There are lots of other proper ways of measuring inaccuracy besides Brier. But Brier tends to be the default among philosophers writing in the accuracy framework, at least as a working example. Why?&lt;/p&gt;

&lt;p&gt;My impression (though I&amp;rsquo;m no guru) is that it&amp;rsquo;s the default because:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Brier is a lot like Euclidean distance, as we saw. So it&amp;rsquo;s easier and more intuitive to work with than some of the alternatives.&lt;/li&gt;
&lt;li&gt;Brier tends to be representative of other proper/immodest rules. If you discover something philosophically interesting using Brier, there&amp;rsquo;s a good chance it holds for many other proper scoring rules.&lt;/li&gt;
&lt;li&gt;Brier has other nice mathematical properties which, according to authors like Richard Pettigrew, make it The One True Measure of Inaccuracy. (It may have some odd features too, though: see &lt;a href=&#34;http://m-phi.blogspot.ca/2015/03/a-strange-thing-about-brier-score.html&#34; target=&#34;_blank&#34;&gt;this post&lt;/a&gt; by Brian Knab and Miriam Schoenfield, for example.)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;How does our starting argument for the laws of total probability fare if we use other proper scoring rules, besides Brier? Really well, it turns out!&lt;/p&gt;

&lt;p&gt;The key fact our diagram illustrates doesn&amp;rsquo;t just hold for Euclidean distance and Brier distance. Speaking &lt;em&gt;very&lt;/em&gt; loosely: it holds on any proper way of measuring distance (but do see sections 8 and 9 of &lt;a href=&#34;https://philpapers.org/rec/JOYAAC&#34; target=&#34;_blank&#34;&gt;Joyce&amp;rsquo;s 2009&lt;/a&gt; for the details before getting carried away with this generalization; or see Theorem 4.3.5 of &lt;a href=&#34;https://global.oup.com/academic/product/accuracy-and-the-laws-of-credence-9780198732716&#34; target=&#34;_blank&#34;&gt;Pettigrew 2016&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Proving that requires grinding through a good deal of math, though. So in these posts we&amp;rsquo;re going to stick with Brier distance, at least for a while.&lt;/p&gt;

&lt;h1 id=&#34;begging-the-question&#34;&gt;Begging the Question?&lt;/h1&gt;

&lt;p&gt;We started these posts with an illustration of an influential argument for the laws of probability. But we quickly switched to &lt;em&gt;assuming&lt;/em&gt; those very same laws in the arguments that followed.&lt;/p&gt;

&lt;p&gt;For example, to illustrate the instability of Euclidean distance, I chose a point on the diagonal of our diagram, $(.6, .4)$. And in the theorem that generalized that example, I assumed probabilistic assignments like $(p, 1-p)$ and $(q, 1-q)$, which add up to $1$.&lt;/p&gt;

&lt;p&gt;So didn&amp;rsquo;t we beg the question when we motivated switching from Euclid to Brier?&lt;/p&gt;

&lt;p&gt;To some extent: yes. We are assuming that reasonable ways of measuring inaccuracy can&amp;rsquo;t be so hostile to the laws of probability that they make almost all probability assignments unstable.&lt;/p&gt;

&lt;p&gt;But also: no. We aren&amp;rsquo;t assuming that the laws of probability are absolute and inviolable, just that they&amp;rsquo;re reasonable &lt;em&gt;sometimes&lt;/em&gt;. Euclidean distance would rule out probabilistic credences on pretty much all occasions. So it conflicts with the very modest thought that following the laws of probability is &lt;em&gt;occasionally&lt;/em&gt; reasonable. So, even if you&amp;rsquo;re just a little bit open to the idea of probability theory, Euclidean distance will seem pretty unfriendly.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Perhaps most importantly, though: the motivation I&amp;rsquo;ve given you here for moving from Euclid to Brier isn&amp;rsquo;t the official one you&amp;rsquo;ll find in an actual, bottom-up argument for probability theory, like &lt;a href=&#34;https://richardpettigrew.wordpress.com/accuracy-book/&#34; target=&#34;_blank&#34;&gt;Richard Pettigrew&amp;rsquo;s&lt;/a&gt;. His argument starts from a much more abstract place. He starts with axioms that any measure of inaccuracy must obey, and then narrows things down to Brier.&lt;/p&gt;

&lt;p&gt;So there&amp;rsquo;s the official story and the unofficial story. This post gives you the unofficial story, to help you get started. Because the official story is often really hard to understand. Not only is the math way more abstract, but the philosophical motivations are often hard to suss out. Because&amp;mdash;and this is just between you and me now&amp;mdash;the people telling the official story actually started out with the unofficial story, and then worked backwards until they came up with an officially respectable story that doesn&amp;rsquo;t beg the question quite so obviously.&lt;/p&gt;

&lt;p&gt;Ok, that&amp;rsquo;s unfair. Here&amp;rsquo;s a more even-handed (and better-informed) way of putting it, from &lt;a href=&#34;http://ndpr.nd.edu/news/70705-accuracy-and-the-laws-of-credence/&#34; target=&#34;_blank&#34;&gt;Kenny Easwaran&amp;rsquo;s review&lt;/a&gt; of Pettigrew&amp;rsquo;s book:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Some philosophers have a vision of what they do as starting from unassailable premises, and giving an ironclad argument for a conclusion. However, I think we&amp;rsquo;ve all often seen cases where these arguments are weaker than they seem to the author, and with the benefit of a bit of distance, one can often recognize how the premises were in fact motivated by an attempt to justify the conclusion, which was chosen in advance. Pettigrew avoids the charade of pretending to have come up with the premises independently of recognizing that they lead to the conclusions of his arguments. Instead, he is open about having chosen target conclusions in advance [&amp;hellip;] and investigated what collection of potentially plausible principles about accuracy and epistemic decision theory will lead to those conclusions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;This argument is essentially drawn from &lt;a href=&#34;https://philpapers.org/rec/JOYAAC&#34; target=&#34;_blank&#34;&gt;(Joyce 2009)&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 1: Euclid Improper</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%201/</link>
      <pubDate>Fri, 13 Jan 2017 09:53:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%201/</guid>
      <description>

&lt;p&gt;If you&amp;rsquo;ve bumped into &lt;a href=&#34;https://plato.stanford.edu/entries/epistemic-utility/#AccArg&#34; target=&#34;_blank&#34;&gt;the accuracy framework&lt;/a&gt; before, you&amp;rsquo;ve probably seen a diagram like this one:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The vertices $(1,0)$ and $(0,1)$ represent two possibilities, whether a coin lands heads or tails in this example.&lt;/p&gt;

&lt;p&gt;According to the laws of probability, the probability of heads and of tails must add up to $1$, like $.3 + .7$ or $.5 + .5$. So the diagonal line connecting the two vertices covers all the possible probability assignments&amp;hellip;  $(0,1)$, $(.3,.7)$, $(.5, .5)$, $(.9, .1)$, $(1,0)$, etc.$\newcommand{\vone}{(1,0)}$$\newcommand{\vtwo}{(0,1)}$&lt;/p&gt;

&lt;p&gt;The diagram illustrates a key fact of the accuracy framework. Assignments that obey the laws of probability are always &amp;ldquo;closer to the truth&amp;rdquo; than assignments that violate those laws&amp;mdash;&lt;em&gt;no matter what the truth turns out to be&lt;/em&gt;.  Given any point &lt;em&gt;not&lt;/em&gt; on the line, there is a point &lt;em&gt;on&lt;/em&gt; the line that is closer to &lt;em&gt;both&lt;/em&gt; vertices $\vone$ and $\vtwo$. So, whether the coin lands heads or tails, you&amp;rsquo;ll be closer to the truth if your degrees of belief (a.k.a. &amp;ldquo;credences&amp;rdquo;) obey the laws of probability.&lt;/p&gt;

&lt;p&gt;Take $c^*$, for example, which doesn&amp;rsquo;t lie on the diagonal line. Let&amp;rsquo;s assume $c^*$ is the point $(.7, .5)$, which violates the laws of probability: $.7 + .5 &amp;gt; 1$. Now compare that to $c&amp;rsquo;$, which does lie on the diagonal line. That&amp;rsquo;s the point $(.6, .4)$, which does obey the laws of probability: $.6 + .4 = 1$.&lt;/p&gt;

&lt;p&gt;Well, $c&amp;rsquo;$ is closer to $\vone$ than $c^*$ is. Just look at the right-triangle connecting all three points: to get to $\vone$ from $c^*$ you have to travel along the hypotenuse. But you only have to travel the distance of one of the legs to get there from $c&amp;rsquo;$. And the same thinking applies to the other vertex, $\vtwo$. So $c&amp;rsquo;$ is closer to both vertices than $c^*$ is.&lt;/p&gt;

&lt;p&gt;The same idea applies to &lt;em&gt;any&lt;/em&gt; point in the unit square. If it&amp;rsquo;s not on the diagonal line, there&amp;rsquo;s a point on the line that will be closer to both vertices&amp;mdash;because Pythagoras. Just go from whatever $c^*$ you start with to the closest point $c&amp;rsquo;$ on the diagonal. You&amp;rsquo;ll have two right-triangles, one for  each vertex. So the $c&amp;rsquo;$ point will be closer to both vertices than the $c^*$ point you started with.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s more, no point on the line is closer to both vertices than any other. For example, if you move from $(.5, .5)$ to some other point on the line, you&amp;rsquo;ll move towards one vertex but away from the other. So if you&amp;rsquo;re off the line, you can always get closer to both vertices by moving onto the line. But once you&amp;rsquo;re on the line, there&amp;rsquo;s no way that guarantees you&amp;rsquo;ll be closer to the vertex representing the true outcome of the coin toss.&lt;/p&gt;

&lt;p&gt;And that&amp;rsquo;s why you should obey the laws of probability, according to advocates of the accuracy framework. Violating the laws of probability takes you away from the truth, no matter what the truth turns out to be. Whereas if you obey the laws of probability, that doesn&amp;rsquo;t happen.&lt;/p&gt;

&lt;h1 id=&#34;hey-dummy&#34;&gt;Hey, Dummy&lt;/h1&gt;

&lt;p&gt;If you&amp;rsquo;re like me, the first time you see this argument you think to yourself: &amp;ldquo;Cool! The diagram gives me the key idea, I&amp;rsquo;ll worry about mathematical technicalities later (like, what if there are more than two possibilities?). For now let me just see where you&amp;rsquo;re going with this, epistemology-wise&amp;hellip;&amp;rdquo;&lt;/p&gt;

&lt;p&gt;But when I finally did sit down to work through the math, I found it much harder than I expected to answer some elementary questions. The answers to these questions were usually taken for granted in published work, or they went by so fast I wasn&amp;rsquo;t sure about the details.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m still working on filling in a lot of these gaps, as I work through &lt;a href=&#34;https://global.oup.com/academic/product/accuracy-and-the-laws-of-credence-9780198732716?cc=ca&amp;amp;lang=en&amp;amp;&#34; target=&#34;_blank&#34;&gt;Richard Pettigrew&amp;rsquo;s excellent new book&lt;/a&gt; and get up to speed (I hope!) with the latest research. I&amp;rsquo;m writing these posts to help me get clear on the basics, and hopefully help you do the same.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://s-media-cache-ak0.pinimg.com/736x/2e/46/00/2e4600f7eab945f936f00548b5498ba4.jpg&#34; alt=&#34;Dennis Duffy: Hey Dummy&#34; /&gt;&lt;/p&gt;

&lt;p&gt;(Warning: since I&amp;rsquo;m learning this stuff as I go, my solutions and proofs won&amp;rsquo;t always be the best. In fact they&amp;rsquo;re bound to have errors. So I encourage you to contact me with corrections, and help improve these posts for others.)&lt;/p&gt;

&lt;p&gt;Now on to today&amp;rsquo;s topic: Euclidean distance as a measure of accuracy.&lt;/p&gt;

&lt;h1 id=&#34;fear-of-a-euclidean-plane&#34;&gt;Fear of a Euclidean Plane&lt;/h1&gt;

&lt;p&gt;We just saw that the laws of probability keep you close to the truth in our coin-toss example, whatever the truth turns out to be. And by &amp;ldquo;close&amp;rdquo; we meant Euclidean distance, the kind of spatial distance familiar from grade-school geometry.&lt;/p&gt;

&lt;p&gt;But people writing in the accuracy framework never use Euclidean distance. Why not? Because, it turns out, Euclidean distance is unstable!&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Unstable&amp;rdquo; how?&lt;/p&gt;

&lt;p&gt;Well, if your aim is to be as close to the truth as possible in terms of Euclidean distance, then you will almost always be driven to change your opinion to something extreme: either $(1,0)$ or $(0,1)$. And not because you get some definite information about how the coin-flip turns out. But just because of the way Euclidean distance interacts with &lt;a href=&#34;https://plato.stanford.edu/entries/rationality-normative-utility/#DefExpUti&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;expected value&lt;/em&gt;&lt;/a&gt;. (I&amp;rsquo;m going to assume you&amp;rsquo;re familiar with the notion of expected value. If not, you can read &lt;a href=&#34;(https://plato.stanford.edu/entries/rationality-normative-utility/#DefExpUti)&#34; target=&#34;_blank&#34;&gt;the linked section&lt;/a&gt; of the &lt;em&gt;SEP&lt;/em&gt; article or do a bit of googling.)&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s how that happens. Suppose your credences in heads/tails are $(.6, .4)$: you&amp;rsquo;re $60\%$ confident the coin will land heads, and $40\%$ confident it&amp;rsquo;ll land tails. What&amp;rsquo;s your &lt;em&gt;expected inaccuracy&lt;/em&gt;, then? If we think of accuracy as utility, and thus inaccuracy as disutility, how well can you expect to do by holding your current state of opinion?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s run the calculation. We&amp;rsquo;ll write $EI(x, 1-x)$ for the expected inaccuracy of having credence $x$ in heads and $1-x$ in tails.
$$
\begin{align}
EI(.6, .4) &amp;amp;= .6 \sqrt{(.6 - 1)^2 + (.4 - 0)^2} + .4 \sqrt{(.6 - 0)^2 + (.4 - 1)^2}\\&lt;br /&gt;
&amp;amp;= .6 \sqrt{(-.4)^2 + .4^2} + .4 \sqrt{.6^2 + (-.6)^2}\\&lt;br /&gt;
&amp;amp;= .678823
\end{align}
$$
Ok, not bad. But now let&amp;rsquo;s compare that to how you can expect to do if you change your opinion to the extreme state $(1,0)$:
$$
\begin{align}
EI(1, 0) &amp;amp;= .6 \sqrt{(1 - 1)^2 + (0 - 0)^2} + .4 \sqrt{(1 - 0)^2 + (0 - 1)^2}\\&lt;br /&gt;
&amp;amp;= .565685
\end{align}
$$
Some things to keep in mind here:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The numbers outside the square root symbols are $.6$ and $.4$ because those are your current beliefs, and we&amp;rsquo;re asking how well you expect to do &lt;em&gt;according to your current beliefs&lt;/em&gt;.

&lt;ul&gt;
&lt;li&gt;The numbers inside the square roots are $1$ and $0$ because we&amp;rsquo;re asking how well you expect to do by adopting those extreme opinions. So those numbers describe the outcomes whose inaccuracy we want to evaluate and weigh.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Remember, &lt;strong&gt;smaller&lt;/strong&gt; numbers are &lt;strong&gt;better&lt;/strong&gt; because we&amp;rsquo;re talking about &lt;strong&gt;in&lt;/strong&gt;accuracy.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And look: the extreme opinion $(1, 0)$ does &lt;em&gt;better&lt;/em&gt; than the more moderate opinion you actually hold, $(.6, .4)$. The extreme opinion has lower expected inaccuracy (think: higher expected accuracy).&lt;/p&gt;

&lt;p&gt;In fact, the extreme assignment does better than the moderate one &lt;em&gt;according to the moderate assignment itself&lt;/em&gt;. So your moderate opinions end up undermining themselves. They drive you to hold more extreme opinions than you initially do, in the name of accuracy.&lt;/p&gt;

&lt;p&gt;This isn&amp;rsquo;t an artifact of the particular example $(.6, .4)$. We can prove that an extreme state of opinion always does best in terms of expected inaccuracy&amp;mdash;unless you are completely uncertain about the outcome, i.e. $(.5,.5)$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
Suppose $p \in [0, 1]$ and $p \neq .5$. Then, according to the probability assignment $(p, 1-p)$, the expected Euclidean distance of any alternative assignment $(q, 1-q)$ from the points $(1,0)$ and $(0,1)$ is uniquely minimized by:
$$
q = \begin{cases}
0 &amp;amp; \mbox{ if } p &amp;lt; .5,\\&lt;br /&gt;
1 &amp;amp; \mbox{ if } p &amp;gt; .5.
\end{cases}
$$&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp;
Suppose $0 \leq p \leq 1$ and $p \neq .5$. According to the probability assignment $(p, 1-p)$, the expected Euclidean distance from $(1,0)$ and $(0,1)$ of any alternative assignment $(q, 1-q)$ is:
$$
\begin{align}
EI(q, 1-q) &amp;amp;= p \sqrt{(q - 1)^2 + ((1-q) - 0)^2}\\&lt;br /&gt;
&amp;amp;\quad + (1-p) \sqrt{(q - 0)^2 + ((1-q) - 1)^2}\\&lt;br /&gt;
&amp;amp;= p \sqrt{(q - 1)^2 + (1 - q)^2} + (1-p) \sqrt{q^2 + q^2}\\&lt;br /&gt;
&amp;amp;= p \sqrt{2} (1 - q) + (1-p) \sqrt{2} q\\&lt;br /&gt;
&amp;amp;= \sqrt{2} \left( p (1 - q) + (1-p) q \right).
\end{align}
$$
We are looking for the value of $q$ that minimizes the quantity on the last line, which is the same if we drop the $\sqrt{2}$ and just seek to minimize:
$$ p (1 - q) + (1-p) q. $$
This quantity is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Weighted_arithmetic_mean&#34; target=&#34;_blank&#34;&gt;weighted average&lt;/a&gt; of the two values $p$ and $(1-p)$, with the weights being $1-q$ and $q$, respectively. So the minimum possible value is just whichever of $p$ or $1-p$ is smaller. And this minimum is achieved when all the weight is given to the smaller value.&lt;/p&gt;

&lt;p&gt;So, if $p &amp;lt; .5$, then the minimum possible value is $p$, and it is achieved when $1 - q = 1$, and thus $q = 0$. If instead $p &amp;gt; .5$, the minimum possible value is $1 - p$ and is achieved when $q = 1$.
&lt;span style=&#34;float: right;&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Based on this proof you can also see what happens when $p=.5$. It doesn&amp;rsquo;t matter what value $q$ takes: any value $0 \leq q \leq 1$ will result in the same expected inaccuracy, namely $.5\sqrt{2}$.&lt;/p&gt;

&lt;p&gt;So here&amp;rsquo;s the problem with Euclidean distance as a way of measuring inaccuracy. As soon as you find yourself leaning one way or another on heads-vs.-tails, you&amp;rsquo;re driven to extremes. If you get information that makes heads slightly more likely, say $.51$ for example, your expected inaccuracy is minimized by leaping to the conclusion that the coin will certainly come up heads.&lt;/p&gt;

&lt;p&gt;So any probability assignment to heads/tails besides $(.5, .5)$ is self-undermining. It gives you cause to adopt some other assignment&amp;mdash;an extreme one, at that.&lt;/p&gt;

&lt;p&gt;Even at $(.5, .5)$ things aren&amp;rsquo;t so happy, btw. Any other assignment of probabilities is just as good as far as minimizing inaccuracy goes. So even if the pursuit of accuracy doesn&amp;rsquo;t &lt;em&gt;require&lt;/em&gt; you to change your opinion, it still &lt;em&gt;permits&lt;/em&gt; you to do so. As far as accuracy goes, being indifferent about the coin toss also makes you indifferent about what opinion to hold. Which is pretty strange in itself.&lt;/p&gt;

&lt;h1 id=&#34;where-this-leaves-us&#34;&gt;Where This Leaves Us&lt;/h1&gt;

&lt;p&gt;Wait a minute: if Euclidean distance is a bad way to measure inaccuracy, then what&amp;rsquo;s the use of the diagram we started with?? And what&amp;rsquo;s the right way to measure inaccuracy?&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll tackle these questions in the next post. But here&amp;rsquo;s the short answer.&lt;/p&gt;

&lt;p&gt;One common way of measuring inaccuracy is a variation on Euclidean distance called &lt;em&gt;Brier&lt;/em&gt; distance. Brier distance is just enough like Euclidean distance to vindicate the reasoning we did with our opening diagram. But it&amp;rsquo;s different enough from Euclidean distance to avoid the instability problem we ended up with.&lt;/p&gt;

&lt;p&gt;So what is Brier distance? It&amp;rsquo;s just the square of Euclidean distance. Just take the square root symbol off Euclid&amp;rsquo;s formula and you&amp;rsquo;ve got the formula for Brier distance. Next time we&amp;rsquo;ll see how that one change makes all the right differences.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>