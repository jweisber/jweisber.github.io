<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Jonathan Weisberg</title>
    <link>http://jonathanweisberg.org/post/index.xml</link>
    <description>Recent content in Posts on Jonathan Weisberg</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Dec 2017 10:36:00 -0500</lastBuildDate>
    <atom:link href="http://jonathanweisberg.org/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Call for Papers: Formal Epistemology Workshop (FEW) 2018</title>
      <link>http://jonathanweisberg.org/post/CFP%20FEW%202018/</link>
      <pubDate>Thu, 21 Dec 2017 10:36:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/CFP%20FEW%202018/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Location:&lt;/strong&gt; University of Toronto&lt;br /&gt;
&lt;strong&gt;Dates:&lt;/strong&gt; June 12–14, 2018&lt;br /&gt;
&lt;strong&gt;Keynote Speakers:&lt;/strong&gt; &lt;a href=&#34;http://www.larabuchak.net/&#34; target=&#34;_blank&#34;&gt;Lara Buchak&lt;/a&gt; and &lt;a href=&#34;https://sites.google.com/site/michaeltitelbaum/&#34; target=&#34;_blank&#34;&gt;Mike Titelbaum&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Submission Deadline:&lt;/strong&gt; February 12, 2018&lt;br /&gt;
&lt;strong&gt;Authors Notified:&lt;/strong&gt; March 31, 2018&lt;/p&gt;

&lt;p&gt;We are pleased to invite papers in formal epistemology, broadly construed to include related areas of philosophy as well as cognate disciplines like statistics, psychology, economics, computer science, and mathematics.&lt;/p&gt;

&lt;p&gt;Submissions should be:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;prepared for anonymous review,&lt;/li&gt;
&lt;li&gt;no more than 6,000 words,&lt;/li&gt;
&lt;li&gt;accompanied by an abstract of up to 300 words, and&lt;/li&gt;
&lt;li&gt;in PDF format.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Submission is via the &lt;a href=&#34;https://easychair.org/conferences/?conf=few2018&#34; target=&#34;_blank&#34;&gt;EasyChair website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The final selection of the program will be made with an eye to diversity. We especially encourage submissions from PhD candidates, early career researchers, and members of groups underrepresented in academic philosophy.&lt;/p&gt;

&lt;p&gt;Some funds are available to reimburse speakers&amp;rsquo; travel expenses. The available amounts are still being determined, but we hope to cover most/all expenses for student and early career speakers. Childcare can also be arranged.&lt;/p&gt;

&lt;p&gt;The contact address for the conference is &lt;a href=&#34;mailto:few2018toronto@gmail.com&#34; target=&#34;_blank&#34;&gt;few2018toronto@gmail.com&lt;/a&gt;. The local organizers are &lt;a href=&#34;http://www.davidjamesbar.net/&#34; target=&#34;_blank&#34;&gt;David James Barnett&lt;/a&gt;, &lt;a href=&#34;http://individual.utoronto.ca/jnagel/Home_Page.html&#34; target=&#34;_blank&#34;&gt;Jennifer Nagel&lt;/a&gt;, and &lt;a href=&#34;http://jonathanweisberg.org/&#34; target=&#34;_blank&#34;&gt;Jonathan Weisberg&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More information and a conference website are coming soon&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>REU Redux: Allais All Over Again</title>
      <link>http://jonathanweisberg.org/post/REU%20Redeux/</link>
      <pubDate>Tue, 26 Sep 2017 20:24:04 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/REU%20Redeux/</guid>
      <description>

&lt;p&gt;&lt;em&gt;This post is coauthored with &lt;a href=&#34;http://johannathoma.com/&#34; target=&#34;_blank&#34;&gt;Johanna Thoma&lt;/a&gt; and cross-posted at &lt;a href=&#34;https://choiceinference.wordpress.com/&#34; target=&#34;_blank&#34;&gt;Choice &amp;amp; Inference&lt;/a&gt;. Accompanying Mathematica code is available on &lt;a href=&#34;https://github.com/jweisber/reu&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Lara Buchak&amp;rsquo;s &lt;a href=&#34;http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199672165.001.0001/acprof-9780199672165&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt;&lt;/a&gt; advertises REU theory as able to recover the modal preferences in the Allais paradox. In &lt;a href=&#34;https://link.springer.com/content/pdf/10.1007%2Fs11098-017-0916-3.pdf&#34; target=&#34;_blank&#34;&gt;our commentary&lt;/a&gt; we challenged this claim. We pointed out that REU theory is strictly &lt;a href=&#34;https://johannathoma.files.wordpress.com/2015/08/decision-theory-open-handbook-edit.pdf#page=11&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;grand-world&amp;rdquo;&lt;/a&gt;, and in the grand-world setting it actually struggles with the Allais preferences.&lt;/p&gt;

&lt;p&gt;To demonstrate, we constructed a grand-world model of the Allais problem. We replaced each small-world outcome with a normal distribution whose mean matches its utility, and whose height corresponds to its probability.&lt;/p&gt;

&lt;p&gt;Take for example the Allais gamble:
$$(\$0, .01; \$1M, .89; \$5M, .1).$$
If we adopt &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt;&amp;rsquo;s utility assignments:
$$u(\$0) = 0, u(\$1M) = 1, u(\$5M) = 2,$$
we can depict the small-world version of this gamble:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reu_redeux/fig1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;On our grand-world model this becomes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reu_redeux/fig2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And REU theory fails to predict the usual Allais preferences on this model, provided the normal distributions used are minimally spread out.&lt;/p&gt;

&lt;p&gt;If we squeeze the normal distributions tight enough, the grand-world problem collapses into the small-world problem, and REU theory can recover the Allais preferences. But, we showed, they&amp;rsquo;d have to be squeezed absurdly tight. A small standard deviation like $\sigma = .1$ lets REU theory recover the Allais preferences.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; But it also requires outlandish certainty that a windfall of $\$$1M will lead to a better life than the one you&amp;rsquo;d expect to lead without it. The probability of a life of utility at most 0, despite winning $\$$1M, would have to be smaller than $1 \times 10^{-23}$.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; Yet the chances are massively greater than that of suffering life-ruining tragedy (illness, financial ruin&amp;hellip; &lt;em&gt;Game of Thrones&lt;/em&gt; ending happily ever after, etc.).&lt;/p&gt;

&lt;p&gt;In response Buchak offers &lt;a href=&#34;https://link.springer.com/content/pdf/10.1007%2Fs11098-017-0907-4.pdf&#34; target=&#34;_blank&#34;&gt;two replies&lt;/a&gt;. The first is a technical maneuver, adjusting the model parameters. The second is more philosophical, adjusting the target interpretation of the Allais paradox instead.&lt;/p&gt;

&lt;h1 id=&#34;first-reply&#34;&gt;First Reply&lt;/h1&gt;

&lt;p&gt;Buchak&amp;rsquo;s first reply tweaks our model in two ways. First, the mean utility of winning $\$$5M is shifted from 2 down to 1.3. Second, all normal distributions are skewed by a factor of 5 (positive 5 for utility 0, negative otherwise). So, for example, the Allais gamble pictured above becomes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reu_redeux/fig3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll focus on the second tweak here, the introduction of skew. It rests on a technical error, as we&amp;rsquo;ll show momentarily. But it also wants for motivation.&lt;/p&gt;

&lt;h2 id=&#34;motivational-problems&#34;&gt;Motivational Problems&lt;/h2&gt;

&lt;p&gt;Why should the grand-world model be skewed? And why in this particular way? Buchak writes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&amp;hellip;] receiving $\$$1M makes the worst possibilities much less likely. Receiving $\$$1M provides security in the sense of making the probability associated with lower utility values smaller and smaller. The utility of $\$$1M is concentrated around a high mean with a long tail to the left: things likely will be great, though there is some small and diminishing chance they will be fine but not great. Similarly, the utility of $\$$0 is concentrated around a low mean with a long tail to the right: things likely will be fine but not great, though there is some small and diminishing chance they will be great. In other words, $\$$1M (and $\$$5M) is a gamble with negative skew, and $\$$0 is a gamble with positive skew &lt;a href=&#34;p. 2401&#34; target=&#34;_blank&#34;&gt;&amp;hellip;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But this passage never actually identifies any asymmetry in the phenomena we&amp;rsquo;re modeling. True, &amp;ldquo;receiving $\$$1M makes the worst possibilities much less likely&amp;rdquo;, but it also makes the best possibilities much more likely. Likewise,  &amp;ldquo;[r]eceiving $\$$1M provides security in the sense of making the probability associated with lower utility values smaller and smaller.&amp;rdquo; But $\$$1M also makes the probability associated with higher utility values larger. And so on.&lt;/p&gt;

&lt;p&gt;The tendencies of large winnings to control bad outcomes and promote good outcomes was already captured in the original model. A normal distribution centered on utility 1 already admits &amp;ldquo;some small and diminishing chance that [things] will be fine but not great.&amp;rdquo; It just also admits some small chance that things will be much better than great, since it&amp;rsquo;s symmetric around utility 1. To motivate the skewed model, we&amp;rsquo;d need some reason to think this symmetry should not hold. But none has been given.&lt;/p&gt;

&lt;h2 id=&#34;technical-difficulties&#34;&gt;Technical Difficulties&lt;/h2&gt;

&lt;p&gt;Motivation aside, there is a technical fault in the skewed model.&lt;/p&gt;

&lt;p&gt;Introducing skew is supposed to make room for a reasonably large standard deviation while still recovering the Allais preferences. Buchak advertises a standard deviation&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; of $\sigma = .17$ for the skewed model, but the true value is actually $.106$&amp;mdash;essentially the same as the $.1$ value Buchak concedes is implausibly small, and seeks to avoid by introducing skew.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Where does the $.17$ figure come from then? It&amp;rsquo;s the &lt;a href=&#34;https://en.wikipedia.org/wiki/Scale_parameter&#34; target=&#34;_blank&#34;&gt;scale parameter&lt;/a&gt; of the skew normal distribution, often denoted $\omega$. For an ordinary normal distribution, the scale $\omega$ famously coincides with the standard deviation $\sigma$, and so we write $\sigma$ for both. But when we skew a normal distribution, we tighten it, shrinking the standard deviation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reu_redeux/fig4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The distributions in this figure share the same scale parameter ($.17$) but the skewed one (yellow) is much narrower.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, &lt;em&gt;Mathematica&lt;/em&gt; uses $\sigma$ for the scale parameter even in skewed normal distributions, giving the misleading impression that it&amp;rsquo;s still the standard deviation.&lt;/p&gt;

&lt;p&gt;What really matters, of course, isn&amp;rsquo;t the value of the standard deviation itself, but the probabilities that result from whatever parameters we choose. And Buchak argues that her model avoids the implausible probabilities we cited in the introduction. How can this be?&lt;/p&gt;

&lt;p&gt;Buchak says that the skewed model has &amp;ldquo;more overlap in the utility that $\$$0 and $\$$1M might deliver&amp;rdquo;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&amp;hellip;] there is a 0.003 probability that the $\$$0 gamble will deliver more than 0.5 utils, and a 0.003 probability that the $\$$1M gamble will deliver less than 0.5 utils. (p. 2402)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But this &amp;ldquo;overlap&amp;rdquo; was never the problematic quantity. The problem was, rather, that a small standard deviation like $.1$ requires you to think it less than $1 \times 10^{-23}$ likely you will end up with a life no better than $0$ utils, despite a $\$$1M windfall.&lt;/p&gt;

&lt;p&gt;On Buchak&amp;rsquo;s model this probability is still absurdly small: $4 \times 10^{-9}$.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; This is a considerable improvement over $1 \times 10^{-23}$, but it&amp;rsquo;s still not plausible. For example, it&amp;rsquo;s almost $300,000$ times more likely that one author of this post (Jonathan Weisberg) will &lt;a href=&#34;http://www.statcan.gc.ca/pub/84-537-x/2013005/tbl/tbl7a-eng.htm&#34; target=&#34;_blank&#34;&gt;die in the coming year at the ripe old age of 39&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But worst of all, any improvement here comes at an impossible price: ludicrously low probabilities on the other side. For example, the probability that the life you&amp;rsquo;ll lead with $\$$1M will end up as good as the one you&amp;rsquo;d expect with $\$$5M is so small that &lt;em&gt;Mathematica&lt;/em&gt; can&amp;rsquo;t distinguish it from zero.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:7&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:7&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; So the problem is actually worse than before, not better.&lt;/p&gt;

&lt;h1 id=&#34;second-reply&#34;&gt;Second Reply&lt;/h1&gt;

&lt;p&gt;Buchak&amp;rsquo;s second reply is that it wouldn&amp;rsquo;t in fact be a problem if REU theory could only recover the Allais preferences in a small-world setting. We should think of the Allais problem as a thought experiment: it asks us to abstract away from anything but the immediate rewards mentioned in the problem, and to think of the monetary rewards as stand-ins for things that are valuable for their own sakes.&lt;/p&gt;

&lt;p&gt;What &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; showed, according to Buchak, is that REU theory can accommodate people&amp;rsquo;s intuitions regarding such a small-world thought experiment. And this is a success, because this establishes that the theory can accommodate a certain kind of reasoning that we all engage in. Buchak moreover concedes that it may well be a mistake for agents to think of the choices they actually face in small-world terms. But she claims this is no problem for her theory:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[I]f people &amp;lsquo;really&amp;rsquo; face the simple choices, then their reasoning is correct and REU captures it. If people &amp;lsquo;really&amp;rsquo; face the complex choices, then the reasoning in favor of their preferences is misapplied, and REU does not capture their preferences. Either way, the point still stands: REU-maximization rationalizes and formally reconstructs a certain kind of intuitive reasoning, as seen through REU theory&amp;rsquo;s ability to capture preferences over highly idealized gambles to which this reasoning is relevant. (p. 2403)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But there isn&amp;rsquo;t actually an &amp;lsquo;if&amp;rsquo; here. People do really face &amp;lsquo;complex&amp;rsquo; choices as we tried to model them. Any reward from an isolated gamble an agent faces in her life really should itself be thought of as a gamble. This is not only true when the potential reward is something like money, which is only a means to something else. Even if the good in question is &amp;lsquo;ultimate&amp;rsquo;, it just adds to the larger gamble of the agent&amp;rsquo;s life she is yet to face. She might win a beautiful holiday, but she will still face 20 micromorts per day for the rest of her life (&lt;a href=&#34;https://en.wikipedia.org/wiki/Micromort#Baseline&#34; target=&#34;_blank&#34;&gt;24 if she moves from Canada to England&lt;/a&gt;). Even on our deathbeds, we are unsure about how a lot of things we care about will play out. REU theory makes this background risk relevant to the evaluation of any individual gamble.&lt;/p&gt;

&lt;p&gt;So Buchak&amp;rsquo;s response really comes to this: REU theory captures a kind of intuitive reasoning that we employ in highly idealized decision contexts, but which would be misapplied in any actual decisions agents face in their lives. This raises two questions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Why should we care about accommodating reasoning in highly idealized decision contexts?&lt;/p&gt;

&lt;p&gt;The original project of &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; was to rationally accommodate the ordinary decision-maker. But now what we are rationally accommodating are at best her responses to thought experiments that are very far removed from her real life, namely thought experiments that ask her to imagine that she faces no other risk in her life. If our model is right, then REU theory still has to declare her irrational if she acts in real life as she would in the thought experiment&amp;mdash;as presumably ordinary decision-makers do. And then we haven&amp;rsquo;t done very much to rationally accommodate her. At best, we have provided an error theory to explain her ordinary behaviour: her mistake is to treat grand-world problems like small-world problems. This is, of course, a different project than the one &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; originally embarked on. As an error theory, REU theory will have to compete with other theories of choice under uncertainty that were never meant to be theories of rationality, such as prospect theory. Moreover, there is still another open question.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Why should agents have developed a knack for the reasoning displayed in the Allais problem if it is never actually rational to use it?&lt;/p&gt;

&lt;p&gt;As a heuristic to try and approximate the behaviour of a perfectly rational system, at least in the Allais example, agents would do better to maximize expected utility&amp;mdash;which is also easier to compute. Moreover, the burden of proof is on proponents of REU theory to show that there are any grand-world decisions commonly faced by real agents where REU theory comes to a significantly different assessment than expected utility theory. Unless they can show this, expected utility theory comes out as the better heuristic more generally. It is then quite mysterious what explains our supposed employment of REU-style reasoning. Why should irrational agents, who employ it more generally, have developed a bad heuristic? And why should rational agents, who never use it in real life, develop a tendency to employ it exclusively in highly idealized thought experiments?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Ultimately, if Buchak&amp;rsquo;s first reply fails, and all we can rely on is her second reply, &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; provides us with no reason to abandon expected utility theory as our best theory of rational choice under uncertainty in actual choice scenarios. Even if we grant that REU theory is a better theory of rational choice in hypothetical scenarios we never face, this is a much less exciting result than the one &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt; advertised.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Though we need a slightly more severe risk function than that used in &lt;em&gt;Risk &amp;amp; Rationality&lt;/em&gt;: $r(p) = p^{2.05}$ instead of $r(p) = p^2$. See our original commentary for details.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:2&#34;&gt;&lt;p&gt;To get this figure we calculate the cumulative density, at zero, of the normal distribution $𝒩(1,.1)$. Using &lt;em&gt;Mathematica&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;CDF[NormalDistribution[1, .1], 0]
7.61985 × 10^-24
&lt;/code&gt;&lt;/pre&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;This is the &amp;ldquo;variance&amp;rdquo; in Buchak&amp;rsquo;s terminology, but we&amp;rsquo;ll continue to use &amp;ldquo;standard deviation&amp;rdquo; here for consistency with our previous discussion and the preferred nomenclature.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:4&#34;&gt;&lt;p&gt;In &lt;em&gt;Mathematica&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;StandardDeviation[SkewNormalDistribution[1, .17, -5]]
0.105874
&lt;/code&gt;&lt;/pre&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;Skewing also shifts the mean, we should note.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:6&#34;&gt;&lt;p&gt;In &lt;em&gt;Mathematica&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;CDF[SkewNormalDistribution[1, .17, -5], 0]
4.04475 × 10^-9
&lt;/code&gt;&lt;/pre&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:7&#34;&gt;&lt;p&gt;Here we calculate the complement of the cumulative density, at $1.3$, of the skew normal distribution with location $1$, scale $.17$, and skew $-5$. In &lt;em&gt;Mathematica&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;1 - CDF[SkewNormalDistribution[1, .17, -5], 1.3]
0.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that &lt;em&gt;Mathematica&lt;/em&gt; can estimate this value at the nearby point $1.25$, which gives us an upper bound of about $7 \times 10^{-16}$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;1 - CDF[SkewNormalDistribution[1, .17, -5], 1.25]
6.66134 × 10^-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For comparison, this probability was about $.0013$ with no skew and $\sigma = .1$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-mathematica&#34;&gt;1 - CDF[NormalDistribution[1, .1], 1.3]
0.0013499
&lt;/code&gt;&lt;/pre&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:7&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Mosteller Hall Puzzle</title>
      <link>http://jonathanweisberg.org/post/Teaching%20Monty%20Hall/</link>
      <pubDate>Wed, 14 Jun 2017 15:21:42 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Teaching%20Monty%20Hall/</guid>
      <description>&lt;p&gt;One of my favourite probability puzzles to teach is a close cousin of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Monty_Hall_problem&#34; target=&#34;_blank&#34;&gt;Monty Hall problem&lt;/a&gt;. Originally from a 1965 &lt;a href=&#34;https://books.google.ca/books/about/Fifty_Challenging_Problems_in_Probabilit.html?id=QiuqPejnweEC&#34; target=&#34;_blank&#34;&gt;book by Frederick Mosteller&lt;/a&gt;,&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; here&amp;rsquo;s my formulation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Three prisoners, A, B, and C, are condemned to die in the morning. But the king decides in the night to pardon one of them. He makes his choice at random and communicates it to the guard, who is sworn to secrecy. She can only tell the prisoners that one of them will be released at dawn.&lt;/p&gt;

&lt;p&gt;Prisoner A welcomes the news, as he now has a 1/3 chance of survival. Hoping to go even further, he says to the guard, &amp;ldquo;I know you can&amp;rsquo;t tell me whether I am condemned or pardoned. But at least one other prisoner must still be condemned, so can you just name one who is?&amp;rdquo;. The guard replies (truthfully) that B is still condemned. &amp;ldquo;Ok&amp;rdquo;, says A, &amp;ldquo;then it&amp;rsquo;s either me or C who was pardoned. So my chance of survival has gone up to &amp;frac12;&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Unfortunately for A, he is mistaken. But how?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: turns out the puzzle isn&amp;rsquo;t originally due to Mosteller after all! It appears in &lt;a href=&#34;https://www.nature.com/scientificamerican/journal/v201/n4/pdf/scientificamerican1059-174.pdf&#34; target=&#34;_blank&#34;&gt;a 1959 article&lt;/a&gt; in &lt;em&gt;Scientific American&lt;/em&gt;, by Martin Gardner.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For me it&amp;rsquo;s really intuitive that A is mistaken. The way he figures things, his chance of survival will go up to &amp;frac12; whoever the guard names in her response. But then A doesn&amp;rsquo;t even have to bother the guard. He can just skip ahead to the conclusion that his chance of survival is &amp;frac12;. And that&amp;rsquo;s absurd.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s a bit harder to say exactly &lt;em&gt;where&lt;/em&gt; A goes wrong. But I&amp;rsquo;ve always taken this puzzle to be, like Monty Hall, a lesson in Carnap&amp;rsquo;s TER: the Total Evidence Requirement.&lt;/p&gt;

&lt;p&gt;What A learns isn&amp;rsquo;t only that B is condemned, but also that the guard reports as much. And this report is more likely if C was pardoned than if A was. If C was pardoned, the guard had to name B, the only other prisoner still condemned. Whereas if A was pardoned, the guard could just as easily have named C instead.&lt;/p&gt;

&lt;p&gt;So when the guard names B, her report fits twice as well with the hypothesis that C was pardoned, not A:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/misc/mosteller_tree_diagram.png&#34; alt=&#34;Tree diagram&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Thus A&amp;rsquo;s chance of being condemned remains twice that of being pardoned.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re like me, this reasoning will actually be less intuitive than the initial, gut feeling that A must be mistaken (because her logic would make it unnecessary to consult the guard). The argument is still instructive though, for several reasons:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;It shows how the initial, gut feeling is consistent with the probability axioms. We&amp;rsquo;ve constructed a plausible probability model that vindicates it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Total Evidence Requirement makes the difference in this model. Learning merely that B is condemned would have a different effect in this model. A&amp;rsquo;s chance of survival really would go up to &amp;frac12; then.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;These lessons can be carried over to Monty Hall. The same model yields the correct solution there, with the TER playing out in a parallel way.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And that last point is the real point of this post. As my colleague &lt;a href=&#34;http://www.sergiotenenbaum.org/&#34; target=&#34;_blank&#34;&gt;Sergio Tenenbaum&lt;/a&gt; pointed out in conversation, it means you can use Mosteller&amp;rsquo;s puzzle to teach Monty Hall. Because, unlike in Monty Hall, &lt;em&gt;the intuitive judgment is the correct one in Mosteller&amp;rsquo;s puzzle&lt;/em&gt;. So you can use it to get students on board with the less intuitive (but entirely correct) argument we used to resolve Mosteller&amp;rsquo;s puzzle.&lt;/p&gt;

&lt;p&gt;Once students have seen how important it is to set up the probability model correctly, so that the Total Evidence Requirement can do its work, they may be more comfortable using the same technique on Monty Hall.&lt;/p&gt;

&lt;p&gt;There are other ways of bringing students around to the correct solution to Monty Hall, of course. You can run them through a variant with a hundred doors instead of three; you can invite them to consider what would happen in the long run in repeated games; you can ask them how things would have been different had Monty opened the other door instead.&lt;/p&gt;

&lt;p&gt;These are all worthy heuristics. And I expect different ones will click for different students.&lt;/p&gt;

&lt;p&gt;But for my money, there&amp;rsquo;s nothing like a simple and concrete model to help me get oriented and shake off that befuddled feeling. And, in this case, Mosteller&amp;rsquo;s puzzle helps make the model more intuitive, hence more memorable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://68.media.tumblr.com/776dfc1f8b3baa0309b41c6a90ea1a13/tumblr_nd53ozBNz81qj0u7fo1_r1_400.gif&#34; alt=&#34;Fainting Goat&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;So I think it actually predates Monty Hall, though I gather this general family of puzzles goes back at least to 1889 and &lt;a href=&#34;https://en.wikipedia.org/wiki/Bertrand%27s_box_paradox&#34; target=&#34;_blank&#34;&gt;Bertrand&amp;rsquo;s box paradox&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 7: Dominance</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%207%20-%20Brier%20Dominance/</link>
      <pubDate>Wed, 07 Jun 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%207%20-%20Brier%20Dominance/</guid>
      <description>

&lt;p&gt;In our &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 5 - Convexity/&#34;&gt;last&lt;/a&gt; &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 6 - Obtusity/&#34;&gt;two&lt;/a&gt; posts we established two key facts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The set of possible probability assignments is convex.&lt;/li&gt;
&lt;li&gt;Convex sets are &amp;ldquo;obtuse&amp;rdquo;. Given a point outside a convex set, there&amp;rsquo;s a point inside that forms a right-or-obtuse angle with any third point in the set.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Today we&amp;rsquo;re putting them together to get the central result of the accuracy framework, the Brier dominance theorem. We&amp;rsquo;ll show that a non-probabilistic credence assignment is always &amp;ldquo;Brier dominated&amp;rdquo; by some probabilistic one. That is, there is always a probabilistic assignment that is closer, in terms of Brier distance, to every possible truth-value assignment.&lt;/p&gt;

&lt;p&gt;In fact we&amp;rsquo;ll show something a bit more general. We&amp;rsquo;ll show that there&amp;rsquo;s a probability assignment that&amp;rsquo;s closer to all the possible &lt;em&gt;probability&lt;/em&gt; assignments. But truth-value assignments are probability assignments, just extreme ones. So the result we really want follows straight away as a special case.$
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\x}{\vec{x}}
\newcommand{\y}{\vec{y}}
\newcommand{\z}{\vec{z}}
\newcommand{\v}{\vec{v}}
\newcommand{\p}{\vec{p}}
\newcommand{\q}{\vec{q}}
\newcommand{\B}{B}
\newcommand{\R}{\mathbb{R}}
\newcommand{\EIpq}{EI_{\p}(\q)}\newcommand{\EIpp}{EI_{\p}(\p)}
$&lt;/p&gt;

&lt;h1 id=&#34;recap&#34;&gt;Recap&lt;/h1&gt;

&lt;p&gt;For reference, let&amp;rsquo;s collect our notation, terminology, and previous results, so that we have everything in one place.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re using $n$ for the number of possibilities under consideration. And we use bold letters like $\x$ and $\p$ to represent $n$-tuples of real numbers. So $\p = (p_1, \ldots, p_n)$ is a point in $n$-dimensional space: a member of $\R^n$.&lt;/p&gt;

&lt;p&gt;We call $\p$ a &lt;em&gt;probability assignment&lt;/em&gt; if its coordinates are (a) all nonnegative, and (b) they sum to $1$. And we write $P$ for the set of all probability assignments.&lt;/p&gt;

&lt;p&gt;We call $\v$ a &lt;em&gt;truth-value assignment&lt;/em&gt; if its coordinates are all zeros except for a single $1$. And we write $V$ for the set of all truth-value assignments.&lt;/p&gt;

&lt;p&gt;A point $\y$ is a &lt;em&gt;mixture&lt;/em&gt; of the points $\x_1, \ldots, \x_n$ if there are real numbers $\lambda_1, \ldots, \lambda_n$ such that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\lambda_i \geq 0$ for all $i$,&lt;/li&gt;
&lt;li&gt;$\lambda_1 + \ldots + \lambda_n = 1$, and&lt;/li&gt;
&lt;li&gt;$\y = \lambda_1 \x_1 + \ldots + \lambda_n \x_n$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We say that a set is &lt;em&gt;convex&lt;/em&gt; if it is closed under mixing, i.e. any mixture of elements in the set is also in the set.&lt;/p&gt;

&lt;p&gt;The difference between two points, $\x - \y$, is defined coordinate-wise:
  $$ \x - \y = (x_1 - y_1, \ldots, x_n - y_n). $$
The &lt;em&gt;dot product&lt;/em&gt; of two points $\x$ and $\y$ is written $\x \cdot \y$, and is defined:
  $$ \x \cdot \y = x_1 y_1 + \ldots + x_n y_n. $$
As a reminder, the dot product returns a single, real number (not another $n$-dimensional point as one might expect). And the sign of the dot product reflects the angle between $\x$ and $\y$ when viewed as vectors/arrows. In particular, $\x \cdot \y \leq 0$ corresponds to a right-or-obtuse angle.&lt;/p&gt;

&lt;p&gt;Finally, $\B(\x,\y)$ is the Brier distance between $\x$ and $\y$, which can be defined:
  $$
  \begin{align}
    \B(\x,\y) &amp;amp;= (\x - \y)^2\\&lt;br /&gt;
              &amp;amp;= (\x - \y) \cdot (\x - \y).
  \end{align}
  $$&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s restate the two key theorems we&amp;rsquo;ll be relying on.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem (Convexity).&lt;/strong&gt;&amp;nbsp;
The set of probability functions $P$ is convex.&lt;/p&gt;

&lt;p&gt;We established this in &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 5 - Convexity/&#34;&gt;Part 5&lt;/a&gt; of this series. In particular, we showed that $P$ is the &amp;ldquo;convex hull&amp;rdquo; of $V$: the set of all mixtures of points in $V$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lemma (Obtusity).&lt;/strong&gt;&amp;nbsp;
If $S$ is convex, $\x \not \in S$, and $\y \in S$ minimizes $\B(\y,\x)$ as a function of $\y$ on the domain $S$, then for any $\z \in S$, $(\x - \y) \cdot (\z - \y) \leq 0$.&lt;/p&gt;

&lt;p&gt;The intuitive idea behind this lemma, which we proved last time in &lt;a href=&#34;(/post/Accuracy for Dummies - Part 6 - Obtusity/)&#34; target=&#34;_blank&#34;&gt;Part 6&lt;/a&gt;, can be illustrated with a diagram:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/ObtusityLemma3.png&#34; alt=&#34;&#34; /&gt;
Given a point outside a convex set, we can find a point inside (the closest point) that forms a right-or-obtuse angle with all other points in the set.&lt;/p&gt;

&lt;p&gt;What we&amp;rsquo;ll show next is the natural and intuitive consequence: that point $\y$ is thus closer to any point $\z$ of $S$ than $\x$ is.&lt;/p&gt;

&lt;h1 id=&#34;the-brier-dominance-theorem&#34;&gt;The Brier Dominance Theorem&lt;/h1&gt;

&lt;p&gt;Intuitively, we want to show that if the angle formed at point $\y$ with the points $\x$ and $\z$ is right-or-obtuse, then $\y$ must be closer to $\z$ than $\x$ is (in Brier distance).&lt;/p&gt;

&lt;p&gt;Formally, a right-or-obtuse angle corresponds to a dot product less than or equal to zero: $(\x - \y) \cdot (\z - \y) \leq 0$. But if $\x = \y$, then the dot product will be zero trivially. So the precise statement of our theorem is:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
If $(\x - \y) \cdot (\z - \y) \leq 0$ and $\x \neq \y$, then $\B(\x,\z) &amp;gt; \B(\y,\z)$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;  To start, we establish a general identity via algebra:
  $$
  \begin{align}
  \B(\x, \z) - \B(\x, \y) - \B(\y,\z)
    &amp;amp;= (\x - \z)^2 - (\x - \y)^2 - (\y - \z)^2\\&lt;br /&gt;
    &amp;amp;= -2\y^2 - 2 \x \cdot \z + 2 \x \cdot \y + 2 \y \cdot \z\\&lt;br /&gt;
    &amp;amp;= -2 (\x - \y) \cdot (\z - \y).
  \end{align}
  $$
Now suppose $ (\x - \y) \cdot (\z - \y) \leq 0$. Then, given the negative sign on the $-2$ in the established identity,
  $$ \B(\x, \z) - \B(\x, \y) - \B(\y,\z) \geq 0, $$
from which we derive
  $$ \B(\x, \z)  \geq \B(\x, \y) + \B(\y,\z). $$
Now, since $\x \neq \y$ by hypothesis, $\B(\x,\y) &amp;gt; 0$. Thus $\B(\x,\z) &amp;gt; \B(\y,\z)$, as desired.
&lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;It follows now that if $\x$ isn&amp;rsquo;t a probability assignment, there&amp;rsquo;s a probability assignment that&amp;rsquo;s closer to every truth-value assignment than $\x$ is.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Corollary (Brier Dominance).&lt;/strong&gt; If $\x \not \in P$ then there is a $\p \in P$ such that $\B(\p,\v) &amp;lt; \B(\x, \v)$ for all $\v \in V$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;  Fix $\x \not \in P$, and let $\p$ be the member of $P$ that minimizes $B(\y,\x)$ as a function of $\y$. The Convexity theorem tells us that $P$ is convex, so the Obtusity lemma implies $(\x - \p) \cdot (\v - \p) \leq 0$ for every $\v \in V$. And since $\x \neq \p$ (because $\x \not \in P$), the last theorem entails $\B(\p,\v) &amp;lt; \B(\x, \v)$, as desired.
&lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;This is the core of the main result we&amp;rsquo;ve been working towards. Hooray! But, we still have one piece of unfinished business. For what if $\p$ is itself dominated??&lt;/p&gt;

&lt;h1 id=&#34;undominated-dominance&#34;&gt;Undominated Dominance&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;ve shown that credences which violate the probability axioms are always &amp;ldquo;accuracy dominated&amp;rdquo; by some assignment of credences that obeys those axioms. But what if those dominating, probabilistic credences are themselves dominated? &lt;em&gt;What if they&amp;rsquo;re dominated by non-probabilistic credences??&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For all we&amp;rsquo;ve said, that&amp;rsquo;s a real possibility. And if it actually obtains, then there&amp;rsquo;s nothing especially accuracy-conducive about the laws of probability. So we had better rule this possibility out. Luckily, that&amp;rsquo;s pretty easy to do.&lt;/p&gt;

&lt;p&gt;In fact, the reals work here was already done back in &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 3/&#34;&gt;Part 3&lt;/a&gt; of the series. There we showed that Brier distance is a &amp;ldquo;proper&amp;rdquo; measure of inaccuracy: each probability assignment expects itself to do best with respect to accuracy, if inaccuracy is measured by Brier distance.&lt;/p&gt;

&lt;p&gt;As a reminder, we wrote $\EIpq$ for the expected inaccuracy of probability assignment $\q$ according to assignment $\p$. When inaccuracy is measured in terms of Brier distance:
$$ \EIpq = p_1 \B(\q,\v_1) + p_2 \B(\q,\v_2) + \ldots + p_n \B(\q,\v_n). $$
Here $\v_i$ is the truth-value assignment with a $1$ in the $i$-th coordinate, and $0$ everywhere else. What we showed in Part 3 was:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
$\EIpq$ is uniquely minimized when $\q = \p$.&lt;/p&gt;

&lt;p&gt;And notice, this would be impossible if there were some $\q$ such that $\B(\q,\v_i) \leq \B(\p,\v_i)$ for all $i$. For then the weighted average $\EIpq$ would have to be no larger than $\EIpp$. And this contradicts the theorem, which says that $\EIpq &amp;gt; \EIpp$ for all $\q \neq \p$.&lt;/p&gt;

&lt;p&gt;So, at long last, we have the full result we want:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Corollary (Undominated Brier Dominance).&lt;/strong&gt; If $\x \not \in P$ then there is a $\p \in P$ such that $\B(\p,\v) &amp;lt; \B(\x, \v)$ for all $\v \in V$. Moreover, there is no $\q \in P$ such that $\B(\q,\v) \leq \B(\p, \v)$ for all $\v \in V$.&lt;/p&gt;

&lt;p&gt;So the laws of probability really are specially conducive to accuracy, as measured using Brier distance. Only probabilistic credence assignments are undominated.&lt;/p&gt;

&lt;h1 id=&#34;where-to-next&#34;&gt;Where to Next?&lt;/h1&gt;

&lt;p&gt;That&amp;rsquo;s a pretty sweet result. And it raises plenty of fun and interesting questions we could look at next. Here are three:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;What about other ways of measuring inaccuracy besides Brier? Are there reasonable alternatives, and if so, do similar results apply to them?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What about other probabilistic principles, like Conditionalization, the Principal Principle, or the Principle of Indifference? Can we take this approach beyond the probability axioms?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Speaking of the probability axioms, we&amp;rsquo;ve been working with a pretty paired down conception of a &amp;ldquo;probability assignment&amp;rdquo;. Usually we assign probabilities not just to atomic possibilities, but to disjunctions/sets of possibilities: e.g. &amp;ldquo;the prize is behind either door #1 or door #2&amp;rdquo;. Can we extend this result to such &amp;ldquo;super-atomic&amp;rdquo; probability assignments?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We&amp;rsquo;ll tackle some or all of these questions in future posts. But I haven&amp;rsquo;t yet decided which ones or in what order.&lt;/p&gt;

&lt;p&gt;So for now let&amp;rsquo;s just stop and appreciate the work we&amp;rsquo;ve already done. Because not only have we proved one of the most central and interesting results of the accuracy framework. But also, in a lot of ways the hardest work is already behind us. If you&amp;rsquo;ve come this far, I think you deserve a nice pat on the back.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i1145.photobucket.com/albums/o503/KimmieRocks/tumblr_liqmv89ru51qb2dn6.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Journal Submission Rates by Gender: A Look at the APA/BPA Data</title>
      <link>http://jonathanweisberg.org/post/A%20Look%20at%20the%20APA-BPA%20Data/</link>
      <pubDate>Tue, 06 Jun 2017 11:45:04 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/A%20Look%20at%20the%20APA-BPA%20Data/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; &lt;em&gt;editors at CJP and Phil Quarterly have kindly shared some important, additional information. See the edit below for details.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A &lt;a href=&#34;https://link.springer.com/article/10.1007/s11098-017-0919-0&#34; target=&#34;_blank&#34;&gt;new paper&lt;/a&gt; on the representation of women in philosophy journals prompted some debate in the philosophy blogosphere last week. The paper found women to be underrepresented across a range of prominent journals, yet overrepresented in the two journals studied where review was non-anonymous.&lt;/p&gt;

&lt;p&gt;Commenters &lt;a href=&#34;http://dailynous.com/2017/05/26/women-philosophy-journals-new-data/&#34; target=&#34;_blank&#34;&gt;over at Daily Nous&lt;/a&gt; complained about the lack of base-rate data. How many of the submissions to these journals were from women? In some respects, it&amp;rsquo;s hard to know what to make of these findings without such data.&lt;/p&gt;

&lt;p&gt;A few commenters linked to &lt;a href=&#34;http://www.apaonline.org/resource/resmgr/journal_surveys_2014/apa_bpa_survey_data_2014.xlsx&#34; target=&#34;_blank&#34;&gt;a survey&lt;/a&gt; conducted by the APA and BPA a while back, which supplies some numbers along these lines. I was surprised, because I&amp;rsquo;ve wondered about these numbers, but I didn&amp;rsquo;t recall seeing this data-set before. I was excited too because the data-set is huge, in a way: it covers more than 30,000 submissions at 40+ journals over a span of three years!&lt;/p&gt;

&lt;p&gt;So I was keen to give it a closer look. This post walks through that process. But I should warn you up front that the result is kinda disappointing.&lt;/p&gt;

&lt;h1 id=&#34;initial-reservations&#34;&gt;Initial Reservations&lt;/h1&gt;

&lt;p&gt;Right away some conspicuous omissions stand out.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; A good number of the usual suspects aren&amp;rsquo;t included, like &lt;em&gt;Philosophical Studies&lt;/em&gt;, &lt;em&gt;Analysis&lt;/em&gt;, and &lt;em&gt;Australasian Journal of Philosophy&lt;/em&gt;. So the usual worries about response rates and selection bias apply.&lt;/p&gt;

&lt;p&gt;The data are also a bit haphazard and incomplete. Fewer than half of the journals that responded included gender data. And some of those numbers are suspiciously round.&lt;/p&gt;

&lt;p&gt;Still, there&amp;rsquo;s hope. We have data on over ten thousand submissions even after we exclude journals that didn&amp;rsquo;t submit any gender data. As long as they paint a reasonably consistent picture, we stand to learn a lot.&lt;/p&gt;

&lt;h1 id=&#34;first-pass&#34;&gt;First Pass&lt;/h1&gt;

&lt;p&gt;For starters we&amp;rsquo;ll just do some minimal cleaning. We&amp;rsquo;ll exclude data from 2014, since almost no journals supplied it. And we&amp;rsquo;ll lump together the submissions from the remaining three years, 2011&amp;ndash;13, since the gender data isn&amp;rsquo;t broken down by year.&lt;/p&gt;

&lt;p&gt;We can then calculate the following cross-journal tallies for 2011&amp;ndash;13:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Accepted submissions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Rejected submissions&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Men&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;792&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9104&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Women&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;213&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1893&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The difference here looks notable at first: 17.5% of submitted papers came from women compared with  21.2% of accepted papers, a statistically significant difference (&lt;em&gt;p&lt;/em&gt; = 0.002).&lt;/p&gt;

&lt;p&gt;But if we plot the data by journal, the picture becomes much less clear:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/apa_bpa_data_files/unnamed-chunk-3-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;The dashed line&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; indicates parity: where submission and acceptance rate would be equal. At journals above the line, women make up a larger portion of published authors than they do submitting authors. At journals below the line, it&amp;rsquo;s the reverse.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s pretty striking how much variation there is between journals. For example, &lt;em&gt;BJPS&lt;/em&gt; is 12 points above the parity line while &lt;em&gt;Phil Quarterly&lt;/em&gt; is 9 points below it.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s also notable that it&amp;rsquo;s the largest journals which diverge the most from parity: &lt;em&gt;BJPS&lt;/em&gt;, &lt;em&gt;EJP&lt;/em&gt;, &lt;em&gt;MIND&lt;/em&gt;, and &lt;em&gt;Phil Quarterly&lt;/em&gt;. (Note: &lt;em&gt;Hume Studies&lt;/em&gt; is actually the most extreme by far. But I&amp;rsquo;ve excluded it from the plot because it&amp;rsquo;s very small, and as an extreme outlier it badly skews the &lt;em&gt;y&lt;/em&gt;-axis.)&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s hard to see all the details in the plot, so here&amp;rsquo;s the same data in a table.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Journal&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;submissions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;accepted&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;% submissions women&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;% accepted women&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Ancient Philosophy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;346&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;63&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;24&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;British Journal for the Philosophy of Science&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1267&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;117&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;27&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Canadian Journal of Philosophy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;792&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;132&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;21&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Dialectica&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;826&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12.05&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;15.48&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;European Journal for Philosophy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1554&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;98&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11.84&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hume Studies&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;152&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;23.7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;58.1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Journal of Applied Philosophy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;510&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;47&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Journal of Political Philosophy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1143&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;53&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;30&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;MIND&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1498&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Oxford Studies in Ancient Philosophy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;290&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20.3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Philosophy East and West&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;320&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;15&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Phronesis&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;388&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;The Journal of Aesthetics and Art Criticism&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;611&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;93&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;27&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;The Philosophical Quarterly&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2305&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;rounders-removed&#34;&gt;Rounders Removed&lt;/h1&gt;

&lt;p&gt;I mentioned that some of the numbers look suspiciously round. Maybe 10% of submissions to &lt;em&gt;MIND&lt;/em&gt; really were from women, compared with 5% of accepted papers. But some of these cases probably involve non-trivial rounding, maybe even eyeballing or guesstimating. So let&amp;rsquo;s see how things look without them.&lt;/p&gt;

&lt;p&gt;If we omit journals where both percentages are round (integer multiples of 5), that leaves ten journals. And the gap from before is even more pronounced: 16.3% of submissions from women compared with  22.9% of accepted papers (&lt;em&gt;p&lt;/em&gt; = 0.0000003).&lt;/p&gt;

&lt;p&gt;But it&amp;rsquo;s still a few, high-volume journals driving the result: &lt;em&gt;BJPS&lt;/em&gt; and &lt;em&gt;EJP&lt;/em&gt; do a ton of business, and each has a large gap. So much so that they&amp;rsquo;re able to overcome the opposite contribution of &lt;em&gt;Phil Quarterly&lt;/em&gt; (which does a mind-boggling amount of business!).&lt;/p&gt;

&lt;h1 id=&#34;editors-anonymous&#34;&gt;Editors Anonymous&lt;/h1&gt;

&lt;p&gt;Naturally I fell to wondering how these big journals differ in their editorial practices. What are they doing differently that leads to such divergent results?&lt;/p&gt;

&lt;p&gt;One thing the data tell us is which journals practice fully anonymous review, with even the editors ignorant of the author&amp;rsquo;s identity. That narrows it down to just three journals: &lt;em&gt;CJP&lt;/em&gt;, &lt;em&gt;Dialectica&lt;/em&gt;, and &lt;em&gt;Phil Quarterly&lt;/em&gt;.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; The tallies then are:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Accepted submissions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Rejected submissions&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Men&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;240&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3103&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Women&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;537&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;And now the gap is gone: 14.8% of submissions from women, compared with 15.2% of accepted papers&amp;mdash;not a statistically significant difference (&lt;em&gt;p&lt;/em&gt; = 0.91). That makes it look like the gap is down to editors&amp;rsquo; decisions being influenced by knowledge of the author&amp;rsquo;s gender (whether deliberately or unconsciously).&lt;/p&gt;

&lt;p&gt;But notice again, &lt;em&gt;Phil Quarterly&lt;/em&gt; is still a huge part of this story. It&amp;rsquo;s their high volume and unusually negative differential that compensates for the more modest, positive differentials at &lt;em&gt;CJP&lt;/em&gt; and &lt;em&gt;Dialectica&lt;/em&gt;. So I still want to know more about &lt;em&gt;Phil Quarterly&lt;/em&gt;, and what might explain their unusually negative differential.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit&lt;/strong&gt;: editors at &lt;em&gt;CJP&lt;/em&gt; and &lt;em&gt;Phil Quarterly&lt;/em&gt; kindly wrote with the following, additional information.&lt;/p&gt;

&lt;p&gt;At &lt;em&gt;CJP&lt;/em&gt;, the author&amp;rsquo;s identity is withheld from the editors while they decide whether to send the paper for external review, but then their identity is revealed (presumably to avoid inviting referees who are unacceptably close to the author&amp;mdash;e.g. those identical to the author).&lt;/p&gt;

&lt;p&gt;And chairman of &lt;em&gt;Phil Quarterly&lt;/em&gt;&amp;rsquo;s editorial board, Jessica Brown, writes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;the PQ is very aware of issues about the representation of women, unsurprisingly given that the editorial board consists of myself, Sarah Broadie and Sophie-Grace Chappell. We monitor data on submissions by women and papers accepted in the journal every year.&lt;/li&gt;
&lt;li&gt;the PQ has for many years had fully anonymised processing including the point at which decisions on papers are made (i.e. accept, reject, R and R etc). So, when we make such decisions we have no idea of the identity of the author.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;While in some years the data has concerned us, more recently the figures do look better which is encouraging:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;16-17: 25% declared female authored papers accepted; 16% submissions&lt;/li&gt;
&lt;li&gt;15-16: 14% accepted; 15% submissions&lt;/li&gt;
&lt;li&gt;14-15: 16% accepted; 16% submissions&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;a-gruesome-conclusion&#34;&gt;A Gruesome Conclusion&lt;/h1&gt;

&lt;p&gt;In the end, I don&amp;rsquo;t see a clear lesson here. Before drawing any conclusions from the aggregated, cross-journal tallies, it seems we&amp;rsquo;d need to know more about the policies and practices of the journals driving them. Otherwise we&amp;rsquo;re liable to be misled to a false generalization about a heterogeneous group.&lt;/p&gt;

&lt;p&gt;Some of that policy-and-practice information is probably publicly available; I haven&amp;rsquo;t had a chance to look. And I bet a lot of it is available informally, if you just talk to the right people. So this data-set could still be informative on our base-rate question. But sadly, I don&amp;rsquo;t think I&amp;rsquo;m currently in a position to make informative use of it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/ojvPBaY.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;technical-note&#34;&gt;Technical Note&lt;/h1&gt;

&lt;p&gt;This post was written in R Markdown and the source is &lt;a href=&#34;https://github.com/jweisber/rgo/blob/master/apa bpa data/apa_bpa_data.Rmd&#34; target=&#34;_blank&#34;&gt;available on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;No, I don&amp;rsquo;t mean &lt;em&gt;Ergo&lt;/em&gt;! We published our first issue in 2014 while the survey covers mainly 2011&amp;ndash;13.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;&lt;strong&gt;Edit&lt;/strong&gt;: the parity line was solid blue originally. But that misled some people into reading it as a fitted line. For reference and posterity, &lt;a href=&#34;http://jonathanweisberg.org/img/apa_bpa_data_files/unnamed-chunk-3-2.png&#34;&gt;the original image is here&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;That&amp;rsquo;s if we continue to exclude journals with very round numbers. Adding these journals back in doesn&amp;rsquo;t change the following result, though.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 6: Obtusity</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%206%20-%20Obtusity/</link>
      <pubDate>Wed, 24 May 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%206%20-%20Obtusity/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 5 - Convexity/&#34;&gt;Last time&lt;/a&gt; we saw that the set of probability assignments is &lt;em&gt;convex&lt;/em&gt;. Today we&amp;rsquo;re going to show that convex sets have a special sort of &amp;ldquo;obtuse&amp;rdquo; relationship with outsiders. Given a point &lt;em&gt;outside&lt;/em&gt; a convex set, there is always a point &lt;em&gt;in&lt;/em&gt; the set that forms a right-or-obtuse angle with it.&lt;/p&gt;

&lt;p&gt;Recall our 2D diagram from the first post. The convex set of interest here is the diagonal line segment from $(0,1)$ to $(1,0)$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For any point outside the diagonal, like $c^* $, there is a point like $c&amp;rsquo;$ on it that forms a right angle with all other points on the diagonal. As a result, $c&amp;rsquo;$ is closer to all other points on the diagonal than $c^* $ is. In particular, $c&amp;rsquo;$ is closer to both vertices, so it&amp;rsquo;s always more accurate than $c^*$. It&amp;rsquo;s &amp;ldquo;closer to the truth&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;The insider point $c&amp;rsquo;$ that we used in this case is the closest point on the diagonal to $c^*$. That&amp;rsquo;s what licenses the right-triangle reasoning here. Today we&amp;rsquo;re generalizing this strategy to $n$ dimensions.&lt;/p&gt;

&lt;p&gt;To do that, we need some tools for reasoning about $n$-dimensional geometry.$
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\x}{\vec{x}}
\newcommand{\y}{\vec{y}}
\newcommand{\z}{\vec{z}}
\newcommand{\B}{B}
$&lt;/p&gt;

&lt;h1 id=&#34;arithmetic-with-arrows&#34;&gt;Arithmetic with Arrows&lt;/h1&gt;

&lt;p&gt;You&amp;rsquo;re familiar with arithmetic in one dimension: adding, subtracting, and multiplying single numbers. What about points in $n$ dimensions?&lt;/p&gt;

&lt;p&gt;We introduced two ideas for arithmetic with points last time. We&amp;rsquo;ll add a few more today, and also talk about what they mean geometrically.&lt;/p&gt;

&lt;p&gt;Suppose you have two points $\x$ and $\y$ in $n$ dimensions:
  $$
  \begin{align}
    \x &amp;amp;= (x_1, \ldots, x_n),\\&lt;br /&gt;
    \y &amp;amp;= (y_1, \ldots, y_n).
  \end{align}
  $$
Their sum $\x + \y$, as we saw last time, is defined as follows:
  $$ \x + \y = (x_1 + y_1, \ldots, x_n + y_n). $$
In other words, points are added coordinate-wise.&lt;/p&gt;

&lt;p&gt;This definition has a natural, geometric meaning we didn&amp;rsquo;t mention last time. Start by thinking of $\x$ and $\y$ as &lt;em&gt;vectors&lt;/em&gt;&amp;mdash;as arrows pointing from the origin to the points $\x$ and $\y$. Then $\x + \y$ just amounts to putting the two arrows end-to-point and taking the point at the end:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorAddition.png&#34; alt=&#34;&#34; /&gt;
(Notice that we&amp;rsquo;re continuing our usual practice of bold letters for points/vectors like $\x$ and $\y$, and italics for single numbers like $x_1$ and $y_3$.)&lt;/p&gt;

&lt;p&gt;You can also multiply a vector $\x$ by a single number, $a$. The definition is once again coordinate-wise:
  $$ a \x = (a x_1, \ldots, a x_n). $$
And again there&amp;rsquo;s a natural, geometric meaning. We&amp;rsquo;ve lengthened the vector $\x$ by a factor of $a$.
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorMultiplication.png&#34; alt=&#34;&#34; /&gt;
Notice that if $a$ is between $0$ and $1$, then &amp;ldquo;lengthening&amp;rdquo; is actually shortening. For example, multiplying a vector by $a = 1/ 2$ makes it half as long.&lt;/p&gt;

&lt;p&gt;If $a$ is negative, then multiplying by $a$ reverses the direction of the arrow. For example, multiplying the northeasterly arrow $(1,1)$ by $-1$ yields the southwesterly arrow pointing to $(-1,-1)$.&lt;/p&gt;

&lt;p&gt;That means we can define subtraction in terms of addition and multiplication by negative one (just as with single numbers):
  $$
  \begin{align}
    \x - \y &amp;amp;= \x + (-1 \times \y)\\&lt;br /&gt;
            &amp;amp;= (x_1 - y_1, \ldots, x_n - y_n).
  \end{align}
  $$
So vector subtraction amounts to coordinate-wise subtraction.&lt;/p&gt;

&lt;p&gt;But what about multiplying two vectors? That&amp;rsquo;s actually different from what you might expect! We don&amp;rsquo;t just multiply coordinate-wise. We do that &lt;strong&gt;and then add up the results&lt;/strong&gt;:
  $$ \x \cdot \y = x_1 y_1 + \ldots + x_n y_n. $$
So the product of two vectors is &lt;strong&gt;not a vector&lt;/strong&gt;, but a number. That number is called the &lt;em&gt;dot product&lt;/em&gt;, $\x \cdot \y$.&lt;/p&gt;

&lt;p&gt;Why are dot products defined this way? Why do we add up the results of coordinate-wise multiplication to get a single number? Because it yields a more useful extension of the concept of multiplication from single numbers to vectors. We&amp;rsquo;ll see part of that in a moment, in the geometric meaning of the dot product.&lt;/p&gt;

&lt;p&gt;(There&amp;rsquo;s an algebraic side to the story too, having to do with the axioms that characterize the real numbers&amp;mdash;&lt;a href=&#34;https://en.wikipedia.org/wiki/Field_(mathematics)&#34; target=&#34;_blank&#34;&gt;the field axioms&lt;/a&gt;. We won&amp;rsquo;t go into that, but it comes out in &lt;a href=&#34;http://www.youtube.com/watch?v=63HpaUFEtXY&amp;amp;t=8m28s&#34; target=&#34;_blank&#34;&gt;this bit&lt;/a&gt; of a beautiful lecture by Francis Su, especially around &lt;a href=&#34;http://www.youtube.com/watch?v=63HpaUFEtXY&amp;amp;t=11m45s&#34; target=&#34;_blank&#34;&gt;the 11:45 mark&lt;/a&gt;.)&lt;/p&gt;

&lt;h1 id=&#34;signs-and-their-significance&#34;&gt;Signs and Their Significance&lt;/h1&gt;

&lt;p&gt;In two dimensions, a right angle has a special algebraic property: the dot-product of two arrows making the angle is always zero.&lt;/p&gt;

&lt;p&gt;Imagine a right triangle at the origin, with one leg going up to the point $(0,1)$ and the other leg going out to $(1,0)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorRightAngle.png&#34; alt=&#34;&#34; /&gt;
The dot product of those two vectors is $(1,0) \cdot (0,1) = 1 \times 0 + 0 \times 1 = 0$. One more example: consider the right angle formed by the vectors $(-3,3)$ and $(1,1)$.
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorRightAngle2.png&#34; alt=&#34;&#34; /&gt;
Again, the dot product is $(-3,3) \cdot (1,1) = -3 \times 1 + 3 \times 1 = 0.$&lt;/p&gt;

&lt;p&gt;Going a bit further: the dot product is always positive for acute angles, and negative for obtuse angles. Take the vectors $(5,0)$ and $(-1,1)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorObtuseAngle.png&#34; alt=&#34;&#34; /&gt;
Then we have $(5,0) \cdot (-1,1) = -5$. Whereas for $(5,0)$ and $(1,1)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/VectorAcuteAngle.png&#34; alt=&#34;&#34; /&gt;
we find $(5,0) \cdot (1,1) = 5$.&lt;/p&gt;

&lt;p&gt;So the sign of the dot-product reflects the angle formed by the vectors $\x$ and $\y$:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;acute angle: $\x \cdot \y &amp;gt; 0$,&lt;/li&gt;
&lt;li&gt;right angle: $\x \cdot \y = 0$,&lt;/li&gt;
&lt;li&gt;obtuse angle: $\x \cdot \y &amp;lt; 0$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That&amp;rsquo;s going to be key in generalizing to $n$ dimensions, where reasoning with diagrams breaks down. But first, one last bit of groundwork.&lt;/p&gt;

&lt;h1 id=&#34;algebra-with-arrows&#34;&gt;Algebra with Arrows&lt;/h1&gt;

&lt;p&gt;You can check pretty easily that vector addition and multiplication behave a lot like ordinary addition and multiplication. The usual laws of commutativity, associativity, and distribution hold:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\x + \y = \y + \x$.&lt;/li&gt;
&lt;li&gt;$\x + (\y + \z) = (\x + \y) + \z$.&lt;/li&gt;
&lt;li&gt;$a ( \x + \y) = a\x + a\y$.&lt;/li&gt;
&lt;li&gt;$\x \cdot \y = \y \cdot \x$.&lt;/li&gt;
&lt;li&gt;$\x \cdot (\y + \z) = \x\y + \x\z$.&lt;/li&gt;
&lt;li&gt;$a (\x \cdot \y) = a \x \cdot \y = \x \cdot a \y$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One notable consequence, which we&amp;rsquo;ll use below, is the analogue of the familiar &lt;a href=&#34;https://en.wikipedia.org/wiki/FOIL_method&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;FOIL method&amp;rdquo;&lt;/a&gt; from high school algebra:
  $$
  \begin{align}
    (\x - \y)^2 &amp;amp;= (\x - \y) \cdot (\x - \y)\\&lt;br /&gt;
                &amp;amp;= \x^2 - 2 \x \cdot \y + \y^2.
  \end{align}
  $$
We&amp;rsquo;ll also make use of the fact that the Brier distance between $\x$ and $\y$ can be written $(\x - \y)^2$. Why?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s write $\B(\x,\y)$ for the Brier distance between points $\x$ and $\y$. Recall the definition of Brier distance, which is just the square of Euclidean distance:
  $$ \B(\x,\y) = (x_1 - y_1)^2 + (x_2 - y_2)^2 + \ldots + (x_n - y_n)^2. $$
Now consider that, thanks to our definition of vector subtraction:
  $$ \x - \y = (x_1 - y_1, x_2 - y_2, \ldots, x_n - y_n). $$
And thanks to the definition of the dot product:
  $$ (\x - \y) \cdot (\x - \y) = (x_1 - y_1)^2 + (x_2 - y_2)^2 + \ldots (x_n - y_n)^2. $$
So $\B(\x, \y) = (\x - \y) \cdot (\x - \y)$, in other words:
  $$ \B(\x, \y) = (\x - y)^2. $$&lt;/p&gt;

&lt;h1 id=&#34;a-cute-lemma&#34;&gt;A Cute Lemma&lt;/h1&gt;

&lt;p&gt;Now we can prove the lemma that&amp;rsquo;s the aim of this post. For the intuitive idea, picture a convex set $S$ in the plane, like a pentagon. Then choose an arbitrary point $\x$ outside that set:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/ObtusityLemma.png&#34; alt=&#34;&#34; /&gt;
Now trace a straight line from $\x$ to the closest point of the convex region, $\y$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/ObtusityLemma2.png&#34; alt=&#34;&#34; /&gt;
Finally, trace another straight line to any other point $\z$ of $S$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/ObtusityLemma3.png&#34; alt=&#34;&#34; /&gt;
No matter what point we choose for $\z$, the angle formed will either be right or obtuse. It cannot be acute.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lemma.&lt;/strong&gt; Let $S$ be a convex set of points in $\mathbb{R}^n$. Let $\x \not \in S$, and let $\y \in S$ minimize $\B(\y, \x)$ as a function of $\y$ on the domain $S$. Then for any $\z \in S$,
  $$ (\x - \y) \cdot (\z - \y) \leq 0. $$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s pause to understand what the Lemma is saying before we dive into the proof.&lt;/p&gt;

&lt;p&gt;Focus on the centered inequality. It&amp;rsquo;s about the vectors $\x - \y$ and $\z - \y$. These are the arrows pointing from $\y$ to $\x$, and from $\y$ to $\z$. So in terms of our original two dimensional diagram with the triangle:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34; alt=&#34;&#34; /&gt;
we&amp;rsquo;re looking at the angle between  $c^*$, $c&amp;rsquo;$, and any point on the diagonal you like&amp;hellip; which includes the ones we&amp;rsquo;re especially interested in, the vertices. What the lemma tells us is that this angle is always at least a right angle.&lt;/p&gt;

&lt;p&gt;Of course, it&amp;rsquo;s exactly a right angle in this case, not an obtuse one. That&amp;rsquo;s because our convex region is just the diagonal line. But the Lemma could also be applied to the whole triangular region in the diagram. That&amp;rsquo;s a convex set too. And if we took a point inside the triangle as our third point, the angle formed would be obtuse. (This is actually important if you want to generalize the dominance theorem beyond what we&amp;rsquo;ll prove next time. But for us it&amp;rsquo;s just a mathematical extra.)&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s prove the Lemma.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt; Because $S$ is convex and $\y$ and $\z$ are in $S$, any mixture of $\y$ and $\z$ must also be in $S$. That is, every point $\lambda \z + (1-\lambda) \y$ is in $S$, given $0 \leq \lambda \leq 1$.&lt;/p&gt;

&lt;p&gt;Notice that we can rewrite $\lambda \z + (1-\lambda) \y$ as follows:
  $$ \lambda \z + (1-\lambda) \y = \y + \lambda(\z - \y). $$
We&amp;rsquo;ll use this fact momentarily.&lt;/p&gt;

&lt;p&gt;Now, by hypothesis $\y$ is at least as close to $\x$ as any other point of $S$ is. So, in particular, $\y$ is at least as close to $\x$ as the mixtures of $\y$ and $\z$ are. Thus, for any given $\lambda \in [0,1]$:
  $$ \B(\y,\x) \leq \B(\lambda \z + (1-\lambda) \y, \x). $$
Using algebra, we can transform the right-hand side as follows:
  $$
  \begin{align}
    \B(\lambda \z + (1-\lambda) \y, \x) &amp;amp;= \B(\x, \lambda \z + (1-\lambda) \y)\\&lt;br /&gt;
      &amp;amp;= \B(\x, \y + \lambda(\z - \y))\\&lt;br /&gt;
      &amp;amp;= (\x - (\y + \lambda(\z - \y)))^2\\&lt;br /&gt;
      &amp;amp;= ((\x - \y) - \lambda(\z - \y))^2\\&lt;br /&gt;
      &amp;amp;= (\x - \y)^2 + \lambda^2(\z - \y)^2 - 2\lambda(\x - \y) \cdot (\z - \y)\\&lt;br /&gt;
      &amp;amp;= \B(\x,\y) + \lambda^2\B(\z,\y) - 2\lambda(\x - \y) \cdot (\z - \y).
  \end{align}
  $$
Combining this equation with the previous inequality, we have:
  $$ \B(\y,\x) \leq \B(\x,\y) + \lambda^2\B(\z,\y) - 2\lambda(\x - \y) \cdot (\z - \y). $$
And because $\B(\y, \x) = \B(\x, \y)$, this becomes:&lt;br /&gt;
  $$ 0 \leq \lambda^2\B(\z,\y) - 2\lambda(\x - \y) \cdot (\z - \y). $$
If we then restrict our attention to $\lambda &amp;gt; 0$, we can divide and rearrange terms to get:
  $$ (\x - \y) \cdot (\z - \y) \leq \frac{\lambda\B(\z,\y)}{2}. $$
And since this inequality holds no matter how small $\lambda$ is, it follows that
  $$ (\x - \y) \cdot (\z - \y) \leq 0, $$
as desired.
&lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;taking-stock&#34;&gt;Taking Stock&lt;/h1&gt;

&lt;p&gt;Here&amp;rsquo;s what we&amp;rsquo;ve got from this post and the last one:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Last time: the set of probability functions $P$ is convex.&lt;/li&gt;
&lt;li&gt;This time: given a point $\x$ outside $P$, there&amp;rsquo;s a point $\y$ inside $P$ that forms a right-or-obtuse angle with every other point $\z$ in $P$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Intuitively, it should follow that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\y$ is closer to every $\z$ in $P$ than $\x$ is.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And indeed, that&amp;rsquo;s what we&amp;rsquo;ll show in the next post!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 5: Convexity</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%205%20-%20Convexity/</link>
      <pubDate>Thu, 18 May 2017 10:35:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%205%20-%20Convexity/</guid>
      <description>

&lt;p&gt;In this and the next two posts we&amp;rsquo;ll establish the central theorem of the accuracy framework. We&amp;rsquo;ll show that the laws of probability are specially suited to the pursuit of accuracy, measured in Brier distance.&lt;/p&gt;

&lt;p&gt;We showed this for cases with two possible outcomes, like a coin toss,  way back in &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;the first post of this series&lt;/a&gt;. A simple, &lt;a href=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34;&gt;two-dimensional diagram&lt;/a&gt; was all we really needed for that argument. To see how the same idea extends to any number of dimensions, we need to generalize the key ingredients of that reasoning to $n$ dimensions.&lt;/p&gt;

&lt;p&gt;This post supplies the first ingredient: the convexity theorem.&lt;/p&gt;

&lt;h1 id=&#34;convex-shapes&#34;&gt;Convex Shapes&lt;/h1&gt;

&lt;p&gt;Convex shapes are central to the accuracy framework because, in a way, the laws of probability have a convex shape. Hopefully that mystical pronouncement will make sense by the end of this post.&lt;/p&gt;

&lt;p&gt;You probably know a convex shape when you see one. Circles, triangles, and octagons are convex; pentagrams and the state of Texas are not.&lt;/p&gt;

&lt;p&gt;But what makes a convex shape convex? Roughly: &lt;em&gt;it contains all its connecting lines&lt;/em&gt;. If you take any two points in a convex region and draw a line connecting them, the line will lie entirely inside that region.&lt;/p&gt;

&lt;p&gt;But on a non-convex figure, you can find points whose connecting line leaves the figure&amp;rsquo;s boundary:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/TexasLine.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We want to take this idea beyond two dimensions, though. And for that, we need  to generalize the idea of connecting lines. We need the concept of a &amp;ldquo;mixture&amp;rdquo;.&lt;/p&gt;

&lt;h2 id=&#34;pointy-arithmetic&#34;&gt;Pointy Arithmetic&lt;/h2&gt;

&lt;p&gt;In two dimensions it&amp;rsquo;s pretty easy to see that if you take some percentage of one point, and a complementary percentage of another point, you get a third point on the line between them.$
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\p}{\vec{p}}
\newcommand{\q}{\vec{q}}
\newcommand{\r}{\vec{r}}
\newcommand{\v}{\vec{v}}
\newcommand{\R}{\mathbb{R}}
$&lt;/p&gt;

&lt;p&gt;For example, if you take $1/ 2$ of $(0,0)$ and add it to $1/ 2$ of $(1,1)$, you get the point halfway between: $(1/ 2,1/ 2)$. That&amp;rsquo;s pretty intuitive geometrically:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Fig1.png&#34; alt=&#34;&#34; /&gt;
But we can capture the idea algebraically too:
$$
  \begin{align}
    1/ 2 \times (0,0) + 1/ 2 \times (1,1)
      &amp;amp;= (0,0) + (1/ 2, 1/ 2)\\&lt;br /&gt;
      &amp;amp;= (1/ 2, 1/ 2).
  \end{align}
$$&lt;/p&gt;

&lt;p&gt;Likewise, if you add $3/10$ of $(0,0)$ to $7/10$ of $(1, 1)$, you get the point seven-tenths of the way in between, namely $(7/10, 7/10)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Fig2.png&#34; alt=&#34;&#34; /&gt;
In algebraic terms:
$$
  \begin{align}
    3/10 \times (0,0) + 7/10 \times (1,1)
      &amp;amp;= (0,0) + (7/10, 7/10)\\&lt;br /&gt;
      &amp;amp;= (7/10, 7/10).
  \end{align}
$$&lt;/p&gt;

&lt;p&gt;Notice that we just introduced two rules for doing arithmetic with points. When multiplying a point $\p = (p_1, p_2)$ by a number $a$, we get:
$$ a \p = (a p_1, a p_2). $$
And when adding two points $\p = (p_1, p_2)$ and $\q = (q_1, q_2)$ together:
$$ \p + \q = (p_1 + q_1, p_2 + q_2). $$
In other words, multiplying a point by a single number works element-wise, and so does adding two points together.&lt;/p&gt;

&lt;p&gt;We can generalize these ideas straightforwardly to any number of dimensions $n$. Given points $\p = (p_1, p_2, \ldots, p_n)$ and $\q = (q_1, q_2, \ldots, q_n)$, we can define:
$$ a \p = (a p_1, a p_2, \ldots, a p_n), $$
and
$$ \p + \q = (p_1 + q_1, p_2 + q_2, \ldots, p_n + q_n).$$
We&amp;rsquo;ll talk more about arithmetic with points next time. For now, these two definitions will do.&lt;/p&gt;

&lt;h2 id=&#34;mixtures&#34;&gt;Mixtures&lt;/h2&gt;

&lt;p&gt;Now back to connecting lines between points. The idea is that the straight line between $\p$ and $\q$ is the set of points we get by &amp;ldquo;mixing&amp;rdquo; some portion of $\p$ with some portion of $\q$.&lt;/p&gt;

&lt;p&gt;We take some number $\lambda$ between $0$ and $1$, we multiply $\p$ by $\lambda$ and $\q$ by $1 - \lambda$, and we sum the results: $\lambda \p + (1-\lambda) \q$. The set of points you can obtain this way is the straight line between $\p$ and $\q$.&lt;/p&gt;

&lt;p&gt;In fact, you can mix any number of points together. Given $m$ points $\q_1, \ldots, \q_m$, we can define their &lt;em&gt;mixture&lt;/em&gt; as follows. Let $\lambda_1, \ldots \lambda_m$ be positive real numbers that sum to one. That is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\lambda_i \geq 0$ for all $i$, and&lt;/li&gt;
&lt;li&gt;$\lambda_1 + \lambda_2 + \ldots + \lambda_m = 1$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then we multiply each $\q_i$ by the corresponding $\lambda_i$ and sum up:
  $$ \p = \lambda_1 \q_1 + \ldots + \lambda_m \q_m. $$
The resulting point $\p$ is a &lt;em&gt;mixture&lt;/em&gt; of the $\q_i$&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;Now we can define the general notion of a &lt;em&gt;convex set&lt;/em&gt; of points. A convex set is one where the mixture of any points in the set is also contained in the set. (A convex set is &amp;ldquo;closed under mixing&amp;rdquo;, you might say.)&lt;/p&gt;

&lt;h1 id=&#34;convex-hulls&#34;&gt;Convex Hulls&lt;/h1&gt;

&lt;p&gt;It turns out that the set of possible probability assignments is convex.&lt;/p&gt;

&lt;p&gt;More than that, it&amp;rsquo;s the convex set generated by the possible truth-value assignments, in a certain way. It&amp;rsquo;s the &amp;ldquo;convex hull&amp;rdquo; of the possible truth-value assignments.&lt;/p&gt;

&lt;p&gt;What in the world is a &amp;ldquo;convex hull&amp;rdquo;?&lt;/p&gt;

&lt;p&gt;Imagine some points in the plane&amp;mdash;the corners of a square, for example. Now imagine stretching a rubber band around those points and letting it snap tight. The shape you get is the square with those points as corners. And the set of points enclosed by the rubber band is a convex set. Take any two points inside the square, or on its boundary, and draw the straight line between them. The line will not leave the square.&lt;/p&gt;

&lt;p&gt;Intuitively, the convex hull of a set of points in the plane is the set enclosed by the rubber band exercise. Formally, the convex hull of a set of points is the set of points that can be obtained from them as a mixture. (And this definition works in any number of dimensions.)&lt;/p&gt;

&lt;p&gt;For example, any of the points in our square example can be obtained by taking a mixture of the vertices. Take the center of the square: it&amp;rsquo;s halfway between the bottom left and top right corners. To get something to the left of that we can mix in some of the top left corner (and correspondingly less of the top right). And so on.&lt;/p&gt;

&lt;p&gt;Now imagine the rubber band exercise using the possible truth-value assignments, instead of the corners of a square. In two dimensions, those are the points $(0,1)$ and $(1,0)$. And when you let the band snap tight, you get the diagonal line connecting them. As we saw way back in &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;our first post&lt;/a&gt;, the points on that diagonal line are the possible probability assignments.&lt;/p&gt;

&lt;h1 id=&#34;peeking-ahead&#34;&gt;Peeking Ahead&lt;/h1&gt;

&lt;p&gt;We also saw that if you take any point &lt;em&gt;not&lt;/em&gt; on that diagonal, the closest point on the diagonal forms a right angle. That&amp;rsquo;s what lets us do some basic geometric reasoning to see that there&amp;rsquo;s a point on the line that&amp;rsquo;s closer to both vertices than the point off the line:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram - 400px.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That fact about closest points and right angles is what&amp;rsquo;s going to enable us to generalize the argument beyond two dimensions. If you take any point not on a convex hull, there&amp;rsquo;s a point on the convex hull (namely the closest point) which forms a right (or obtuse) angle with the other points on the hull.&lt;/p&gt;

&lt;p&gt;Consider the three dimensional case. The possible truth-value assignments are $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Three Vertices.png&#34; alt=&#34;&#34; /&gt;
And when you let a rubber band snap tight around them, it encloses the triangular surface connecting them:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Three Vertices with Hull.png&#34; alt=&#34;&#34; /&gt;
That&amp;rsquo;s the set of probability assignments for three outcomes.&lt;/p&gt;

&lt;p&gt;Now take any point that&amp;rsquo;s not on that triangular surface. Drop a straight line to the closest point on the surface. Then draw another straight line from there to one of the triangle&amp;rsquo;s vertices. These two straight lines will form a right or obtuse angle. So the distance from the first, off-hull point to the vertex is further than the distance from the second, on-hull point to the vertex.&lt;/p&gt;

&lt;p&gt;Essentially the same reasoning works in any number of dimensions. But to make it work, we need to do three things.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Prove that the probability assignments always form a convex hull around the possible truth-value assignments.&lt;/li&gt;
&lt;li&gt;Prove that any point outside a convex hull forms a right angle (or an obtuse angle) with any point on the hull.&lt;/li&gt;
&lt;li&gt;Prove that the point off the hull is further from all the vertices than the closest point on the hull.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This post is dedicated to the first item.&lt;/p&gt;

&lt;h1 id=&#34;the-convexity-theorem&#34;&gt;The Convexity Theorem&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;re going to prove that the set of possible probability assignments is the same as the convex hull of the possible truth-value assignments. First let&amp;rsquo;s get some notation in place.&lt;/p&gt;

&lt;h2 id=&#34;notation&#34;&gt;Notation&lt;/h2&gt;

&lt;p&gt;As usual $n$ is the number of possible outcomes under consideration. So each possible truth-value assignment is a point of $n$ coordinates, with a single $1$ and $0$ everywhere else. For example, if $n = 4$ then $(0, 0, 1, 0)$ represents the case where the third possibility obtains.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll write $V$ for the set of all possible truth value assignments. And we&amp;rsquo;ll write $\v_1, \ldots, \v_n$ for the elements of $V$. The first element $\v_1$ has its $1$ in the first coordinate, $\v_2$ has its $1$ in the second coordinate, etc.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll use a superscript $^+$ for the convex hull of a set. So $V^+$ is the convex hull of $V$. It&amp;rsquo;s the set of all points that can be obtained by mixing members of $V$.&lt;/p&gt;

&lt;p&gt;Recall, a mixture is a point obtained by taking nonnegative real numbers $\lambda_1, \ldots, \lambda_n$ that sum to one, and multiplying each one against the corresponding $\v_i$ and then summing up:
  $$ \lambda_1 \v_1 + \lambda_2 \v_2 + \ldots + \lambda_n \v_n. $$
So $V^+$ is the set of all points that can be obtained by this method. Each choice of values $\lambda_1, \ldots, \lambda_n$ generates a member of $V^+$. (To exclude one of the $\v_i$&amp;rsquo;s from a mixture, just set $\lambda_i = 0$.)&lt;/p&gt;

&lt;p&gt;Finally, we&amp;rsquo;ll use $P$ for the set of all probability assignments. Recall: a probability assignment is a point of $n$ coordinates, where each coordinate is nonnegative, and all the coordinates together add up to one. That is, $\p = (p_1,\ldots,p_n)$ is a probability assignment just in case:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$p_i \geq 0$ for all $i$, and&lt;/li&gt;
&lt;li&gt;$p_1 + p_2 + \ldots + p_n = 1$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The set $P$ contains just those points $\p$ satisfying these two conditions.&lt;/p&gt;

&lt;h2 id=&#34;statement-and-proof&#34;&gt;Statement and Proof&lt;/h2&gt;

&lt;p&gt;In the notation just established, what we&amp;rsquo;re trying to show is that $V^+ = P$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; $V^+ = P$. That is, the convex hull of the possible truth-value assignments just is the set of possible probability assignments.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt; Let&amp;rsquo;s first show that $V^+ \subseteq P$.&lt;/p&gt;

&lt;p&gt;Notice that a truth-value assignment is also probability assignment. Its coordinates are always $1$ or $0$, so all coordinates are nonnegative. And since it has only a single coordinate with value $1$, its coordinates add up to $1$.&lt;/p&gt;

&lt;p&gt;But we have to show that any mixture of truth-value assignments is also a probability assignment. So let $\lambda_1, \ldots, \lambda_n$ be nonnegative numbers that sum to $1$. If we multiply $\lambda_i$ against a truth-value assignment $\v_i$, we get a point with $0$ in every coordinate except the $i$-th coordinate, which has value $\lambda_i$. For example, $\lambda_3 \times (0, 0, 1, 0) = (0, 0, \lambda_3, 0)$. So the mixture that results from $\lambda_1, \ldots, \lambda_n$ is:
  $$
    \lambda_1 \v_1 + \lambda_2 \v_2 + \ldots \lambda_n \v_n = (\lambda_1, \lambda_2, \ldots, \lambda_n).
  $$
And this mixture has coordinates that are all nonnegative and sum to $1$, by hypothesis. In other words, it is a probability assignment.&lt;/p&gt;

&lt;p&gt;So we turn to showing that $P \subseteq V^+$. In other words, we want to show that every probability assignment can be obtained as a mixture of the $\v_i$&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;So take an arbitrary probability assignment $\p \in P$, where $\p = (p_1, \ldots, p_n)$. Let the $\lambda_i$&amp;rsquo;s be the probabilities that $\p$ assigns to each $i$: $\lambda_1 = p_1$, $\lambda_2 = p_2$, and so on. Then, by the same logic as in the first part of the proof:
  $$ \lambda_1 \v_1 + \ldots + \lambda_n \v_n = (p_1, \ldots, p_n). $$
In other words, $\p$ is a mixture of the possible truth-value assignments, where the weights in the mixture are just the probability values assigned by $\p$. &lt;span style=&#34;float: right;&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;up-next&#34;&gt;Up Next&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;ve established the first of the three items listed earlier. Next time we&amp;rsquo;ll establish the second: given a point outside a convex set, there&amp;rsquo;s always a point inside that forms a right or obtuse angle with any other point of the set. Then we&amp;rsquo;ll be just a few lines of algebra from the main result: the Brier dominance theorem!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Journals as Ratings Agencies</title>
      <link>http://jonathanweisberg.org/post/Journals%20as%20Ratings%20Agencies/</link>
      <pubDate>Thu, 30 Mar 2017 15:27:04 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Journals%20as%20Ratings%20Agencies/</guid>
      <description>

&lt;p&gt;Starting in July, philosophy&amp;rsquo;s two most prestigious journals won&amp;rsquo;t reject submitted papers anymore. Instead they&amp;rsquo;ll &amp;ldquo;grade&amp;rdquo; every submission, assigning a rating on the familiar letter-grade scale (A+, A, A-, B+, B, B-, etc.).&lt;/p&gt;

&lt;p&gt;They will, in effect, become ratings agencies.&lt;/p&gt;

&lt;p&gt;They&amp;rsquo;ll still publish papers. Those rated A- or higher can be published in the journal, if the authors want. Or they can seek another venue, if they think they can do better.&lt;/p&gt;

&lt;p&gt;I just made that up. But imagine if it were true&amp;mdash;especially if a bunch of journals did this. How would it change philosophy&amp;rsquo;s publication game?&lt;/p&gt;

&lt;p&gt;Well we&amp;rsquo;d save a lot of wasted labour, for one thing. And we&amp;rsquo;d discourage frivolous submissions, for another.&lt;/p&gt;

&lt;h1 id=&#34;the-bad&#34;&gt;The Bad&lt;/h1&gt;

&lt;p&gt;Under the current arrangement, the system is sagging low under the weight of premature, mediocre, even low-quality submissions. (I&amp;rsquo;d say it&amp;rsquo;s even creaking and cracking.) Editors scrounge miserably for referees, and referees frantically churn out reports and recommendations, mostly for naught.&lt;/p&gt;

&lt;p&gt;In a typical case, the editor rejects the submission and the referees&amp;rsquo; reports are filed away in a database, never to be read again. Maybe the author makes substantial revisions, but very likely they don&amp;rsquo;t&amp;mdash;especially if the paper&amp;rsquo;s main idea is the real limiting factor. The process repeats at another journal, often at several more journals. And in the end all the philosophical public sees is: accepted at &lt;em&gt;International Journal of Such &amp;amp; Such Studies&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Of all the people who&amp;rsquo;ve read and assessed the paper by that point, only two have their assessments directly broadcast to the public. And even then, only the &amp;ldquo;two thumbs more-or-less up&amp;rdquo; part of the signal gets out.&lt;/p&gt;

&lt;p&gt;Yet five, eight, or even ten people have weighed in on the paper by then. They&amp;rsquo;ve thought about its strengths and weaknesses, and they&amp;rsquo;ve generated valuable insights and assessments that could save others time and trouble. Yet only the handling editors and the authors get the direct benefit of that labour.&lt;/p&gt;

&lt;p&gt;The current system even encourages authors to waste editors&amp;rsquo; and referees&amp;rsquo; time. Unless they&amp;rsquo;re in a rush, authors can start at the top of the journal-prestige hierarchy and work their way down. You don&amp;rsquo;t even have to perfect your paper before starting this incredibly inefficient process. With so many journals to try, you&amp;rsquo;ll basically get unlimited kicks at the can. So you might as well let the referees do your homework for you.&lt;/p&gt;

&lt;p&gt;(This doesn&amp;rsquo;t apply to all authors, obviously. Some work in areas that severely limit their can-kicking. And many &lt;em&gt;are&lt;/em&gt; in a rush, to get jobs and tenure.)&lt;/p&gt;

&lt;h1 id=&#34;the-good&#34;&gt;The Good&lt;/h1&gt;

&lt;p&gt;But, if a paper were publicly assigned a grade every place it was submitted, authors might be more realistic in deciding where to submit. They might also wait until their paper is truly ready for public consumption before imposing on editors and referees.&lt;/p&gt;

&lt;p&gt;Readers would also benefit from seeing a paper&amp;rsquo;s transcript. Not only could it inform their decision about whether to read the paper, it could aid their sense of how its contribution is received by peers and experts.&lt;/p&gt;

&lt;p&gt;Referees would also have better incentives, to take on referee work and to be more diligent about it. They would know that their labour would have a greater impact, and that their assessment would have a more lasting effect.&lt;/p&gt;

&lt;p&gt;Editors could even limit submissions based on their grade-history, e.g. &amp;ldquo;no submissions already graded  by two other journals&amp;rdquo;, or &amp;ldquo;no submissions with an average grade less than a B&amp;rdquo;. (Ideally, different journals would have different policies here, to allow some variety.)&lt;/p&gt;

&lt;h1 id=&#34;the-ugly&#34;&gt;The Ugly&lt;/h1&gt;

&lt;p&gt;Of course, several high-profile journals would have to take the lead to make this kind of thing happen. And there would have to be strong norms within the discipline about publicizing grades: requiring they be listed alongside the paper on CVs and websites, for example&lt;/p&gt;

&lt;p&gt;And there would be costs.&lt;/p&gt;

&lt;p&gt;Everybody has their favourite story about the groundbreaking paper that got rejected five times, but was finally published in &lt;em&gt;The Posh Journal of Philosophy Review&lt;/em&gt;, and has since been cited a gajillion times. Such papers could be weighed down by having their grade-transcripts publicized. (On the plus side, we could have a new genre of great paper: the cult classic!)&lt;/p&gt;

&lt;p&gt;Also, some authors have to rely on referee feedback more than others, because of their limited philosophical networks. They&amp;rsquo;d likely find their papers with longer, more checkered grade-transcripts, exacerbating an existing injustice.&lt;/p&gt;

&lt;p&gt;And, in the end, the present proposal might only be a band-aid. If there really is an oversubmission problem in academic philosophy (as I suspect there is), it&amp;rsquo;s probably caused by increased pressure to publish&amp;mdash;because jobs are scarce, and administrators demand it, for example. Turning journals into ratings agencies wouldn&amp;rsquo;t relieve that pressure, even if it would help to manage some of its bad effects.&lt;/p&gt;

&lt;h1 id=&#34;decision-r-r&#34;&gt;Decision: R&amp;amp;R&lt;/h1&gt;

&lt;p&gt;In the end, I&amp;rsquo;m undecided about this proposal. I think it has some very attractive features, but the costs give me pause (much the same as the alternatives I&amp;rsquo;m aware of, like &lt;a href=&#34;http://davidfaraci.com/populus&#34; target=&#34;_blank&#34;&gt;Populus&lt;/a&gt;). I&amp;rsquo;m only certain that we can&amp;rsquo;t keep going as we have been; it won&amp;rsquo;t end well.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 4: Euclid in the Round</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%204/</link>
      <pubDate>Thu, 23 Feb 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%204/</guid>
      <description>

&lt;p&gt;Last time we took Brier distance beyond two dimensions. &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 3/&#34;&gt;We showed&lt;/a&gt; that it&amp;rsquo;s &amp;ldquo;proper&amp;rdquo; in any finite number of dimensions. Today we&amp;rsquo;ll show that Euclidean distance is &amp;ldquo;improper&amp;rdquo; in any finite number dimensions.&lt;/p&gt;

&lt;p&gt;When I first sat down to write this post, I had in mind a straightforward generalization of &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;our previous result&lt;/a&gt; for Euclidean distance in two dimensions. And I figured it would be easy to prove.&lt;/p&gt;

&lt;p&gt;Not so.&lt;/p&gt;

&lt;p&gt;My initial conjecture was false, and worse, when I asked my accuracy-guru friends for the truth, nobody seemed to know. (They did offer lots of helpful suggestions, though.)&lt;/p&gt;

&lt;p&gt;So today we&amp;rsquo;re muddling through on our own even more than usual. Here goes.&lt;/p&gt;

&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s recall where we are. We&amp;rsquo;ve been considering different ways of measuring the inaccuracy of a probability assignment given a possibility, or a &amp;ldquo;possible world&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start today by regimenting our terminology. We&amp;rsquo;ve used these terms semi-formally for a while now. But let&amp;rsquo;s gather them here for reference, and to make them a little more precise.$
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\p}{\vec{p}}
\newcommand{\q}{\vec{q}}
\newcommand{\u}{\vec{u}}
\newcommand{\EIpq}{EI_{\p}(\q)}
\newcommand{\EIpp}{EI_{\p}(\p)}
$&lt;/p&gt;

&lt;p&gt;Given a number of dimensions $n$:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A &lt;em&gt;probability assignment&lt;/em&gt; $\p = (p_1, \ldots, p_n)$ is a vector of positive real numbers that sum to $1$.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;possible world&lt;/em&gt; is a vector $\u$ of length $n$ containing all zeros except for a single $1$. (A &lt;a href=&#34;https://en.wikipedia.org/wiki/Unit_vector&#34; target=&#34;_blank&#34;&gt;unit vector&lt;/a&gt; of length $n$, in other words.)&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;measure of inaccuracy&lt;/em&gt; $D(\p, \u)$ is a function that takes a probability assignment and a possible world and returns a real number.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;rsquo;ve been considering two measures of inaccuracy. The first is the familiar Euclidean distance between $\p$ and $\u$. For example, when $\u = (1, 0, \ldots, 0)$ we have:
$$ \sqrt{(p_1 - 1)^2 + (p_2 - 0)^2 + \ldots + (p_n - 0)^2}.$$
The second way of measuring inaccuracy is less familiar, Brier distance, which is just the square of Euclidean distance:
$$ (p_1 - 1)^2 + (p_2 - 0)^2 + \ldots + (p_n - 0)^2.$$&lt;/p&gt;

&lt;p&gt;What we found in $n = 2$ dimensions is that Euclidean distance is &amp;ldquo;unstable&amp;rdquo; in a way that Brier is not. If we measure inaccuracy using Euclidean distance, a probability assignment can expect some &lt;em&gt;other&lt;/em&gt; probability assignment to do better accuracy-wise, i.e. to have lower inaccuracy.&lt;/p&gt;

&lt;p&gt;In fact, given almost any probability assignment, the way to minimize expected inaccuracy is to leap to certainty in the most likely possibility. Given $(2/3, 1/3)$, for example, the way to minimize expected inaccuracy is to move to $(1,0)$.&lt;/p&gt;

&lt;p&gt;Because Euclidean distance is unstable in this way, it&amp;rsquo;s called an &amp;ldquo;improper&amp;rdquo; measure of inaccuracy. So, two more bits of terminology:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Given a probability assignment $\p$ and a measure of inaccuracy $D$, the &lt;em&gt;expected inaccuracy&lt;/em&gt; of probability assignment $\q$, written $\EIpq$, is the weighted sum:
$$
\EIpq = p_1 D(\q,\u_1) + \ldots + p_n D(\q,\u_n),
$$
where $\u_i$ is the possible world with a $1$ at index $i$.&lt;/li&gt;
&lt;li&gt;A measure of inaccuracy $D$ is &lt;em&gt;improper&lt;/em&gt; if there is a probability assignment $\p$ such that for some assignment $\q \neq \p$, $\EIpq &amp;lt; \EIpp$ when inaccuracy is measured according to $D$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Last time we showed that Brier is &lt;em&gt;proper&lt;/em&gt; in any finite number of dimensions $n$. Today our main task is to show that Euclidean distance is &lt;em&gt;&lt;strong&gt;im&lt;/strong&gt;proper&lt;/em&gt; in any finite number of dimensions $n$.&lt;/p&gt;

&lt;p&gt;But first, let&amp;rsquo;s get a tempting mistake out of the way.&lt;/p&gt;

&lt;h1 id=&#34;a-conjecture-and-its-refutation&#34;&gt;A Conjecture and Its Refutation&lt;/h1&gt;

&lt;p&gt;In &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;our first post&lt;/a&gt;, we saw that Euclidean distance isn&amp;rsquo;t just improper in two dimensions. It&amp;rsquo;s also &lt;em&gt;extremizing&lt;/em&gt;: the assignment $(2/3, 1/3)$ doesn&amp;rsquo;t just expect &lt;em&gt;some&lt;/em&gt; other assignment to do better accuracy-wise. It expects the assignment $(1,0)$ to do best!&lt;/p&gt;

&lt;p&gt;At first I thought we&amp;rsquo;d be proving a straightforward generalization of that result today:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conjecture 1 (False).&lt;/strong&gt; Let $(p_1, \ldots, p_n)$ be a probability assignment with a unique largest element $p_i$. If we measure inaccuracy by Euclidean distance, then $\EIpq$ is minimized when $\q = \u_i$.&lt;/p&gt;

&lt;p&gt;Intuitively: expected inaccuracy is minimized by leaping to certainty in the most probable possibility. Turns out this is false in three dimensions. Here&amp;rsquo;s a&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Counterexample.&lt;/strong&gt; Let&amp;rsquo;s define:
$$
\begin{align}
\p &amp;amp;= (5/12, 4/12, 3/12),\\&lt;br /&gt;
\p&amp;rsquo; &amp;amp;= (6/12, 4/12, 2/12),\\&lt;br /&gt;
\u_1 &amp;amp;= (1, 0, 0).
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Then we can calculate (or better, &lt;a href=&#34;https://github.com/jweisber/a4d/blob/master/Euclid%20in%20the%20Round.nb&#34; target=&#34;_blank&#34;&gt;have &lt;em&gt;Mathematica&lt;/em&gt; calculate&lt;/a&gt;):
$$
\begin{align}
\EIpp &amp;amp;\approx .804,\\&lt;br /&gt;
EI_{\p}(\p&amp;rsquo;) &amp;amp;\approx .800,\\&lt;br /&gt;
EI_{\p}(\u_1) &amp;amp;\approx .825.
\end{align}
$$
In this case $\EIpp &amp;lt; EI_{\p}(\u_1)$. So leaping to certainty doesn&amp;rsquo;t minimize expected inaccuracy (as measured by Euclidean distance).&lt;/p&gt;

&lt;p&gt;Of course, staying put doesn&amp;rsquo;t minimize it either, since $EI_{\p}(\p&amp;rsquo;) &amp;lt; \EIpp$.&lt;/p&gt;

&lt;p&gt;So what &lt;em&gt;does&lt;/em&gt; minimize it in this example? I asked &lt;em&gt;Mathematica&lt;/em&gt; to minimize $\EIpq$ and got&amp;hellip; nothing for days. Eventually I gave up waiting and asked instead for &lt;a href=&#34;https://github.com/jweisber/a4d/blob/master/Euclid%20in%20the%20Round.nb&#34; target=&#34;_blank&#34;&gt;a numerical approximation of the minimum&lt;/a&gt;. One second later I got:&lt;/p&gt;

&lt;p&gt;$$EI_{\p}(0.575661, 0.250392, 0.173947) \approx 0.797432.$$&lt;/p&gt;

&lt;p&gt;I have no idea what that is in more meaningful terms, I&amp;rsquo;m sorry to say. But at least we know it&amp;rsquo;s not anywhere near the extreme point $\u_1$ I conjectured at the outset. (See the &lt;strong&gt;Update&lt;/strong&gt; at the end for a little more.)&lt;/p&gt;

&lt;h1 id=&#34;a-shortcut-and-its-shortcomings&#34;&gt;A Shortcut and Its Shortcomings&lt;/h1&gt;

&lt;p&gt;So I asked friends who do this kind of thing for a living how they handle the $n$-dimensional case.  A couple of them suggested taking a shortcut around it!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Look, you&amp;rsquo;ve already handled the two-dimensional case. And that&amp;rsquo;s just an instance of higher dimensional cases.&lt;/p&gt;

&lt;p&gt;Take a probability assignment like (2/3, 1/3). We can also think of it as (2/3, 1/3, 0), or as (2/3, 0, 1/3, 0), etc.&lt;/p&gt;

&lt;p&gt;No matter how many zeros we sprinkle around in there, the same thing is going to happen as in the two-dimensional case. Leaping to certainty in the 2/3 possibility will minimize expected inaccuracy. (Because possibilities with no probability make no difference to expected value calculations.)&lt;/p&gt;

&lt;p&gt;So no matter how many dimensions we&amp;rsquo;re working in, there will always be &lt;em&gt;some&lt;/em&gt; probability assignment where leaping to certainty minimizes expected inaccuracy. It just might have lots of zeros in it.&lt;/p&gt;

&lt;p&gt;So Euclidean distance is, technically, improper in any finite number of dimensions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At first I thought that was good enough for philosophy. Though I still wanted to know how to handle &amp;ldquo;no zeros&amp;rdquo; cases for the mathematical clarity.&lt;/p&gt;

&lt;p&gt;Then I realized there may be a philosophical reason to be dissatisfied with this shortcut. A lot of people endorse the &lt;a href=&#34;http://philosophy.anu.edu.au/sites/default/files/Staying%20Regular.December%2028.2012.pdf&#34; target=&#34;_blank&#34;&gt;Regularity principle&lt;/a&gt;: you should never assign zero probability to any possibility. For these people, the shortcut might be a dead end.&lt;/p&gt;

&lt;p&gt;(Of course, maybe we shouldn&amp;rsquo;t embrace Regularity if we&amp;rsquo;re working in the accuracy framework. I won&amp;rsquo;t stop for that question here.)&lt;/p&gt;

&lt;h1 id=&#34;a-theorem-and-its-corollary&#34;&gt;A Theorem and Its Corollary&lt;/h1&gt;

&lt;p&gt;So let&amp;rsquo;s take the problem head on. We want to show that Euclidean distance is improper in $n &amp;gt; 2$ dimensions, even when there are &amp;ldquo;no zeros&amp;rdquo;. Two last bits of terminology:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A probability assignment $(p_1, \ldots, p_n)$ is &lt;em&gt;regular&lt;/em&gt; if $p_i &amp;gt; 0$ for all $i$.&lt;/li&gt;
&lt;li&gt;A probability assignment $(p_1, \ldots, p_n)$ is &lt;em&gt;uniform&lt;/em&gt; if $p_i = p_j$ for all $i,j$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, for example, the assignment $(1/3, 1/3, 1/3)$ is both regular and uniform. Whereas the assignment $(2/5, 2/5, 1/5)$ is regular, but not uniform.&lt;/p&gt;

&lt;p&gt;What we&amp;rsquo;ll show is that assignments like $(2/5, 2/5, 1/5)$ make Euclidean distance &amp;ldquo;unstable&amp;rdquo;: they expect some other assignment to do better, accuracy-wise. (Exactly which other assignment they&amp;rsquo;ll expect to do best isn&amp;rsquo;t always easy to say.)&lt;/p&gt;

&lt;p&gt;(Though I try to keep the math in these posts as elementary as possible, this proof will use calculus. If you know a bit about derivatives, you should be fine. Technically we&amp;rsquo;ll use multi-variable calculus. But if you&amp;rsquo;ve worked with derivatives in single-variable calculus, that should be enough for the main ideas.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
Let $\p = (p_1, \ldots, p_n)$ be a regular, non-uniform probability assignment. If accuracy is measured by Euclidean distance, then $EI_{\p}(\q)$ is not minimized when $\q = \p$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp;
Let $\p = (p_1, \ldots, p_n)$ be a regular and non-uniform probability assignment, and measure inaccuracy using Euclidean distance. Then:
$$
\begin{align}
EI_{\p}(\q) &amp;amp;= p_1 \sqrt{(q_1 - 1)^2 + \ldots + (q_n - 0)^2} + \ldots + p_n \sqrt{(q_1 - 0)^2 + \ldots + (q_n - 1)^2}\\&lt;br /&gt;
&amp;amp;= p_1 \sqrt{(q_1 - 1)^2 + \ldots + q_n^2} + \ldots + p_n \sqrt{q_1^2 + \ldots + (q_n - 1)^2}
\end{align}
$$&lt;/p&gt;

&lt;p&gt;The crux of our proof will be that the derivatives of this function are non-zero at the point $\q = \p$. Since the minimum of a function is always a &lt;a href=&#34;https://en.wikipedia.org/wiki/Critical_point_(mathematics)&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;critical point&amp;rdquo;&lt;/a&gt;, that suffices to show that $\q = \p$ is not a minimum of $\EIpq$.&lt;/p&gt;

&lt;p&gt;To start, we calculate the partial derivative of $\EIpq$ for an arbitrary $q_i$:
$$
\begin{align}
\frac{\partial}{\partial q_i} \EIpq
&amp;amp;=
\frac{\partial}{\partial q_i} \left( p_1 \sqrt{(q_1 - 1)^2 + \ldots + q_n^2} + \ldots + p_n \sqrt{q_1^2 + \ldots + (q_n - 1)^2} \right)\\&lt;br /&gt;
&amp;amp;=
p_1 \frac{\partial}{\partial q_i} \sqrt{(q_1 - 1)^2 + \ldots + q_n^2} + \ldots + p_n \frac{\partial}{\partial q_i} \sqrt{q_1^2 + \ldots + (q_n - 1)^2}\\&lt;br /&gt;
&amp;amp;= \quad
p_i \frac{q_i - 1}{\sqrt{(q_i - 1)^2 + \sum_{j \neq i} q_j^2}} + \sum_{j \neq i} p_j \frac{q_i}{\sqrt{(q_j - 1)^2 + \sum_{k \neq j} q_k^2}}\\&lt;br /&gt;
&amp;amp;= \quad
\sum_{j \neq i} \frac{p_j q_i}{\sqrt{(q_j - 1)^2 + \sum_{k \neq j} q_k^2}} - \sum_{j \neq i} \frac{p_i q_j}{\sqrt{(q_i - 1)^2 + \sum_{j \neq i} q_j^2}}.
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Then we evaluate at $\q = \p$:
$$
\begin{align}
\frac{\partial}{\partial q_i} \EIpp
&amp;amp;= \sum_{j \neq i} \frac{p_i p_j}{\sqrt{(p_j - 1)^2 + \sum_{k \neq j} p_k^2}} - \sum_{j \neq i} \frac{p_i p_j}{\sqrt{(p_i - 1)^2 + \sum_{j \neq i} p_j^2}}
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Now, because $\p$ is not uniform, some of its elements are larger than others. And because it is finite, there is at least one largest element. When $p_i$ is one of these largest elements, then $\partial / \partial q_i \EIpp$ is negative.&lt;/p&gt;

&lt;p&gt;Why?&lt;/p&gt;

&lt;p&gt;In our equation for $\partial / \partial q_i \EIpp$, each positive term has a corresponding negative term whose numerator is identical. And when $p_i$ is a largest element of $\p$, the denominator of each negative term will never be larger, but will sometimes be smaller, than the denominator of its corresponding positive term. Subtracting $1$ from $p_i$ before squaring does more to reduce the sum of squares $p_i^2 + \sum_{j \neq i} p_j^2$ than subtracting $1$ from any smaller term would. It effectively removes the/a largest square from the sum and substitutes the smallest replacement. So the negative terms are never smaller, but are sometimes larger, than their positive counterparts.&lt;/p&gt;

&lt;p&gt;If, on the other hand, $p_i$ is the one of the smallest elements, then $\partial / \partial q_i \EIpp$ is positive. For then the reverse argument applies: the denominator of each negative term will never be smaller and will sometimes be larger than the denominator of the corresponding positive term. So the negatives terms are never larger, but are sometimes smaller, than their positive counterparts.&lt;/p&gt;

&lt;p&gt;We have shown that the partial derivates of $\EIpq$ are non-zero at the point $\q = \p$. Thus $\p$ is not a critical point of $\EIpq$, and hence cannot be a minimum of $\EIpq$.  &lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Corollary.&lt;/strong&gt; Euclidean distance is improper in any finite number of dimensions.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp; This is just a slight restatement of our theorem. If $\q = \p$ is not a minimum of $\EIpq$, then there is some $\q \neq \p$ such that $\EIpq &amp;lt; \EIpp$.  &lt;span class=&#34;floatright&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;conjectures-awaiting-refutations&#34;&gt;Conjectures Awaiting Refutations&lt;/h1&gt;

&lt;p&gt;Notice, we&amp;rsquo;ve also shown something a bit stronger. We showed that the slope of $\EIpq$ at the point $\q = \p$ is always negative in the direction of $\p$&amp;rsquo;s largest element(s), and positive in the direction of its smallest element(s). That means we can always reduce expected inaccuracy by taking some small quantity away from the/a smallest element of $\p$ and adding it to the/a largest element. In other words, we can always reduce expected inaccuracy by moving &lt;em&gt;some&lt;/em&gt; way towards perfect certainty in the/a possibility that $\p$ rates most probable.&lt;/p&gt;

&lt;p&gt;However, we &lt;em&gt;haven&amp;rsquo;t&lt;/em&gt; shown that repeatedly minimizing expected inaccuracy will, eventually, lead to certainty in the/a possibility that was most probable to begin with. For one thing, we haven&amp;rsquo;t shown that moving towards certainty in this direction minimizes expected inaccuracy at each step. We&amp;rsquo;ve only shown that moving in this direction reduces it.&lt;/p&gt;

&lt;p&gt;Still, I&amp;rsquo;m pretty sure a result along these lines holds. Tinkering in &lt;em&gt;Mathematica&lt;/em&gt; strongly suggests that the following Conjectures are true in any finite number of dimensions $n$:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conjecture 2.&lt;/strong&gt; If a probability assignment gives greater than $1/ 2$ probability to some possibility, then expected inaccuracy is minimized by assigning probability 1 to that possibility. (But see the &lt;strong&gt;Update&lt;/strong&gt; below.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conjecture 3.&lt;/strong&gt; Given a non-uniform probability assignment, repeatedly minimizing expected inaccuracy will, within a finite number of steps, increase the probability of the/a possibility that was most probable initially beyond $1/ 2$.&lt;/p&gt;

&lt;p&gt;If these conjectures hold, then there&amp;rsquo;s still a weak-ish sense in which Euclidean distance is &amp;ldquo;extremizing&amp;rdquo; in $n &amp;gt; 2$ dimensions. Given a non-uniform probability assignment, repeatedly minimizing expected inaccuracy will eventually lead to greater than $1/ 2$ probability in the/a possibility that was most probable to begin with. Then, minimizing inaccuracy will lead in a single step to certainty in that possibility.&lt;/p&gt;

&lt;p&gt;Proving these conjectures would close much of the gap between the theorem we proved and the false conjecture I started with. If you&amp;rsquo;re interested, you can use &lt;a href=&#34;https://github.com/jweisber/a4d/blob/master/Euclid%20in%20the%20Round.nb&#34; target=&#34;_blank&#34;&gt;this &lt;em&gt;Mathematica&lt;/em&gt; notebook&lt;/a&gt; to test them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update: Mar. 6, 2017.&lt;/strong&gt; Thanks to some excellent help from &lt;a href=&#34;https://mathematics.stanford.edu/people/department-directory/name/jonathan-love/&#34; target=&#34;_blank&#34;&gt;Jonathan Love&lt;/a&gt;, I&amp;rsquo;ve tweaked this post (and greatly simplified &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%203/&#34;&gt;the previous one&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I changed the counterexample to the false Conjecture 1, which used to be $\p = (3/7, 2/7, 2/7)$ and $\p&amp;rsquo; = (4/7, 2/7, 1/7)$. That works fine, but it&amp;rsquo;s potentially misleading.&lt;/p&gt;

&lt;p&gt;As Jonathan kindly pointed out, the minimum point then is something quite nice. It&amp;rsquo;s obtained by moving in the $x$-dimension from $3/7$ to $\sqrt{3/7}$, and correspondingly reducing the probability in the $y$ and $z$ dimensions in equal parts.&lt;/p&gt;

&lt;p&gt;But, in general, moving to the square root of the largest $p_i$ (when there is one) doesn&amp;rsquo;t minimize $\EIpq$. Even in the special case where all the other elements in the vector are equal, this doesn&amp;rsquo;t generally work.&lt;/p&gt;

&lt;p&gt;Jonathan did solve that special case, though, and he found at least one interesting result connected with Conjecture 2. There appear to be cases where $p_i &amp;lt; 1/ 2$ for all $i$, and yet $\EIpq$ is still minimized by going directly to the extreme. For example, $\p = (.465, .2675, .2675)$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Editorial Gravity</title>
      <link>http://jonathanweisberg.org/post/Editorial%20Gravity/</link>
      <pubDate>Wed, 22 Feb 2017 10:44:10 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Editorial%20Gravity/</guid>
      <description>

&lt;p&gt;We&amp;rsquo;ve all been there. One referee is positive, the other negative, and the editor decides to reject the submission.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve heard it said editors tend to be conservative given the recommendations of their referees. And that jibes with my experience as an author.&lt;/p&gt;

&lt;p&gt;So is there anything to it&amp;mdash;is &amp;ldquo;editorial gravity&amp;rdquo; a real thing? And if it is, how strong is its pull? Is there some magic function editors use to compute their decision based on the referees&amp;rsquo; recommendations?&lt;/p&gt;

&lt;p&gt;In this post I&amp;rsquo;ll consider how things shake out at &lt;a href=&#34;http://www.ergophiljournal.org/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Ergo&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;decision-rules&#34;&gt;Decision Rules&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Ergo&lt;/em&gt; doesn&amp;rsquo;t have any rule about what an editor&amp;rsquo;s decision should be given the referees&amp;rsquo; recommendations. In fact, we explicitly discourage our editors from relying on any such heuristic. Instead we encourage them to rely on their judgment about the submission&amp;rsquo;s merits, informed by the substance of the referees&amp;rsquo; reports.&lt;/p&gt;

&lt;p&gt;Still, maybe there&amp;rsquo;s some natural law of journal editing waiting to be discovered here, or some unwritten rule.&lt;/p&gt;

&lt;p&gt;Referees choose from four possible recommendations at &lt;em&gt;Ergo&lt;/em&gt;: Reject, Major Revisions, Minor Revisions, or Accept. Let&amp;rsquo;s consider four simple rules we might use to predict an editor&amp;rsquo;s decision, given the recommendations of their referees.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Max: the editor follows the recommendation of the most positive referee. (Ha!)&lt;/li&gt;
&lt;li&gt;Mean: the editor &amp;ldquo;splits the difference&amp;rdquo; between the referees&amp;rsquo; recommendations.

&lt;ul&gt;
&lt;li&gt;Accept + Major Revisions → Minor Revisions, for example.&lt;/li&gt;
&lt;li&gt;When the difference is intermediate between possible decisions, we&amp;rsquo;ll stipulate that this rule &amp;ldquo;rounds down&amp;rdquo;.

&lt;ul&gt;
&lt;li&gt;Major Revisions + Minor Revisions → Major Revisions, for example.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Min: the editor follows the recommendation of the most negative referee.&lt;/li&gt;
&lt;li&gt;Less-than-Min: the editor&amp;rsquo;s decision is a step more negative than either of the referees&amp;rsquo;.

&lt;ul&gt;
&lt;li&gt;Major Revisions + Minor Revisions → Reject, for example.&lt;/li&gt;
&lt;li&gt;Except obviously that Reject + anything → Reject.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Do any of these rules do a decent job of predicting editorial decisions? If so, which does best?&lt;/p&gt;

&lt;h1 id=&#34;a-test&#34;&gt;A Test&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s run the simplest test possible. We&amp;rsquo;ll go through the externally reviewed submissions in &lt;em&gt;Ergo&lt;/em&gt;&amp;rsquo;s database and see how often each rule makes the correct prediction.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/editorial_gravity_files/unnamed-chunk-2-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Not only was Min the most accurate rule, its predictions were correct 85% of the time! (The sample size here is 233 submissions, by the way.) Apparently, editorial gravity is a real thing, at least at &lt;em&gt;Ergo&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Of course, &lt;em&gt;Ergo&lt;/em&gt; might be atypical here. It&amp;rsquo;s a new journal, and online-only with no regular publication schedule. So there&amp;rsquo;s some pressure to play it safe, and no incentive to accept papers in order to fill space.&lt;/p&gt;

&lt;p&gt;But let&amp;rsquo;s suppose for a moment that &lt;em&gt;Ergo&lt;/em&gt; is typical as far as editorial gravity goes. That raises some questions. Here are two.&lt;/p&gt;

&lt;h1 id=&#34;two-questions&#34;&gt;Two Questions&lt;/h1&gt;

&lt;p&gt;First question: can we improve on the Min rule? Is there a not-too-complicated heuristic that&amp;rsquo;s even more accurate?&lt;/p&gt;

&lt;p&gt;Visualizing our data might help us spot any patterns. Typically there are two referees, so we can plot most submissions on a plane according to the referees&amp;rsquo; recommendations. Then we can colour them according to the editor&amp;rsquo;s decision. Adding a little random jitter to make all the points visible:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/editorial_gravity_files/unnamed-chunk-3-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To my eye this looks a lot like the pattern of concentric-corners you&amp;rsquo;d expect from the Min rule. Though not exactly, especially when the two referees strongly disagree&amp;mdash;the top-left and bottom-right corners of the plot. Still, other than treating cases of strong disagreement as a tossup, no simple way of improving on the Min rule jumps out at me.&lt;/p&gt;

&lt;p&gt;Second question: if editorial gravity is a thing, is it a good thing or a bad thing?&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll leave that as an exercise for the reader.&lt;/p&gt;

&lt;h1 id=&#34;technical-note&#34;&gt;Technical Note&lt;/h1&gt;

&lt;p&gt;This post was written in R Markdown and the source code is &lt;a href=&#34;https://github.com/jweisber/rgo/blob/master/editorial gravity/editorial gravity.Rmd&#34; target=&#34;_blank&#34;&gt;available on GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gender &amp; Journal Referees</title>
      <link>http://jonathanweisberg.org/post/Referee%20Gender/</link>
      <pubDate>Mon, 20 Feb 2017 09:34:10 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Referee%20Gender/</guid>
      <description>

&lt;p&gt;We looked at author gender in &lt;a href=&#34;http://jonathanweisberg.org/post/Author Gender/&#34;&gt;a previous post&lt;/a&gt;, today let&amp;rsquo;s consider referees. Does their gender have any predictive value?&lt;/p&gt;

&lt;p&gt;Once again our discussion only covers men and women because we don&amp;rsquo;t have the data to support a deeper analysis.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Using data from &lt;a href=&#34;http://www.ergophiljournal.org/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Ergo&lt;/em&gt;&lt;/a&gt;, we&amp;rsquo;ll consider the following questions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Requests&lt;/em&gt;. How are requests to referee distributed between men and women? Are men more likely to be invited, for example?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Responses&lt;/em&gt;. Does gender inform a referee&amp;rsquo;s response to a request? Are women more likely to say &amp;lsquo;yes&amp;rsquo;, for example?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Response-speed&lt;/em&gt;. Does gender inform how quickly a referee responds to an invitation (whether to agree or to decline)? Do men take longer to agree/decline an invitation, for example?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Completion-speed&lt;/em&gt;. If a referee does agree to provide a report, does their gender inform how quickly they&amp;rsquo;ll complete that report? Do men and women tend to complete their reports in the same time-frame?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Recommendations&lt;/em&gt;. Does gender inform how positive/negative a referee&amp;rsquo;s recommendation is? Are men and women equally likely to recommend that a submission be rejected, for example?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Influence&lt;/em&gt;. Does a referee&amp;rsquo;s gender affect the influence of their recommendation on the editor&amp;rsquo;s decison? Are the recommendations of male referees more likely to be followed, for example?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A quick overview of our data set: there are a total of 1526 referee-requests in &lt;em&gt;Ergo&lt;/em&gt;&amp;rsquo;s database. But only 1394 are included in this analysis. I&amp;rsquo;ve excluded:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Requests to review an invited resubmission, since these are a different sort of beast.&lt;/li&gt;
&lt;li&gt;Pending requests and reports, since the data for these are incomplete.&lt;/li&gt;
&lt;li&gt;A handfull of cases where the referee&amp;rsquo;s gender is either unknown, or doesn&amp;rsquo;t fit the male/female classification.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;requests&#34;&gt;Requests&lt;/h1&gt;

&lt;p&gt;How are requests distributed between men and women? 322 of our 1394 requests went to women, or 23.1% (1072 went to men, or 76.9%).&lt;/p&gt;

&lt;p&gt;How does this compare to the way men and women are represented in academic philosophy in general? Different sources and different subpopulations yield a range of estimates.&lt;/p&gt;

&lt;p&gt;At the low end, we saw in &lt;a href=&#34;http://jonathanweisberg.org/post/Author Gender/&#34;&gt;an earlier post&lt;/a&gt; that about 15.3% of &lt;em&gt;Ergo&lt;/em&gt;&amp;rsquo;s submissions come from women. The PhilPapers survey yields a range from 16.2% (&lt;a href=&#34;https://philpapers.org/surveys/demographics.pl&#34; target=&#34;_blank&#34;&gt;all respondents&lt;/a&gt;) to 18.4% (&lt;a href=&#34;https://philpapers.org/surveys/demographics.pl?affil=Target+faculty&amp;amp;survey=8&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;target&amp;rdquo; faculty&lt;/a&gt;). And sources cited in &lt;a href=&#34;http://www.faculty.ucr.edu/~eschwitz/SchwitzPapers/WomenInPhil-160315b.pdf&#34; target=&#34;_blank&#34;&gt;Schwitzgebel &amp;amp; Jennings&lt;/a&gt; estimate the percentage of women faculty in various English speaking countries at 23% for Australia, 24% for the U.K., and 19&amp;ndash;26% for the U.S.&lt;/p&gt;

&lt;p&gt;So we have a range of baseline estimates from 15% to 26%. For comparison, the 95% confidence interval around our 23.1% finding is (21%, 25.4%).&lt;/p&gt;

&lt;h1 id=&#34;responses&#34;&gt;Responses&lt;/h1&gt;

&lt;p&gt;Do men and women differ in their responses to these requests? Here are the raw numbers:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Agreed&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Declined / No Response / Canceled&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;101&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;221&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;403&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;669&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The final column calls for some explanation. I&amp;rsquo;m lumping togther several scenarios here: (i) the referee responds to decline the request, (ii) the referee never responds, (iii) the editors cancel the request because it was made in error. Unfortunately, these three scenarios are hard to distinguish based on the raw data. For example, sometimes a referee declines by email rather than via our online system, and the handling editor then cancels the request instead of marking it as &amp;ldquo;Declined&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;With that in mind, here are the proportions graphically:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/referee_gender_files/unnamed-chunk-6-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Men agreed more often than women: approximately 38% vs. 31%. And this difference is statistically significant.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:0&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:0&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Note that women and men accounted for about 20% and 80% of the &amp;ldquo;Agreed&amp;rdquo; responses, respectively. Whether this figure differs significantly from the gender makeup of &amp;ldquo;the general population&amp;rdquo; depends, as before, on the source and subpopulation we use for that estimate.&lt;/p&gt;

&lt;p&gt;We saw that estimates of female representation ranged from roughly 15% to 26%. For comparison, the 95% confidence interval around our 20% finding is (16.8%, 23.8%).&lt;/p&gt;

&lt;h1 id=&#34;response-speed&#34;&gt;Response-speed&lt;/h1&gt;

&lt;p&gt;Do men and women differ in response-speed&amp;mdash;in how quickly they respond to a referee request (whether to agree or to decline)?&lt;/p&gt;

&lt;p&gt;The average response-time for women is 1.92 days, and for men it&amp;rsquo;s 1.58 days. This difference is not statistically significant.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;A boxplot likewise suggests that men and women have similar interquartile ranges:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/referee_gender_files/unnamed-chunk-9-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;h1 id=&#34;completion-speed&#34;&gt;Completion-speed&lt;/h1&gt;

&lt;p&gt;What about completion-speed: is there any difference in how long men and women take to complete their reports?&lt;/p&gt;

&lt;p&gt;Women took 27.6 days on average, while men took 23.8 days. This difference is statistically significant.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Does that mean men are more likely to complete their reports on time? Not necessarily. Here&amp;rsquo;s a frequency polygram showing when reports were completed:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/referee_gender_files/unnamed-chunk-11-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;The spike at the four-week mark corresponds to the standard due date. We ask referees to submit their reports within 28 days of the initial request.&lt;/p&gt;

&lt;p&gt;It looks like men had a stronger tendency to complete their reports early. But were they more likely to complete them on time?&lt;/p&gt;

&lt;p&gt;One way to tackle this question is to look at how completed reports accumulate with time (the &lt;a href=&#34;https://en.wikipedia.org/wiki/Empirical_distribution_function&#34; target=&#34;_blank&#34;&gt;empirical cumulative distribution&lt;/a&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/referee_gender_files/unnamed-chunk-12-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;As expected, the plot shows that men completed their reports early with greater frequency. But it also looks like women and men converged around the four-week mark, when reports were due.&lt;/p&gt;

&lt;p&gt;Another way of approaching the question is to classify reports as either &amp;ldquo;On Time&amp;rdquo; or &amp;ldquo;Late&amp;rdquo;, according to whether they were completed before Day 29.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;On Time&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Late&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;38&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;242&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;121&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/referee_gender_files/unnamed-chunk-14-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;A chi-square test of independence then finds no statistically significant difference.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Apparently men and women differed in their tendency to be early, but not necessarily in their tendency to be on time.&lt;/p&gt;

&lt;h1 id=&#34;recommendations&#34;&gt;Recommendations&lt;/h1&gt;

&lt;p&gt;Did male and female referees differ in their recommendations to the editors?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Ergo&lt;/em&gt; offers referees four recommendations to choose from. The raw numbers:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Reject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Major Revisions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Minor Revisions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Accept&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;42&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;154&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;103&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;45&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In terms of frequencies:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/referee_gender_files/unnamed-chunk-16-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;The differences here are not statistically significant according to a chi-square test of independence.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h1 id=&#34;influence&#34;&gt;Influence&lt;/h1&gt;

&lt;p&gt;Does a referee&amp;rsquo;s gender affect whether the editor follows their recommendation? We can tackle this question a few different ways.&lt;/p&gt;

&lt;p&gt;One way is to just tally up those cases where the editor&amp;rsquo;s decision was the same as the referee&amp;rsquo;s recommendation, and those where it was different.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Same&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Different&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;51&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;37&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;206&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;157&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/referee_gender_files/unnamed-chunk-17-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;Clearly there&amp;rsquo;s no statistically significant difference between male and female referees here.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:7&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:7&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;A second approach would be to assign numerical ranks to referees&amp;rsquo; recommendations and editors&amp;rsquo; decisions: Reject = 1, Major Revisions = 2, etc. Then we can consider how far the editor&amp;rsquo;s decision is from the referee&amp;rsquo;s recommendation. For example, a decision of Accept is 3 away from a recommendation of Reject, while a decision of Major Revisions is 2 away from a recommendation of Accept.&lt;/p&gt;

&lt;p&gt;By this measure, the average distance between the referee&amp;rsquo;s recommendation and the editor&amp;rsquo;s decision was 0.57 for women and 0.56 for men&amp;mdash;clearly not a statistically significant difference.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:8&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:8&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;

&lt;p&gt;Men received more requests to referee than women, as expected given the well known gender imbalance in academic philosophy. The distribution of requests between men (76.9%) and women (23.1%) was in line with some estimates of the gender makeup of academic philosophy, though not all estimates.&lt;/p&gt;

&lt;p&gt;Men were more likely to agree to a request (38% vs. 31%), a statistically significant difference. Women accounted for about 20% of the &amp;ldquo;Agreed&amp;rdquo; responses, however, consistent with most (but not all) estimates of the gender makeup of academic philosophy.&lt;/p&gt;

&lt;p&gt;There was no statistically significant difference in response-speed, but there was in the speed with which reports were completed (23.8 days on average for men, 27.6 days for women). This difference appears to be due to a stronger tendency on the part of men to complete their reports early, though not necessarily a greater chance of meeting the deadline.&lt;/p&gt;

&lt;p&gt;Finally, there was no statistically significant difference in the recommendations of male and female referees, or in editors&amp;rsquo; uptake of those recommendations.&lt;/p&gt;

&lt;h1 id=&#34;technical-notes&#34;&gt;Technical Notes&lt;/h1&gt;

&lt;p&gt;This post was written in R Markdown and the source is &lt;a href=&#34;https://github.com/jweisber/rgo/blob/master/referee%20gender/referee%20gender.Rmd&#34; target=&#34;_blank&#34;&gt;available on GitHub&lt;/a&gt;. I&amp;rsquo;m new to both R and classical statistics, and this post is a learning exercise for me. So I encourage you to check the code and contact me with corrections.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Unlike in the previous analysis of author gender, however, here we do have a few known cases where either (i) the referee identifies as neither male nor female, or (ii) they identify as something more specific, e.g. &amp;ldquo;transgender male&amp;rdquo; rather than just &amp;ldquo;male&amp;rdquo;. But these cases are still too few for statistical analysis.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:0&#34;&gt;$\chi^2$(1, &lt;em&gt;N&lt;/em&gt; = 1394) = 3.89, &lt;em&gt;p&lt;/em&gt; = 0.05.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:0&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;&lt;em&gt;t&lt;/em&gt;(437.43) = -1.63, &lt;em&gt;p&lt;/em&gt; = 0.1
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;&lt;em&gt;t&lt;/em&gt;(144.26) = -2.46, &lt;em&gt;p&lt;/em&gt; = 0.02
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;$\chi^2$(1, &lt;em&gt;N&lt;/em&gt; = 451) = 2.59, &lt;em&gt;p&lt;/em&gt; = 0.11.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;$\chi^2$(3, &lt;em&gt;N&lt;/em&gt; = 451) = 3.6, &lt;em&gt;p&lt;/em&gt; = 0.31.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;$\chi^2$(1, &lt;em&gt;N&lt;/em&gt; = 451) = 0.01, &lt;em&gt;p&lt;/em&gt; = 0.93.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:7&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:8&#34;&gt;&lt;em&gt;t&lt;/em&gt;(117.57) = 0.07, &lt;em&gt;p&lt;/em&gt; = 0.95.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:8&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>In Defense of Reviewer 2</title>
      <link>http://jonathanweisberg.org/post/Reviewer%202/</link>
      <pubDate>Mon, 06 Feb 2017 10:36:10 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Reviewer%202/</guid>
      <description>

&lt;p&gt;Spare a thought for Reviewer 2, that much-maligned shade of academe. There&amp;rsquo;s even &lt;a href=&#34;https://twitter.com/hashtag/reviewer2&#34; target=&#34;_blank&#34;&gt;a hashtag&lt;/a&gt; dedicated to the joke:&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet tw-align-center&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;A rare glimpse of reviewer 2, seen here in their natural habitat &lt;a href=&#34;https://t.co/lpT1BVhDCX&#34;&gt;pic.twitter.com/lpT1BVhDCX&lt;/a&gt;&lt;/p&gt;&amp;mdash; Aidan McGlynn (@AidanMcGlynn) &lt;a href=&#34;https://twitter.com/AidanMcGlynn/status/820647829446283264&#34;&gt;January 15, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;http://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;But is it just a joke? Order could easily matter here.&lt;/p&gt;

&lt;p&gt;Referees invited later weren&amp;rsquo;t the editor&amp;rsquo;s first choice, after all. Maybe they&amp;rsquo;re less competent, less likely to appreciate your brilliant insights as an author. Or maybe they&amp;rsquo;re more likely to miss well-disguised flaws! Then we should expect Reviewer 2 to be the more &lt;em&gt;generous&lt;/em&gt; one.&lt;/p&gt;

&lt;p&gt;Come to think of it, we can order referees in other ways beside order-of-invite. We might order them according to who completes their report fastest, for example. And faster referees might be more careless, hence more dismissive. Or they might be less critical and thus more generous.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a lot to consider. Let&amp;rsquo;s investigate, using &lt;a href=&#34;http://www.ergophiljournal.org/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Ergo&lt;/em&gt;&lt;/a&gt;&amp;rsquo;s data, &lt;a href=&#34;http://jonathanweisberg.org/tags/rgo/&#34;&gt;as usual&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;severity-generosity&#34;&gt;Severity &amp;amp; Generosity&lt;/h1&gt;

&lt;p&gt;Reviewer 2 is accused of a lot. It&amp;rsquo;s not just that their overall take is more severe; they also tend to miss the point. They&amp;rsquo;re irresponsible and superficial in their reading. And to the extent they do appreciate the author&amp;rsquo;s point, their objections are poorly thought out. What&amp;rsquo;s more, if they bother to demand revisions, their demands are unreasonable.&lt;/p&gt;

&lt;p&gt;We can&amp;rsquo;t measure these things directly, of course. But we can estimate a referee&amp;rsquo;s generosity indirectly, using their recommendation to the editors as a proxy.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Ergo&lt;/em&gt;&amp;rsquo;s referees choose from four possible recommendations: Reject, Major Revisions, Minor Revisions, and Accept. To estimate a referee&amp;rsquo;s generosity, we&amp;rsquo;ll assign these recommendations numerical ranks, from 1 (Reject) up through 4 (Accept).&lt;/p&gt;

&lt;p&gt;The higher this number, the more generous the referee; the lower, the more severe.&lt;/p&gt;

&lt;h1 id=&#34;invite-order&#34;&gt;Invite Order&lt;/h1&gt;

&lt;p&gt;Is there any connection between the order in which referees are invited and their severity?&lt;/p&gt;

&lt;p&gt;Usually an editor has to try a few people before they get two takers. So we can assign each potential referee an &amp;ldquo;invite rank&amp;rdquo;. The first person asked has rank 1, the second person asked has rank 2, and so on.&lt;/p&gt;

&lt;p&gt;Is there a correlation between invite rank and severity?&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a plot of invite rank (&lt;em&gt;x&lt;/em&gt;-axis) and generosity (&lt;em&gt;y&lt;/em&gt;-axis). (The points have non-integer heights because I&amp;rsquo;ve added some random  &lt;a href=&#34;http://r4ds.had.co.nz/data-visualisation.html#position-adjustments&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;jitter&amp;rdquo;&lt;/a&gt; to make them all visible. Otherwise you&amp;rsquo;d just see an uninformative grid.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reviewer_2_files/unnamed-chunk-2-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The blue curve shows the overall trend in the data.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; It&amp;rsquo;s basically flat all the way through, except at the far-right end where the data is too sparse to be informative.&lt;/p&gt;

&lt;p&gt;We can also look at the classic measure of correlation known as &lt;a href=&#34;https://en.wikipedia.org/wiki/Spearman&#39;s_rank_correlation_coefficient&#34; target=&#34;_blank&#34;&gt;Spearman&amp;rsquo;s rho&lt;/a&gt;. The estimate is essentially 0 given our data ($r_s$ = 0.01).&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Evidently, invite-rank has no discernible impact on severity.&lt;/p&gt;

&lt;h1 id=&#34;speed&#34;&gt;Speed&lt;/h1&gt;

&lt;p&gt;But now let&amp;rsquo;s look at the speed with which a referee completes their report:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/reviewer_2_files/unnamed-chunk-4-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here an upward trend is discernible. And our estimate of Spearman&amp;rsquo;s rho agrees: $r_s$ = 0.1, a small but non-trivial correlation.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Apparently, referees who take longer tend to be more generous!&lt;/p&gt;

&lt;h1 id=&#34;my-take&#34;&gt;My Take&lt;/h1&gt;

&lt;p&gt;I find these results encouraging, for the most part.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s nice to know that an editor&amp;rsquo;s first choice for a referee is the same as their fifth, as far as how severe or generous they&amp;rsquo;re likely to be.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s also nice to know that the speed with which a referee completes their report doesn&amp;rsquo;t &lt;em&gt;hugely&lt;/em&gt; inform heir severity.&lt;/p&gt;

&lt;p&gt;One we might well worry that faster referees are unduly severe. But this worry is tempered by a few considerations.&lt;/p&gt;

&lt;p&gt;For one thing, the effect we found is small enough that it could just be noise. It is detectable using tools like regression and significance testing, so it&amp;rsquo;s not to be dismissed out of hand. But we might also do well to heed the wisdom of &lt;a href=&#34;https://xkcd.com/1725/&#34; target=&#34;_blank&#34;&gt;XKCD&lt;/a&gt; here:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://imgs.xkcd.com/comics/linear_regression_2x.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Even if the effect is real, though, it could be a good thing just as easily as a bad thing.&lt;/p&gt;

&lt;p&gt;True, referees who work fast might be sloppy and dismissive. And those who take longer might feel guiltier and thus be unduly generous.&lt;/p&gt;

&lt;p&gt;But maybe referees who are more on the ball are both more prompt and more apt to spot a submission&amp;rsquo;s flaws. Or (as my coeditor Franz Huber pointed out) manuscripts that should clearly be rejected might be easier to referee on average, hence faster.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s hard to know what to make of this effect, if it is an effect. Clearly, &lt;a href=&#34;https://twitter.com/hashtag/moreresearchisneeded&#34; target=&#34;_blank&#34;&gt;#MoreResearchIsNeeded&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;technical-notes&#34;&gt;Technical Notes&lt;/h1&gt;

&lt;p&gt;This post was written in R Markdown and the source is &lt;a href=&#34;https://github.com/jweisber/rgo/blob/master/reviewer%202/reviewer%202.Rmd&#34; target=&#34;_blank&#34;&gt;available on GitHub&lt;/a&gt;. I&amp;rsquo;m new to both R and statistics, and this post is a learning exercise for me. So I encourage you to check the code and contact me with corrections.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Specifically, the blue curve is a regression curve using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Local_regression#Definition_of_a_LOESS_model&#34; target=&#34;_blank&#34;&gt;LOESS&lt;/a&gt; method of fit.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;A significance test of the null hypothesis $\rho_s$ = 0 yields &lt;em&gt;p&lt;/em&gt; = 0.87.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Testing the null hypothesis $\rho_s$ = 0 yields &lt;em&gt;p&lt;/em&gt; = 0.03.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 3: Beyond the Second Dimension</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%203/</link>
      <pubDate>Fri, 27 Jan 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%203/</guid>
      <description>

&lt;p&gt;Last time we saw why accuracy-mavens prefer Brier distance to Euclidean distance. But we did everything in two dimensions. That&amp;rsquo;s fine for a coin toss, with only two possibilities. But what if there are three doors and one of them has a prize behind it??&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t panic! Today we&amp;rsquo;re going to verify that Brier distance is still a proper way of measuring inaccuracy, even when there are more than two possibilities. (Next time we&amp;rsquo;ll talk about Euclidean distance with more than two possibilitie.)&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start small, with just three possibilities. $\renewcommand{\vec}[1]{\mathbf{#1}}\newcommand{\p}{\vec{p}}\newcommand{\q}{\vec{q}}\newcommand{\v}{\vec{v}}\newcommand{\EIpq}{EI_{\p}(\q)}\newcommand{\EIpp}{EI_{\p}(\p)}$&lt;/p&gt;

&lt;h1 id=&#34;three-possibilities&#34;&gt;Three Possibilities&lt;/h1&gt;

&lt;p&gt;You&amp;rsquo;re on a game show; there are three doors; one has a prize behind it. The three possibilities are represented by the vertices $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Three Vertices.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Your credences are given by some probability assignment $(p_1, p_2, p_3)$. It might be $(1/ 3, 1/ 3, 1/ 3)$ but it could be anything&amp;hellip; $(7/ 10, 2/ 10, 1/ 10)$, for example.&lt;/p&gt;

&lt;p&gt;In case you&amp;rsquo;re curious, here&amp;rsquo;s what the range of possible probability assignments looks like in graphical terms:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/Three Vertices with Hull.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The triangular surface is the three-dimensional analogue of the diagonal line in &lt;a href=&#34;http://jonathanweisberg.org/img/accuracy/2D Dominance Diagram.png&#34;&gt;the two-dimensional diagram&lt;/a&gt; from our &lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy for Dummies - Part 1/&#34;&gt;first post&lt;/a&gt; in this series.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;ll be handy to refer to points on this surface using single letters, like $\p$ for $(p_1, p_2, p_3)$. We&amp;rsquo;ll write these letters in bold, to distinguish a sequence of numbers like $\p$ from a single number like $p_1$. (In math-speak, $\p$ is a &lt;em&gt;vector&lt;/em&gt; and $p_1$ is a &lt;em&gt;scalar&lt;/em&gt;.)&lt;/p&gt;

&lt;p&gt;Our job is to show that Brier distance is &amp;ldquo;proper&amp;rdquo; in three dimensions. Let&amp;rsquo;s recall what that means: given a point $\p$, the expected Brier distance (according to $\p$) of a point $\q = (q_1, q_2, q_3)$ from the three vertices is always smallest when $\q = \p$.&lt;/p&gt;

&lt;p&gt;What does &lt;em&gt;that&lt;/em&gt; mean?&lt;/p&gt;

&lt;p&gt;Recall, the Brier distance from $\q$ to the vertex $(1, 0, 0)$ is:
$$
(q_1 - 1)^2 + (q_2 - 0)^2 + (q_3 - 0)^2
$$
Or, more succinctly:
$$
(q_1 - 1)^2 + q_2^2 + q_3^2
$$
So the &lt;em&gt;expected&lt;/em&gt; Brier distance of $\q$ according to $\p$ weights each such sum by the probability $\p$ assigns to the corresponding vertex.
$$
\begin{align}
&amp;amp;\quad\quad p_1 \left( (q_1 - 1)^2 + q_2^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_2 \left( q_1^2 + (q_2 - 1)^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_3 \left( q_1^2 + q_2^2 + (q_3 - 1)^2 \right)
\end{align}
$$
We need to show that this quantity is smallest when $\q = \p$, i.e. when $q_1 = p_1$, $q_2 = p_2$, and $q_3 = p_3$.&lt;/p&gt;

&lt;h2 id=&#34;visualizing-expected-inaccuracy&#34;&gt;Visualizing Expected Inaccuracy&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s do some visualization. We&amp;rsquo;ll take a few examples of $\p$, and graph the expected inaccuracy of other possible points $\q$, using Brier distance to measure inaccuracy.&lt;/p&gt;

&lt;p&gt;For example, suppose $\p = (1/ 3, 1/ 3, 1/ 3)$. Then the expected inaccuracy of each point $\q$ looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/BrierEI3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The horizontal axes represent $q_1$ and $q_2$. The vertical axis represents expected inaccuracy.&lt;/p&gt;

&lt;p&gt;Where&amp;rsquo;s $q_3$?? Not pictured! If we used all three visible dimensions for the elements of $\q$, we&amp;rsquo;d have nothing left to visualize expected inaccuracy. But $q_3$ is there implicitly. You can always get $q_3$ by calculating $1 - (q_1 + q_2)$, because $\q$ is a probability assignment. So we don&amp;rsquo;t actually need $q_3$ in the graph!&lt;/p&gt;

&lt;p&gt;Now, the red dot is the lowest point on the surface: the smallest possible expected inaccuracy, according to $\p$. But where is that in terms of $q_1$ and $q_2$? Let&amp;rsquo;s look at the same graph from directly above:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/BrierEI3-above.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hey! Looks like the red dot is located at $q_1 = 1/ 3$ and $q_2 = 1/ 3$, i.e. at $\q = (1/ 3, 1/ 3, 1/ 3)$. Also known as $\p$. So that&amp;rsquo;s promising: looks like expected inaccuracy is minimized when $\q = \p$, at least in this example.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s do one more example, $\p = (6/ 10, 3/ 10, 1/ 10)$. Then the expected Brier distance of each point $\q$ looks like this:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/BrierEI3-2.png&#34; alt=&#34;&#34; /&gt;
Or, taking the aerial view again:
&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/BrierEI3-2above.png&#34; alt=&#34;&#34; /&gt;
Yep, looks like the red dot is located at $q_1 = 6/ 10$ and $q_2 = 3/ 10$, i.e. at $\q = (6/ 10, 3/ 10, 1/ 10)$, also known as $\p$. So, once again, it seems expected inaccuracy is minimized when $\q = \p$.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s prove that that&amp;rsquo;s how it always is.&lt;/p&gt;

&lt;h2 id=&#34;a-proof&#34;&gt;A Proof&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll need a little notation: I&amp;rsquo;m going to write $\EIpq$ for the expected inaccuracy of point $\q$, according to $\p$.&lt;/p&gt;

&lt;p&gt;Now recall our formula for expected inaccuracy:
$$
\begin{align}
\EIpq
&amp;amp;= \quad p_1 \left( (q_1 - 1)^2 + q_2^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_2 \left( q_1^2 + (q_2 - 1)^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_3 \left( q_1^2 + q_2^2 + (q_3 - 1)^2 \right).
\end{align}
$$
How do we find the point $\q$ that minimizes this mess?&lt;/p&gt;

&lt;p&gt;Originally this post used some pretty tedious calculus. But thanks to a hot tip from &lt;a href=&#34;https://mathematics.stanford.edu/people/department-directory/name/jonathan-love/&#34; target=&#34;_blank&#34;&gt;Jonathan Love&lt;/a&gt;, we can get by just with algebra.&lt;/p&gt;

&lt;p&gt;First we need to expand the squares in our big ugly sum:
$$
\begin{align}
\EIpq
&amp;amp;= \quad p_1 \left( q_1^2 - 2q_1 + 1 + q_2^2 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_2 \left( q_1^2 + q_2^2 - 2q_2 + 1 + q_3^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_3 \left( q_1^2 + q_2^2 + q_3^2 - 2q_3 + 1 \right).
\end{align}
$$
Then we&amp;rsquo;ll gather some common terms and rearrange things:
$$
\begin{align}
\EIpq &amp;amp;= (p_1 + p_2 + p_3)\left(q_1^2 + q_2^2 + q_3^2 + 1 \right) - 2p_1q_1 - 2p_2q_2 - 2p_3q_3.\\&lt;br /&gt;
\end{align}
$$
Since $p_1 + p_2 + p_3 = 1$, that simplifies to:
$$
\begin{align}
\EIpq &amp;amp;= q_1^2 + q_2^2 + q_3^2 + 1 - 2p_1q_1 - 2p_2q_2 - 2p_3q_3.\\&lt;br /&gt;
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Now we&amp;rsquo;ll use &lt;a href=&#34;https://mathematics.stanford.edu/people/department-directory/name/jonathan-love/&#34; target=&#34;_blank&#34;&gt;Jonathan&lt;/a&gt;&amp;rsquo;s ingenious trick. We&amp;rsquo;re going to add $p_1^2 + p_2^2 + p_3^2 - 1$ to this expression, &lt;em&gt;which doesn&amp;rsquo;t change where the minimum occurs&lt;/em&gt;. If you shift every point on a graph upwards by the same amount, the minimum is still in the same place. (Imagine everybody in the world grows by an inch overnight; the shortest person in the world is still the shortest, despite being an inch taller.)&lt;/p&gt;

&lt;p&gt;Then, magically, we get an expression that factors into something tidy:
$$
\begin{align}
&amp;amp;\phantom{=}\phantom{=} p_1^2 + p_2^2 + p_3^2 + q_1^2 + q_2^2 + q_3^2 - 2p_1q_1 - 2p_2q_2 - 2p_3q_3\\&lt;br /&gt;
  &amp;amp;= (p_1 - q_1)^2 + (p_2 - q_2)^2 + (p_3 - q_3)^2.
\end{align}
$$
And not just tidy, but easy to minimize. It&amp;rsquo;s a sum of squares, and squares are never negative. So the smallest possible value  is $0$, which occurs when all the squares are $0$, i.e. when $q_1 = p_1$, $q_2 = p_2$, and $q_3 = p_3$.&lt;/p&gt;

&lt;p&gt;So, the minimum of $\EIpq$ occurs in the same place, namely when $\q = \p$!&lt;/p&gt;

&lt;h2 id=&#34;the-nth-dimension&#34;&gt;The Nth Dimension&lt;/h2&gt;

&lt;p&gt;Now we can use the same idea to generalize to any number of dimensions. Since the steps are essentially identical, I&amp;rsquo;ll keep it short and (I hope) sweet.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp;
Given a probability assignment $\p = (p_1, \ldots, p_n)$, if inaccuracy is measured using Brier distance, then $\EIpq$ is uniquely minimized when $\q = \p$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp;
Let $\p = (p_1, \ldots, p_n)$ be a probability assignment, and let $\EIpq$ be the expected inaccuracy according to $\p$ of probability assignment $\q = (q_1, \ldots, q_n)$, measured using Brier distance.&lt;/p&gt;

&lt;p&gt;First we simplify our expression for $\EIpq$ using algebra:
$$
\begin{align}
\EIpq
&amp;amp;= \quad p_1 \left( (q_1 - 1)^2 + q_2^2 + \ldots + q_n^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + p_2 \left( q_1^2 + (q_2 - 1)^2 + \ldots + q_n^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad\quad \vdots\\&lt;br /&gt;
  &amp;amp;\quad + p_n \left( q_1^2 + q_2^2 + \ldots + q_{n-1}^2 + (q_n - 1)^2 \right)\\&lt;br /&gt;
&amp;amp;= (p_1 + \ldots + p_n)\left( q_1^2 + \ldots + q_n^2 + 1\right) - 2 p_1 q_1 - \ldots - 2 p_n q_n\\&lt;br /&gt;
&amp;amp;= q_1^2 + \ldots + q_n^2 + 1 - 2 p_1 q_1 - \ldots - 2 p_n q_n.
\end{align}
$$
Now, because $p_1^2 + \ldots + p_n^2 - 1$ is a constant, adding it to $\EIpq$ doesn&amp;rsquo;t change where the minimum occurs. So we can minimize instead:
$$
\begin{align}
&amp;amp;\phantom{=}\phantom{=} p_1^2 + \ldots + p_n^2 + q_1^2 + \ldots + q_n^2 - 2 p_1 q_1 - \ldots - 2 p_n q_n\\&lt;br /&gt;
&amp;amp;= (p_1 - q_1)^2 + \ldots + (p_n - q_n)^2.
\end{align}
$$
Being a sum of squares, the minimum value here cannot be less than $0$, which occurs when $\q = \p$. &lt;span style=&#34;float: right;&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;div class=&#34;text-center&#34;&gt;
&lt;object data=&#34;http://www.youtube.com/embed/MkmMxfCgewQ&#34;
   width=&#34;560&#34; height=&#34;315&#34; classboo=&#34;text-center&#34;&gt;&lt;/object&gt;
&lt;/div&gt;

&lt;p&gt;So what did we learn? That Brier distance isn&amp;rsquo;t just &amp;ldquo;stable&amp;rdquo; in toy cases like a coin-toss. It&amp;rsquo;s also stable in toy cases with any finite number of outcomes.&lt;/p&gt;

&lt;p&gt;No matter how many outcomes are under consideration, each probability assignment expects itself to do best at minimizing inaccuracy, if we use Brier distance to measure inaccuracy.&lt;/p&gt;

&lt;p&gt;To go beyond toy cases, we&amp;rsquo;d have to extend this result to cases with infinite numbers of possibilities. And I haven&amp;rsquo;t even begun to think about how to do that.&lt;/p&gt;

&lt;p&gt;Instead, next time we&amp;rsquo;ll look at what happens in $3+$ dimensions when we use Euclidean distance instead of Brier distance. And it&amp;rsquo;s actually kind of interesting! It turns out Euclidean distance is still improper in $3+$ dimensions, but not necessarily in the same way as in $2$ dimensions. More on that next time&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gender &amp; Journal Submissions</title>
      <link>http://jonathanweisberg.org/post/Author%20Gender/</link>
      <pubDate>Thu, 26 Jan 2017 10:36:10 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Author%20Gender/</guid>
      <description>

&lt;p&gt;Does an author&amp;rsquo;s gender affect the fate of their submission to an academic journal? It&amp;rsquo;s a big question, even if we restrict ourselves to philosophy journals.&lt;/p&gt;

&lt;p&gt;But we can make a start by using &lt;a href=&#34;http://www.ergophiljournal.org&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Ergo&lt;/em&gt;&lt;/a&gt; as one data-point. I&amp;rsquo;ll examine two questions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Question 1: Does gender affect the decision rendered at &lt;em&gt;Ergo&lt;/em&gt;? Are men more likely to have their papers accepted, for example?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Question 2: Does gender affect time-to-decision at &lt;em&gt;Ergo&lt;/em&gt;? For example, do women have to wait longer on average for a decision?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;

&lt;p&gt;Some important background and caveats before we begin:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Our data set goes back to Feb. 11, 2015, when &lt;em&gt;Ergo&lt;/em&gt; moved to its current online system for handling submissions. We do have records going back to Jun. 2013, when the journal launched. But integrating the data from the two systems is a programming hassle I haven&amp;rsquo;t faced up to yet.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;We&amp;rsquo;ll exclude submissions that were withdrawn by the author before a decision could be rendered. Usually, when an author withdraws a submission, it&amp;rsquo;s so that they can resubmit a trivially-corrected manuscript five minutes later. So this data mostly just gets in the way.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;We&amp;rsquo;ll also exclude submissions that were still under review as of Jan. 1, 2017, since the data there is incomplete.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The gender data we&amp;rsquo;ll be using was gathered manually by &lt;em&gt;Ergo&lt;/em&gt;&amp;rsquo;s managing editors (me and Franz Huber). In most cases we didn&amp;rsquo;t know the author personally. So we did a quick google to see whether we could infer the author&amp;rsquo;s gender based on public information, like pronouns and/or pictures. When we weren&amp;rsquo;t confident that we could, we left their gender as &amp;ldquo;unknown&amp;rdquo;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;This analysis covers only men and women, because there haven&amp;rsquo;t yet been any cases where we could confidently infer that an author identified as another gender. And the &amp;ldquo;gender unknown&amp;rdquo; cases are too few for reliable statistical analysis.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Since we only have data for the gender of the submitting author, our analysis will overlook co-authors.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With that in mind, a brief overview: our data set contains $696$ submissions over almost two years (Feb. 11, 2015 up to Jan. 1, 2017), but only $639$ of these are included in this analysis. The $52$ submissions that were in-progress as of Jan. 1, 2017, or were withdrawn by the author, have been excluded. Another $5$ cases where the author&amp;rsquo;s gender was unknown were also excluded.&lt;/p&gt;

&lt;h1 id=&#34;gender-decisions&#34;&gt;Gender &amp;amp; Decisions&lt;/h1&gt;

&lt;p&gt;Does an author&amp;rsquo;s gender affect the journal&amp;rsquo;s decision about whether their submission is accepted? We can slice this question a few different ways:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Does gender affect the first-round decision to reject/accept/R&amp;amp;R?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Does gender affect the likelihood of desk-rejection, specifically?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Does gender affect the chance of converting an R&amp;amp;R into an accept?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Does gender affect the ultimate decision to accept/reject (whether via an intervening R&amp;amp;R or not)?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The short answer to all these questions is: no, at least not in a statistically significant way. But there are some wrinkles. So let&amp;rsquo;s take each question in turn.&lt;/p&gt;

&lt;h2 id=&#34;first-round-decisions&#34;&gt;First-Round Decisions&lt;/h2&gt;

&lt;p&gt;Does gender affect the first-round decision to reject/accept/R&amp;amp;R?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Ergo&lt;/em&gt; has two kinds of R&amp;amp;R, Major Revisions and Minor Revisions. Here are the raw numbers:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Reject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Major Revisions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Minor Revisions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Accept&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;76&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;438&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Graphically, in terms of percentages:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/author_gender_files/unnamed-chunk-4-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;There are differences here, of course: women were asked to make major revisions more frequently than men, for example. And men received verdicts of minor revisions or outright acceptance more often than women.&lt;/p&gt;

&lt;p&gt;Are these differences significant? They don&amp;rsquo;t look it from the bar graph. And a standard chi-square test agrees.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&#34;desk-rejections&#34;&gt;Desk Rejections&lt;/h2&gt;

&lt;p&gt;Things are a little more interesting if we separate out desk rejections from rejections-after-external-review. The raw numbers:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Desk Reject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Non-desk Reject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Major Revisions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Minor Revisions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Accept&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;61&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;311&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;127&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In terms of percentages for men and women:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/author_gender_files/unnamed-chunk-9-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;The differences here are more pronounced. For example, women had their submissions desk-rejected more frequently, a difference of about 8.5%.&lt;/p&gt;

&lt;p&gt;But once again, the differences are not statistically significant according to the standard chi-square test.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&#34;ultimate-decisions&#34;&gt;Ultimate Decisions&lt;/h2&gt;

&lt;p&gt;What if we just consider a submission&amp;rsquo;s ultimate fate&amp;mdash;whether it&amp;rsquo;s accepted or rejected in the end? Here the results are pretty clear:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Reject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Accept&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;78&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;450&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;38&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/author_gender_files/unnamed-chunk-13-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;Pretty obviously there&amp;rsquo;s no significant difference, and a chi-square test agrees.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&#34;conversions&#34;&gt;Conversions&lt;/h2&gt;

&lt;p&gt;Our analysis so far suggests that men and women probably have about equal chance of converting an R&amp;amp;R into an accept. Looking at the numbers directly corroborates that thought:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Reject&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Accept&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/author_gender_files/unnamed-chunk-16-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;As before, a standard chi-square test agrees.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; Though, of course, the numbers here are small and shouldn&amp;rsquo;t be given too much weight.&lt;/p&gt;

&lt;h2 id=&#34;conclusion-so-far&#34;&gt;Conclusion So Far&lt;/h2&gt;

&lt;p&gt;None of the data so far yielded a significant difference between men and women. None even came particularly close (see the footnotes for the numerical details). So it seems the journal&amp;rsquo;s decisions are independent of gender, or nearly so.&lt;/p&gt;

&lt;h1 id=&#34;gender-time-to-decision&#34;&gt;Gender &amp;amp; Time-to-Decision&lt;/h1&gt;

&lt;p&gt;Authors don&amp;rsquo;t just care what decision is rendered, of course. They also care that decisions are made quickly. Can men and women expect similar wait-times?&lt;/p&gt;

&lt;p&gt;The average time-to-decision is 23.3 days. But for men it&amp;rsquo;s 23.9 days while for women it&amp;rsquo;s only 19.6. This looks like a significant difference. And although it isn&amp;rsquo;t quite significant according to a standard $t$ test, it very nearly is.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;What might be going on here? Let&amp;rsquo;s look at the observed distributions for men and women:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/author_gender_files/unnamed-chunk-19-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;A striking difference is that there are so many more submissions from men than from women. But otherwise these distributions actually look quite similar. Each is a bimodal distribution with one peak for desk-rejections around one week, and another, smaller peak for externally reviewed submissions around six or seven weeks.&lt;/p&gt;

&lt;p&gt;We noticed earlier that women had more desk-rejections by about 8.5%. And while that difference wasn&amp;rsquo;t statistically significant, it may still be what&amp;rsquo;s causing the almost-significant difference we see with time-to-decision (especially if men also have a few extra outliers, as seems to be the case).&lt;/p&gt;

&lt;p&gt;To test this hypothesis, we can separate out desk-rejections and externally reviewed submissions. Graphically:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/author_gender_files/unnamed-chunk-20-1.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/author_gender_files/unnamed-chunk-20-2.png&#34; alt=&#34;&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;Aside from the raw numbers, the distributions for men and for women look very similar. And if we run separate $t$ tests for desk-rejections and for externally reviewed submissions, gender differences are no longer close to significance. For desk-rejections $p = 0.24$. And for externally reviewed submissions $p = 0.46$.&lt;/p&gt;

&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;Apparently an author&amp;rsquo;s gender has little or no effect on the content or speed of &lt;em&gt;Ergo&lt;/em&gt;&amp;rsquo;s decision. I&amp;rsquo;d &lt;em&gt;like&lt;/em&gt; to think this is a result of the journal&amp;rsquo;s &lt;a href=&#34;http://www.ergophiljournal.org/review.html&#34; target=&#34;_blank&#34;&gt;strong commitment to triple-anonymous review&lt;/a&gt;. But without data from other journals to make comparisons, we can&amp;rsquo;t really infer much about potential causes. And, of course, we can&amp;rsquo;t generalize to other journals with any confidence, either.&lt;/p&gt;

&lt;h1 id=&#34;technical-notes&#34;&gt;Technical Notes&lt;/h1&gt;

&lt;p&gt;This post was written in R Markdown and the source is &lt;a href=&#34;https://github.com/jweisber/rgo/blob/master/author%20gender/author%20gender.Rmd&#34; target=&#34;_blank&#34;&gt;available on GitHub&lt;/a&gt;. I&amp;rsquo;m new to both R and classical statistics, and this post is a learning exercise for me. So I encourage you to check the code and contact me with corrections.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;&lt;p&gt;Specifically, $\chi^2(3, N = 587) = 1.89$, $p = 0.6$. This raises the question of power, and for a small effect size ($w = .1$) power is only about $0.51$. But it increases quickly to $0.99$ at $w = .2$.&lt;/p&gt;

&lt;p&gt;Given the small numbers in some of the columns though, especially the Accept column, we might prefer a different test than $\chi^2$. The more precise $G$ test yields $p = 0.46$, still fairly large. And Fisher&amp;rsquo;s exact test yields $p = 0.72$.&lt;/p&gt;

&lt;p&gt;We might also do an ordinal analysis, since decisions have a natural desirability ordering for authors: Accept &amp;gt; Minor Revisions &amp;gt; Major Revisions &amp;gt; Reject. We can test for a linear trend by assigning integer ranks from 4 down through 1 &lt;a href=&#34;http://ca.wiley.com/WileyCDA/WileyTitle/productCd-0470463635.html&#34; target=&#34;_blank&#34;&gt;(Agresti 2007)&lt;/a&gt;.  A test of the &lt;a href=&#34;https://onlinecourses.science.psu.edu/stat504/node/91&#34; target=&#34;_blank&#34;&gt;Mantel-Haenszel statistic&lt;/a&gt; $M^2$ then yields $p = 0.82$.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;

&lt;li id=&#34;fn:2&#34;&gt;&lt;p&gt;Here we have $\chi^2(4, N = 587) = 4.64$, $p = 0.33$. As before, the power for a small effect ($w = .1$) is only middling, about 0.46, but increases quickly to near certainty ($0.98$) by $w = .2$.&lt;/p&gt;

&lt;p&gt;Instead of $\chi^2$ we might again consider a $G$ test, which yields $p = 0.24$, or Fisher&amp;rsquo;s exact test which yields $p = 0.37$.&lt;/p&gt;

&lt;p&gt;For an ordinal test using the ranking Desk Reject &amp;lt; Non-desk Reject &amp;lt; Major Revisions &amp;lt; etc., the Mantel-Haenszel statistic $M^2$ now yields $p = 0.39$.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Here we have $\chi^2(1, N = 571) = 0.11$, $p = 0.74$.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;$\chi^2(1, N = 52) = 0$, $p = 1$.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;Specifically, $t(137.71) = 1.78$, $p = 0.08$. Although a $t$ test may not actually be the best choice here, since (as we&amp;rsquo;re about to see) the sampling distributions aren&amp;rsquo;t normal, but rather bimodal. Still, we can compare this result to non-parametric tests like Wilcoxon-Mann-Whitney ($p = 0.1$) or the bootstrap-$t$  ($p = 0.07$). These $p$-values don&amp;rsquo;t quite cross the customary $\alpha = .05$ threshold either, but they are still small.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Accuracy for Dummies, Part 2: from Euclid to Brier</title>
      <link>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%202/</link>
      <pubDate>Wed, 18 Jan 2017 00:00:00 -0500</pubDate>
      
      <guid>http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%202/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://jonathanweisberg.org/post/Accuracy%20for%20Dummies%20-%20Part%201/&#34;&gt;Last time&lt;/a&gt; we saw that Euclidean distance is an &amp;ldquo;unstable&amp;rdquo; way of measuring inaccuracy. Given one assignment of probabilities, you&amp;rsquo;ll expect some other assignment to be more accurate (unless the first assignment is either perfectly certain or perfectly uncertain).&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s why accuraticians don&amp;rsquo;t use good ol&amp;rsquo; Euclidean distance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://crookedrunbrewing.files.wordpress.com/2014/05/scientician.png?w=240&#34; alt=&#34;Just ask this accuratician&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Instead they use&amp;hellip; well, there are lots of alternatives. But the closest thing to a standard one is &lt;em&gt;Brier distance&lt;/em&gt;: the square of Euclidean distance.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s Euclid&amp;rsquo;s formula for the distance between two points $(a, b)$ and $(c, d)$ in the plane:
$$ \sqrt{ (a - c)^2 + (b - d)^2 }. $$
And here&amp;rsquo;s Brier&amp;rsquo;s:
$$ (a - c)^2 + (b - d)^2. $$
So, to get from Euclid to Brier, you just take away the square root.&lt;/p&gt;

&lt;p&gt;That makes a world of difference, it turns out. Brier distance isn&amp;rsquo;t unstable the way Euclidean distance is. But we&amp;rsquo;ll see that it&amp;rsquo;s enough like Euclidean distance to vindicate the argument for the laws of probability we began with last time.&lt;/p&gt;

&lt;p&gt;But first, a fun fact.&lt;/p&gt;

&lt;h1 id=&#34;fun-fact&#34;&gt;Fun Fact&lt;/h1&gt;

&lt;p&gt;Brier distance comes from the world of weather forecasting. Glenn W. Brier worked for the U. S. Weather Bureau, and in &lt;a href=&#34;http://docs.lib.noaa.gov/rescue/mwr/078/mwr-078-01-0001.pdf&#34; target=&#34;_blank&#34;&gt;a 1950 paper&lt;/a&gt; he proposed his formula as a way of measuring how well a weather forecaster is doing at predicting the weather.&lt;/p&gt;

&lt;p&gt;Suppose you say there&amp;rsquo;s a 70% chance of rain. If it does rain, you&amp;rsquo;re hardly wrong, but you&amp;rsquo;re not exactly right either. Brier suggested assessing a forecaster&amp;rsquo;s probabilities by taking the square of the difference from $1$ when it rains, and from $0$ when it doesn&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;Well, actually, he proposed taking the &lt;em&gt;average&lt;/em&gt; of those squares. But we&amp;rsquo;ll follow the recent philosophical literature and keep it simple: we&amp;rsquo;ll just use the sum of squares rather than its average.&lt;/p&gt;

&lt;p&gt;Now on to the substance. Two facts about Brier distance make it useful as a replacement for Euclidean distance.&lt;/p&gt;

&lt;h1 id=&#34;euclid-and-brier-are-ordinally-equivalent&#34;&gt;Euclid and Brier are Ordinally Equivalent&lt;/h1&gt;

&lt;p&gt;First, Brier distance is &lt;em&gt;ordinally equivalent&lt;/em&gt; to Euclidean distance. Meaning: whenever a distance is larger according to Euclid, it&amp;rsquo;s larger according to Brier too. And vice versa.&lt;/p&gt;

&lt;p&gt;How do we know that? Because Brier is just Euclid squared, and squaring a larger number always results in a larger number (for positive numbers like distances, anyway). If $D$ is the distance from Toronto to the sun, and $d$ is the distance from Toronto to the moon, then $D^2 &amp;gt; d^2$. It&amp;rsquo;s further to the sun than to the moon, both in terms of Brier distance and Euclidean distance.&lt;/p&gt;

&lt;p&gt;So, when we&amp;rsquo;re comparing distances from the truth, Brier distance behaves a lot like Euclidean distance. In particular, what we learned from our opening diagram about Euclidean distance holds for Brier distance, too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jonathanweisberg.org/img/accuracy/2D%20Dominance%20Diagram%20-%20400px.png&#34; alt=&#34;Opening diagram&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Not only is $c&amp;rsquo;$ closer to both vertices than $c^*$ in Euclidean terms, it&amp;rsquo;s also closer in terms of Brier distance.&lt;/p&gt;

&lt;h1 id=&#34;brier-is-stable&#34;&gt;Brier is Stable&lt;/h1&gt;

&lt;p&gt;Second, Brier distance doesn&amp;rsquo;t lead to the kind of instability that made Euclidean distance problematic. To see why, let&amp;rsquo;s rerun our expected inaccuracy calculations from last time, but using Brier distance instead of Euclid.&lt;/p&gt;

&lt;p&gt;Suppose your credences in Heads and Tails are $p$ and $1-p$. What&amp;rsquo;s the expected inaccuracy of having some credence $q$ in Heads, and $1-q$ in Tails?&lt;/p&gt;

&lt;p&gt;Well, the Brier distance between $(q, 1-q)$ and $(1,0)$ is:
$$(q - 1)^2 + ((1-q) - 0)^2.$$
And the Brier distance between $(q, 1-q)$ and $(0,1)$ is:
$$(q - 0)^2 + ((1-q) - 1)^2.$$
We don&amp;rsquo;t know which of $(1,0)$ or $(0,1)$ is the &amp;ldquo;true&amp;rdquo; one. But we have assigned them the probabilities $p$ and $1-p$, respectively. So we can calculate the expected inaccuracy of $(q, 1-q)$, written $EI(q, 1-q)$:
$$
\begin{align}
EI(q, 1-q) &amp;amp;= p \left( (q - 1)^2 + ((1-q) - 0)^2 \right)\\&lt;br /&gt;
  &amp;amp;\quad + (1-p) \left( (q - 0)^2 + ((1-q) - 1)^2 \right)\\&lt;br /&gt;
  &amp;amp;= 2 p (1 - q)^2 + 2(1-p) q^2\\&lt;br /&gt;
  &amp;amp;= 2 p q^2 - 4pq + 2p + 2q^2 - 2pq^2\\&lt;br /&gt;
  &amp;amp;= 2q^2 - 4pq + 2p
\end{align}
$$
Now that last line might look like a mess. But it&amp;rsquo;s really just a quadratic equation, where the variable is $q$. Remember: we&amp;rsquo;re treating $p$ as a constant since that&amp;rsquo;s the credence you hold. And we&amp;rsquo;re looking at potential values of $q$ to see which ones minimize the quantity $EI(q, 1-q)$, given a fixed credence of $p$ in heads.&lt;/p&gt;

&lt;p&gt;So which value of $q$ minimizes this quadratic formula? You might remember from algebra class that a quadratic equation of the form:
$$
ax^2 + bx + c
$$
is a parabola, with the bottom of the bowl located at $x = -b/2a$. (Or, if you know some calculus, you can take the derivative and set it equal to $0$. Since the derivative here is $2ax + b$, setting it equal to $0$ yields, again, $x = -b/2a$.)&lt;/p&gt;

&lt;p&gt;In the case of our formula, we have $a = 2$ and $b = -4p$. So the minimum happens when $q = 4p/4 = p$. In other words, given credence $p$ in heads, expected inaccuracy is minimized by sticking with that same credence, i.e. assigning $q = p$.&lt;/p&gt;

&lt;p&gt;So, to complement our result about Euclidean distance from last time, we have a&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt;&amp;nbsp; Suppose $p \in [0,1]$. Then, according to the probability assignment $(p, 1-p)$, the expected Brier distance of any alternative assignment $(q, 1-q)$ from the points $(1,0)$ and $(0,1)$ is uniquely minimized when $p = q$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&amp;nbsp; Scroll up! &lt;span style=&#34;float: right;&#34;&gt;$\Box$&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;proper-scoring-rules&#34;&gt;Proper Scoring Rules&lt;/h1&gt;

&lt;p&gt;When a measure of inaccuracy is stable like this, it&amp;rsquo;s called &lt;em&gt;proper&lt;/em&gt; (or sometimes: &lt;em&gt;immodest&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;There are lots of other proper ways of measuring inaccuracy besides Brier. But Brier tends to be the default among philosophers writing in the accuracy framework, at least as a working example. Why?&lt;/p&gt;

&lt;p&gt;My impression (though I&amp;rsquo;m no guru) is that it&amp;rsquo;s the default because:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Brier is a lot like Euclidean distance, as we saw. So it&amp;rsquo;s easier and more intuitive to work with than some of the alternatives.&lt;/li&gt;
&lt;li&gt;Brier tends to be representative of other proper/immodest rules. If you discover something philosophically interesting using Brier, there&amp;rsquo;s a good chance it holds for many other proper scoring rules.&lt;/li&gt;
&lt;li&gt;Brier has other nice mathematical properties which, according to authors like Richard Pettigrew, make it The One True Measure of Inaccuracy. (It may have some odd features too, though: see &lt;a href=&#34;http://m-phi.blogspot.ca/2015/03/a-strange-thing-about-brier-score.html&#34; target=&#34;_blank&#34;&gt;this post&lt;/a&gt; by Brian Knab and Miriam Schoenfield, for example.)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;How does our starting argument for the laws of total probability fare if we use other proper scoring rules, besides Brier? Really well, it turns out!&lt;/p&gt;

&lt;p&gt;The key fact our diagram illustrates doesn&amp;rsquo;t just hold for Euclidean distance and Brier distance. Speaking &lt;em&gt;very&lt;/em&gt; loosely: it holds on any proper way of measuring distance (but do see sections 8 and 9 of &lt;a href=&#34;https://philpapers.org/rec/JOYAAC&#34; target=&#34;_blank&#34;&gt;Joyce&amp;rsquo;s 2009&lt;/a&gt; for the details before getting carried away with this generalization; or see Theorem 4.3.5 of &lt;a href=&#34;https://global.oup.com/academic/product/accuracy-and-the-laws-of-credence-9780198732716&#34; target=&#34;_blank&#34;&gt;Pettigrew 2016&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Proving that requires grinding through a good deal of math, though. So in these posts we&amp;rsquo;re going to stick with Brier distance, at least for a while.&lt;/p&gt;

&lt;h1 id=&#34;begging-the-question&#34;&gt;Begging the Question?&lt;/h1&gt;

&lt;p&gt;We started these posts with an illustration of an influential argument for the laws of probability. But we quickly switched to &lt;em&gt;assuming&lt;/em&gt; those very same laws in the arguments that followed.&lt;/p&gt;

&lt;p&gt;For example, to illustrate the instability of Euclidean distance, I chose a point on the diagonal of our diagram, $(.6, .4)$. And in the theorem that generalized that example, I assumed probabilistic assignments like $(p, 1-p)$ and $(q, 1-q)$, which add up to $1$.&lt;/p&gt;

&lt;p&gt;So didn&amp;rsquo;t we beg the question when we motivated switching from Euclid to Brier?&lt;/p&gt;

&lt;p&gt;To some extent: yes. We are assuming that reasonable ways of measuring inaccuracy can&amp;rsquo;t be so hostile to the laws of probability that they make almost all probability assignments unstable.&lt;/p&gt;

&lt;p&gt;But also: no. We aren&amp;rsquo;t assuming that the laws of probability are absolute and inviolable, just that they&amp;rsquo;re reasonable &lt;em&gt;sometimes&lt;/em&gt;. Euclidean distance would rule out probabilistic credences on pretty much all occasions. So it conflicts with the very modest thought that following the laws of probability is &lt;em&gt;occasionally&lt;/em&gt; reasonable. So, even if you&amp;rsquo;re just a little bit open to the idea of probability theory, Euclidean distance will seem pretty unfriendly.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Perhaps most importantly, though: the motivation I&amp;rsquo;ve given you here for moving from Euclid to Brier isn&amp;rsquo;t the official one you&amp;rsquo;ll find in an actual, bottom-up argument for probability theory, like &lt;a href=&#34;https://richardpettigrew.wordpress.com/accuracy-book/&#34; target=&#34;_blank&#34;&gt;Richard Pettigrew&amp;rsquo;s&lt;/a&gt;. His argument starts from a much more abstract place. He starts with axioms that any measure of inaccuracy must obey, and then narrows things down to Brier.&lt;/p&gt;

&lt;p&gt;So there&amp;rsquo;s the official story and the unofficial story. This post gives you the unofficial story, to help you get started. Because the official story is often really hard to understand. Not only is the math way more abstract, but the philosophical motivations are often hard to suss out. Because&amp;mdash;and this is just between you and me now&amp;mdash;the people telling the official story actually started out with the unofficial story, and then worked backwards until they came up with an officially respectable story that doesn&amp;rsquo;t beg the question quite so obviously.&lt;/p&gt;

&lt;p&gt;Ok, that&amp;rsquo;s unfair. Here&amp;rsquo;s a more even-handed (and better-informed) way of putting it, from &lt;a href=&#34;http://ndpr.nd.edu/news/70705-accuracy-and-the-laws-of-credence/&#34; target=&#34;_blank&#34;&gt;Kenny Easwaran&amp;rsquo;s review&lt;/a&gt; of Pettigrew&amp;rsquo;s book:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Some philosophers have a vision of what they do as starting from unassailable premises, and giving an ironclad argument for a conclusion. However, I think we&amp;rsquo;ve all often seen cases where these arguments are weaker than they seem to the author, and with the benefit of a bit of distance, one can often recognize how the premises were in fact motivated by an attempt to justify the conclusion, which was chosen in advance. Pettigrew avoids the charade of pretending to have come up with the premises independently of recognizing that they lead to the conclusions of his arguments. Instead, he is open about having chosen target conclusions in advance [&amp;hellip;] and investigated what collection of potentially plausible principles about accuracy and epistemic decision theory will lead to those conclusions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;This argument is essentially drawn from &lt;a href=&#34;https://philpapers.org/rec/JOYAAC&#34; target=&#34;_blank&#34;&gt;(Joyce 2009)&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>